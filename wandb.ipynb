{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\Desktop\\CodeRepositories\\venv\\lib\\site-packages\\requests\\__init__.py:104: RequestsDependencyWarning: urllib3 (1.26.13) or chardet (5.1.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "# import packages and add global parameter settings\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "from io import StringIO\n",
    "from tqdm.auto import tqdm\n",
    "import wandb\n",
    "import string\n",
    "import nltk\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "sb.set_theme(style=\"white\", palette=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/znfph1r8 (running)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/7g29utle (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/sztpd82u (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/obg7g54g (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/avbkuk6f (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/wyy1ypxj (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/5g5ap7y4 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/ruskmd5k (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/x84owtic (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/3424bv3i (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/3dh8hbgw (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/jha105b9 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/xit0y9ko (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/wrbutke3 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/mvap8e8p (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/h050ncsy (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/15j8bqqu (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/vz7helse (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/xbiscehj (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/xy5y79l3 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/ztdgfvh0 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/oiyncgnz (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/2u4pvv2b (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/kmjmrzm2 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/4g0w69e5 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/3rr3mpwc (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/mhkws0ws (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/0krumq5w (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/iz5p4fkp (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/2hnjykxj (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/1m9sfe0j (crashed)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/lvxp673n (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/bkenusqx (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/304rxx2r (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/rbfun4ru (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/d8izv9mo (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/r9z90fgp (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/l8vp6otr (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/yq15wqe8 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/0snlm7yu (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/g1rw6cg5 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/91nc9qlw (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/zymnqlcv (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/he8ngdy7 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/rxb48uds (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/kbpu8xu5 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/boo7m1zo (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/34bolxl7 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/ylmun8jo (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/zz22chfq (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/2r77ocu3 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/mnk1tkqz (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/6othf7uv (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/239fzyoa (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/2dfbewz5 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/tn5sil4h (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/lg0et6xu (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/dwsses2i (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/1knxiq37 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/l5e6ntyg (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/30rcz136 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/veil5uy0 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/0czi5w8j (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/btvghd29 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/1iofcb0t (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/2910cokb (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/2axtridp (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/24mzrihk (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/3dnimr54 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/16jwdikp (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/bmrjmozu (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/3rk5sp7r (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/34cp8nbe (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/ly2tcr9q (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/21xjjwwx (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/3ec2mf5c (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/hl25a4ml (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/u93ps6pu (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/19ub5ymd (crashed)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/5rnmejah (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/eyum2mgg (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/xvhd8rch (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/xwmcj8xi (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/h4j3o2ic (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/eg3z6gcm (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/hdsecxvz (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/g779h6t8 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/k2stjy1j (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/phcjkfkx (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/2kjicxev (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/erl82y8d (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/2w9nfjfk (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/bmcjzt04 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/cq515fo5 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/v379qqee (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/g6kl7uoc (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/b98d1671 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/4mfmzz06 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/18t5sqtw (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/ek413nmt (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/5ojlwxi9 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/y56dsqg3 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/j31v56ns (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/ts7fz3ig (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/wrcx3bb5 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/sx8v8w6y (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/kag8fvfr (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/0yaa9iym (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/fdqf3s7y (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/y6s0sepq (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/1qbgf41z (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/sh5rkgzf (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/m29xasf5 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/73dki9cl (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/s4t742qq (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/4awo9398 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/bnq8zzhw (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/yb8klocm (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/jnf4dktw (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/myb6yz65 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/itofm9ru (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/34wldaup (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/1e78r4dj (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/h152em1z (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/p93unja0 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/43rtkrck (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/gjd302f3 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/18dz4thp (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/rlw5bmp3 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/jtar0ea8 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/wfpg1fas (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/spfmntpp (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/d8zgoxid (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/kt0rto57 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/gvqhvu33 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/r4qt2ub7 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/2wa596mz (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/4fh7kf5n (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/0ow32cvh (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/wldzoaed (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/2cmp1sul (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/2irhadgh (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/krzk8azi (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/t82njqf5 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/a786xjap (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/h7t0bk6v (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/h55ln9jt (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/t4bexsi0 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/zzas3zwl (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/rbjjedl6 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/3uwg069b (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/x45fnojw (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/6b8tiig1 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/itkmqiru (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/iic8pur0 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/l2levtbt (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/8tlb542e (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/yp3hruej (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/2ews1ew2 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/e51ukd8x (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/dy7nwhad (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/eqmk7a5e (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/jcbr461r (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/cfo0e1n4 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/vfmc9zvw (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/lhg3em51 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/p7r29dcv (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/25bhw0lb (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/omwjww2d (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/1gnbj09w (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/v1v0pt8n (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/0abwryrr (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/pebu1ixv (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/3ajvqy10 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/bs69r40n (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/gs46yeht (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/alluyeh0 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/saw12im1 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/92brs01k (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/fx58qa3h (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/n3zdd4fx (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/vef9j3m2 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/0hz6bx2d (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/f6jz1psl (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/7pbljwps (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/ty0k5mhk (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/semhvfwg (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/r22gxoee (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/voxye5mk (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/07j7dnrq (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/ajqcfx6c (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/8grd8dn7 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/h4nzd3iy (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/vj99uk7i (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/bbpzqr6d (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/0dzfyarb (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/a4a8juh0 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/yd2b5mwe (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/nfoxlyts (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/9f81dc4d (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/1jxbs6h6 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/yenib4d6 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/dlx53hus (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/rcawyzg2 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/tnq1ybep (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/brrdoiua (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/erq1rnpn (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/41ftb2fw (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/7w0x0s21 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/6iqmccle (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/j7jo0egi (failed)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/xm2zfz63 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/2utxglip (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/fsnia1i1 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/b6vph1ju (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/3yngyl3v (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/et4u7fqr (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/tasmbm4o (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/cpjwef0u (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/6lp8ajcs (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/99n81ikt (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/fr9wg8fd (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/xm0bhp1e (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/vg8hsptk (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/xxhu3nxo (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/e17vj9et (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/umgst3jy (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/r575zw56 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/qms1n1nx (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/l25edc50 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/zyw5rqyt (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/pqkjl5vj (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/t67ta5ck (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/1qx4zcaa (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/3ixacef5 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/rhh8ktxz (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/6f4hus0m (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/rutyv207 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/lkl6nuj6 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/3g6v0jkk (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/8drm8nv6 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/5ia93aw0 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/s98u1h72 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/fox718p1 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/koykbkj4 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/kydhwov4 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/0f3qznic (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/dgec7yat (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/3ntwf200 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/wtnriu0x (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/3w9f97yx (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/vvbupie9 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/2guwlane (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/xlqffm4p (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/27bsgzwx (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/crppk1on (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/pcgqjg47 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/jvni6hkb (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/c9qvoiyv (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/3mmxn171 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/lx5ny0nq (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/pb8s8qgi (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/356smtrw (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/9hmxjg00 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/swgvqgmf (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/msmo8mvd (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/5vk2ph9n (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/dy584a6x (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/f6nlunyr (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/nf74ucv3 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/1nfcefjj (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/4e8hfbm7 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/9aqbes60 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/5shdc851 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/t94ufx0p (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/ve9ift4i (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/7cih2v47 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/ubo0c6sf (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/7l4jllyb (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/kriphwx8 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/md52vsoa (finished)>]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# connect to wandb and get list of runs\n",
    "api_helper = wandb.Api(api_key='3138e1b24deb278ed045d0dedb39511d3a96245b')\n",
    "runs = list(api_helper.runs(path='yuting_fyp/In-context-learning for Dialogue Summarization',\n",
    "                     per_page=1000))\n",
    "runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c11d604bb95e46d1ad645c63640ccf18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/281 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsing run llama-7b-hf-0-shot\n",
      "parsing run opt-iml-1.3b-2-shot-randomLabel\n",
      "parsing run Cerebras-GPT-13B-3-shot-length\n",
      "parsing run mt5-xl-1-shot-3-keywords-raw\n",
      "[debug] find keyword_num = 3 in mt5-xl-1-shot-3-keywords-raw\n",
      "parsing run alpaca-native-3-shot-length\n",
      "parsing run alpaca-native-3-shot-3-keywords\n",
      "[debug] find keyword_num = 3 in alpaca-native-3-shot-3-keywords\n",
      "parsing run opt-1.3b-2-shot-focus\n",
      "parsing run alpaca-native-2-shot-3-keywords\n",
      "[debug] find keyword_num = 3 in alpaca-native-2-shot-3-keywords\n",
      "parsing run mt5-xl-1-shot-length\n",
      "parsing run mt5-xl-2-shot-length\n",
      "parsing run mt5-xl-3-shot-length\n",
      "parsing run Cerebras-GPT-13B-1-shot-length\n",
      "parsing run opt-1.3b-3-shot-focus\n",
      "parsing run opt-1.3b-1-shot-focus\n",
      "parsing run mt5-xl-3-shot-raw\n",
      "parsing run opt-iml-1.3b-3-shot-focus\n",
      "parsing run GPT3-davinci-003-2-shot-3-keywords\n",
      "[debug] find keyword_num = 3 in GPT3-davinci-003-2-shot-3-keywords\n",
      "parsing run GPT3-davinci-003-2-shot-3-keywords\n",
      "[WARN] skip [] because len(metric_file) < 1\n",
      "parsing run opt-iml-1.3b-2-shot-focus\n",
      "parsing run opt-iml-1.3b-1-shot-focus\n",
      "parsing run mt5-xl-2-shot-raw\n",
      "parsing run alpaca-native-1-shot-3-keywords\n",
      "[debug] find keyword_num = 3 in alpaca-native-1-shot-3-keywords\n",
      "parsing run GPT3-davinci-003-1-shot\n",
      "parsing run alpaca-native-1-shot-2-keywords\n",
      "[debug] find keyword_num = 2 in alpaca-native-1-shot-2-keywords\n",
      "parsing run mt5-xl-1-shot-raw\n",
      "parsing run glowing-violet-439\n",
      "[debug] skip glowing-violet-439\n",
      "parsing run Cerebras-GPT-2.7B-2-shot-length\n",
      "parsing run Cerebras-GPT-2.7B-1-shot-length\n",
      "parsing run llama-7b-hf-3-shot-length\n",
      "parsing run llama-7b-hf-2-shot-length\n",
      "parsing run llama-7b-hf-1-shot-length\n",
      "parsing run Cerebras-GPT-2.7B-3-shot-length\n",
      "parsing run opt-iml-1.3b-0-shot-instructions\n",
      "parsing run opt-iml-1.3b-1-shot-instructions\n",
      "parsing run opt-iml-1.3b-3-shot-instructions\n",
      "parsing run opt-iml-1.3b-2-shot-instructions\n",
      "parsing run opt-iml-1.3b-3-shot-replaceName\n",
      "parsing run opt-iml-1.3b-1-shot-replaceName\n",
      "parsing run opt-iml-1.3b-2-shot-length\n",
      "parsing run opt-iml-1.3b-1-shot-length\n",
      "parsing run opt-iml-1.3b-3-shot-length\n",
      "parsing run bloom-7b1-2-shot-replaceName\n",
      "parsing run bloom-7b1-3-shot-replaceName\n",
      "parsing run bloom-7b1-1-shot-replaceName\n",
      "parsing run opt-1.3b-3-shot-replaceName\n",
      "parsing run opt-1.3b-2-shot-nameReplace\n",
      "parsing run opt-1.3b-1-shot-nameReplace\n",
      "parsing run bloom-7b1-3-shot-length\n",
      "parsing run Cerebras-GPT-13B-1-shot-3-keywords\n",
      "[debug] find keyword_num = 3 in Cerebras-GPT-13B-1-shot-3-keywords\n",
      "parsing run bloom-7b1-2-shot-length\n",
      "parsing run bloom-7b1-1-shot-length\n",
      "parsing run opt-1.3b-2-shot-2-keywords\n",
      "[debug] find keyword_num = 2 in opt-1.3b-2-shot-2-keywords\n",
      "parsing run opt-1.3b-2-shot-1-keywords\n",
      "[debug] find keyword_num = 1 in opt-1.3b-2-shot-1-keywords\n",
      "parsing run opt-1.3b-2-shot-3-keywords\n",
      "[debug] find keyword_num = 3 in opt-1.3b-2-shot-3-keywords\n",
      "parsing run opt-1.3b-3-shot-length\n",
      "parsing run opt-1.3b-2-shot-length\n",
      "parsing run opt-1.3b-1-shot-length\n",
      "parsing run alpaca-native-3-shot-2-keywords\n",
      "[debug] find keyword_num = 2 in alpaca-native-3-shot-2-keywords\n",
      "parsing run opt-1.3b-1-shot-3-keywords\n",
      "[debug] find keyword_num = 3 in opt-1.3b-1-shot-3-keywords\n",
      "parsing run opt-1.3b-1-shot-2-keywords\n",
      "[debug] find keyword_num = 2 in opt-1.3b-1-shot-2-keywords\n",
      "parsing run opt-1.3b-1-shot-1-keywords\n",
      "[debug] find keyword_num = 1 in opt-1.3b-1-shot-1-keywords\n",
      "parsing run alpaca-native-3-shot-1-keywords\n",
      "[debug] find keyword_num = 1 in alpaca-native-3-shot-1-keywords\n",
      "parsing run Cerebras-GPT-13B-1-shot-2-keywords\n",
      "[debug] find keyword_num = 2 in Cerebras-GPT-13B-1-shot-2-keywords\n",
      "parsing run Cerebras-GPT-13B-1-shot-1-keywords\n",
      "[debug] find keyword_num = 1 in Cerebras-GPT-13B-1-shot-1-keywords\n",
      "parsing run Cerebras-GPT-13B-3-shot-2-keywords\n",
      "[debug] find keyword_num = 2 in Cerebras-GPT-13B-3-shot-2-keywords\n",
      "parsing run mt5-xxl\n",
      "[debug] skip mt5-xxl\n",
      "parsing run alpaca-native-2-shot-2-keywords\n",
      "[debug] find keyword_num = 2 in alpaca-native-2-shot-2-keywords\n",
      "parsing run Cerebras-GPT-13B-3-shot-3-keywords\n",
      "[debug] find keyword_num = 3 in Cerebras-GPT-13B-3-shot-3-keywords\n",
      "parsing run llama-7b-hf-2-shot-2-keywords\n",
      "[debug] find keyword_num = 2 in llama-7b-hf-2-shot-2-keywords\n",
      "parsing run opt-1.3b-3-shot\n",
      "parsing run opt-1.3b-2-shot\n",
      "parsing run opt-1.3b-1-shot\n",
      "parsing run alpaca-native-2-shot-1-keywords\n",
      "[debug] find keyword_num = 1 in alpaca-native-2-shot-1-keywords\n",
      "parsing run Cerebras-GPT-13B-3-shot-2-keywords\n",
      "[debug] find keyword_num = 2 in Cerebras-GPT-13B-3-shot-2-keywords\n",
      "parsing run Cerebras-GPT-13B-3-shot-1-keywords\n",
      "[debug] find keyword_num = 1 in Cerebras-GPT-13B-3-shot-1-keywords\n",
      "parsing run alpaca-native-1-shot-1-keywords\n",
      "[debug] find keyword_num = 1 in alpaca-native-1-shot-1-keywords\n",
      "parsing run Cerebras-GPT-2.7B-3-shot-3-keywords\n",
      "[debug] find keyword_num = 3 in Cerebras-GPT-2.7B-3-shot-3-keywords\n",
      "parsing run Cerebras-GPT-2.7B-2-shot-3-keywords\n",
      "[debug] find keyword_num = 3 in Cerebras-GPT-2.7B-2-shot-3-keywords\n",
      "parsing run Cerebras-GPT-2.7B-1-shot-3-keywords\n",
      "[debug] find keyword_num = 3 in Cerebras-GPT-2.7B-1-shot-3-keywords\n",
      "parsing run Cerebras-GPT-2.7B-3-shot-2-keywords\n",
      "[debug] find keyword_num = 2 in Cerebras-GPT-2.7B-3-shot-2-keywords\n",
      "parsing run Cerebras-GPT-2.7B-2-shot-2-keywords\n",
      "[debug] find keyword_num = 2 in Cerebras-GPT-2.7B-2-shot-2-keywords\n",
      "parsing run Cerebras-GPT-2.7B-1-shot-2-keywords\n",
      "[debug] find keyword_num = 2 in Cerebras-GPT-2.7B-1-shot-2-keywords\n",
      "parsing run Cerebras-GPT-2.7B-3-shot-1-keywords\n",
      "[debug] find keyword_num = 1 in Cerebras-GPT-2.7B-3-shot-1-keywords\n",
      "parsing run Cerebras-GPT-2.7B-2-shot-1-keywords\n",
      "[debug] find keyword_num = 1 in Cerebras-GPT-2.7B-2-shot-1-keywords\n",
      "parsing run Cerebras-GPT-2.7B-1-shot-1-keywords\n",
      "[debug] find keyword_num = 1 in Cerebras-GPT-2.7B-1-shot-1-keywords\n",
      "parsing run Cerebras-GPT-6.7B-3-shot-2-keywords\n",
      "[debug] find keyword_num = 2 in Cerebras-GPT-6.7B-3-shot-2-keywords\n",
      "parsing run Cerebras-GPT-6.7B-1-shot-3-keywords\n",
      "[debug] find keyword_num = 3 in Cerebras-GPT-6.7B-1-shot-3-keywords\n",
      "parsing run Cerebras-GPT-6.7B-2-shot-3-keywords\n",
      "[debug] find keyword_num = 3 in Cerebras-GPT-6.7B-2-shot-3-keywords\n",
      "parsing run Cerebras-GPT-6.7B-3-shot-1-keywords\n",
      "[debug] find keyword_num = 1 in Cerebras-GPT-6.7B-3-shot-1-keywords\n",
      "parsing run Cerebras-GPT-6.7B-2-shot-2-keywords\n",
      "[debug] find keyword_num = 2 in Cerebras-GPT-6.7B-2-shot-2-keywords\n",
      "parsing run Cerebras-GPT-6.7B-1-shot-2-keywords\n",
      "[debug] find keyword_num = 2 in Cerebras-GPT-6.7B-1-shot-2-keywords\n",
      "parsing run Cerebras-GPT-6.7B-1-shot-1-keywords\n",
      "[debug] find keyword_num = 1 in Cerebras-GPT-6.7B-1-shot-1-keywords\n",
      "parsing run Cerebras-GPT-6.7B-2-shot-1-keywords\n",
      "[debug] find keyword_num = 1 in Cerebras-GPT-6.7B-2-shot-1-keywords\n",
      "parsing run llama-7b-hf-3-shot-3-keywords\n",
      "[debug] find keyword_num = 3 in llama-7b-hf-3-shot-3-keywords\n",
      "parsing run llama-7b-hf-3-shot-2-keywords\n",
      "[debug] find keyword_num = 2 in llama-7b-hf-3-shot-2-keywords\n",
      "parsing run llama-7b-hf-3-shot-1-keywords\n",
      "[debug] find keyword_num = 1 in llama-7b-hf-3-shot-1-keywords\n",
      "parsing run llama-7b-hf-2-shot-3-keywords\n",
      "[debug] find keyword_num = 3 in llama-7b-hf-2-shot-3-keywords\n",
      "parsing run llama-7b-hf-2-shot-1-keywords\n",
      "[debug] find keyword_num = 1 in llama-7b-hf-2-shot-1-keywords\n",
      "parsing run llama-7b-hf-2-shot-1-keywords\n",
      "[debug] find keyword_num = 1 in llama-7b-hf-2-shot-1-keywords\n",
      "parsing run opt-iml-1.3b-3-shot-3-keywords\n",
      "[debug] find keyword_num = 3 in opt-iml-1.3b-3-shot-3-keywords\n",
      "parsing run opt-iml-1.3b-3-shot-2-keywords\n",
      "[debug] find keyword_num = 2 in opt-iml-1.3b-3-shot-2-keywords\n",
      "parsing run opt-iml-1.3b-3-shot-1-keywords\n",
      "[debug] find keyword_num = 1 in opt-iml-1.3b-3-shot-1-keywords\n",
      "parsing run Cerebras-GPT-13B-2-shot-3-keywords\n",
      "[debug] find keyword_num = 3 in Cerebras-GPT-13B-2-shot-3-keywords\n",
      "parsing run Cerebras-GPT-13B-2-shot-2-keywords\n",
      "[debug] find keyword_num = 2 in Cerebras-GPT-13B-2-shot-2-keywords\n",
      "parsing run llama-7b-hf-1-shot-3-keywords\n",
      "[debug] find keyword_num = 3 in llama-7b-hf-1-shot-3-keywords\n",
      "parsing run llama-7b-hf-1-shot-2-keywords\n",
      "[debug] find keyword_num = 2 in llama-7b-hf-1-shot-2-keywords\n",
      "parsing run Cerebras-GPT-13B-2-shot-1-keywords\n",
      "[debug] find keyword_num = 1 in Cerebras-GPT-13B-2-shot-1-keywords\n",
      "parsing run llama-7b-hf-1-shot-1-keywords\n",
      "[debug] find keyword_num = 1 in llama-7b-hf-1-shot-1-keywords\n",
      "parsing run bloom-7b1-3-shot-3-keywords\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[debug] find keyword_num = 3 in bloom-7b1-3-shot-3-keywords\n",
      "parsing run bloom-7b1-3-shot-2-keywords\n",
      "[debug] find keyword_num = 2 in bloom-7b1-3-shot-2-keywords\n",
      "parsing run bloom-7b1-3-shot-1-keywords\n",
      "[debug] find keyword_num = 1 in bloom-7b1-3-shot-1-keywords\n",
      "parsing run bloom-7b1-2-shot-3-keywords\n",
      "[debug] find keyword_num = 3 in bloom-7b1-2-shot-3-keywords\n",
      "parsing run bloom-7b1-2-shot-2-keywords\n",
      "[debug] find keyword_num = 2 in bloom-7b1-2-shot-2-keywords\n",
      "parsing run bloom-7b1-2-shot-1-keywords\n",
      "[debug] find keyword_num = 1 in bloom-7b1-2-shot-1-keywords\n",
      "parsing run bloom-7b1-1-shot-3-keywords\n",
      "[debug] find keyword_num = 3 in bloom-7b1-1-shot-3-keywords\n",
      "parsing run bloom-7b1-1-shot-1-keywords\n",
      "[debug] find keyword_num = 1 in bloom-7b1-1-shot-1-keywords\n",
      "parsing run bloom-7b1-1-shot-2-keywords\n",
      "[debug] find keyword_num = 2 in bloom-7b1-1-shot-2-keywords\n",
      "parsing run flan-t5-xl-3-shot\n",
      "parsing run flan-t5-xl-3-shot\n",
      "parsing run flan-t5-xl-2-shot\n",
      "parsing run flan-t5-xl-2-shot\n",
      "parsing run alpaca-native-3-shot\n",
      "parsing run opt-iml-1.3b-2-shot-3-keywords\n",
      "[debug] find keyword_num = 3 in opt-iml-1.3b-2-shot-3-keywords\n",
      "parsing run opt-iml-1.3b-1-shot-1-keywords\n",
      "[debug] find keyword_num = 1 in opt-iml-1.3b-1-shot-1-keywords\n",
      "parsing run mt5-xxl-3-shot-3-keywords\n",
      "[debug] find keyword_num = 3 in mt5-xxl-3-shot-3-keywords\n",
      "parsing run alpaca-native-2-shot\n",
      "parsing run mt5-xxl-3-shot-2-keywords\n",
      "[debug] find keyword_num = 2 in mt5-xxl-3-shot-2-keywords\n",
      "parsing run opt-iml-1.3b-2-shot-1-keywords\n",
      "[debug] find keyword_num = 1 in opt-iml-1.3b-2-shot-1-keywords\n",
      "parsing run opt-iml-1.3b-2-shot-2-keywords\n",
      "[debug] find keyword_num = 2 in opt-iml-1.3b-2-shot-2-keywords\n",
      "parsing run opt-iml-1.3b-1-shot-3-keywords\n",
      "[debug] find keyword_num = 3 in opt-iml-1.3b-1-shot-3-keywords\n",
      "parsing run opt-iml-1.3b-1-shot-2-keywords\n",
      "[debug] find keyword_num = 2 in opt-iml-1.3b-1-shot-2-keywords\n",
      "parsing run opt-iml-1.3b-2-shot-3-keywords\n",
      "[debug] find keyword_num = 3 in opt-iml-1.3b-2-shot-3-keywords\n",
      "parsing run opt-iml-1.3b-1-shot-3-keywords\n",
      "[debug] find keyword_num = 3 in opt-iml-1.3b-1-shot-3-keywords\n",
      "parsing run mt5-xxl-3-shot-1-keywords\n",
      "[debug] find keyword_num = 1 in mt5-xxl-3-shot-1-keywords\n",
      "parsing run alpaca-native-1-shot\n",
      "parsing run mt5-xxl-2-shot-3-keywords\n",
      "[debug] find keyword_num = 3 in mt5-xxl-2-shot-3-keywords\n",
      "parsing run mt5-xxl-2-shot-2-keywords\n",
      "[debug] find keyword_num = 2 in mt5-xxl-2-shot-2-keywords\n",
      "parsing run mt5-xxl-2-shot-1-keywords\n",
      "[debug] find keyword_num = 1 in mt5-xxl-2-shot-1-keywords\n",
      "parsing run mt5-xxl-1-shot-3-keywords\n",
      "[debug] find keyword_num = 3 in mt5-xxl-1-shot-3-keywords\n",
      "parsing run mt5-xxl-1-shot-2-keywords\n",
      "[debug] find keyword_num = 2 in mt5-xxl-1-shot-2-keywords\n",
      "parsing run llama-7b-hf-2-shot\n",
      "parsing run mt5-xl-3-shot-3-keywords\n",
      "[debug] find keyword_num = 3 in mt5-xl-3-shot-3-keywords\n",
      "parsing run llama-7b-hf-3-shot\n",
      "parsing run mt5-xxl-1-shot-1-keywords\n",
      "[debug] find keyword_num = 1 in mt5-xxl-1-shot-1-keywords\n",
      "parsing run mt5-xl-2-shot-3-keywords\n",
      "[debug] find keyword_num = 3 in mt5-xl-2-shot-3-keywords\n",
      "parsing run mt5-xl-3-shot-2-keyword\n",
      "[debug] find keyword_num = 2 in mt5-xl-3-shot-2-keyword\n",
      "parsing run mt5-xl-3-shot-1-keyword\n",
      "[debug] find keyword_num = 1 in mt5-xl-3-shot-1-keyword\n",
      "parsing run mt5-xl-2-shot-2-keyword\n",
      "[debug] find keyword_num = 2 in mt5-xl-2-shot-2-keyword\n",
      "parsing run mt5-xl-2-shot-1-keyword\n",
      "[debug] find keyword_num = 1 in mt5-xl-2-shot-1-keyword\n",
      "parsing run mt5-xl-1-shot-3-keyword\n",
      "[debug] find keyword_num = 3 in mt5-xl-1-shot-3-keyword\n",
      "parsing run mt5-xl-1-shot-2-keyword\n",
      "[debug] find keyword_num = 2 in mt5-xl-1-shot-2-keyword\n",
      "parsing run mt5-xl-1-shot-1-keyword\n",
      "[debug] find keyword_num = 1 in mt5-xl-1-shot-1-keyword\n",
      "parsing run bloom-3b-5-shot\n",
      "parsing run Cerebras-GPT-6.7B-2-shot\n",
      "parsing run Cerebras-GPT-6.7B-1-shot\n",
      "parsing run llama-7b-hf-1-shot\n",
      "parsing run opt-iml-1.3b-3-shot\n",
      "parsing run opt-iml-1.3b-2-shot\n",
      "parsing run opt-iml-1.3b-1-shot\n",
      "parsing run bloom-3b-3-shot\n",
      "parsing run bloom-3b-2-shot\n",
      "parsing run bloom-3b-1-shot\n",
      "parsing run bloom-7b1-3-shot\n",
      "parsing run bloom-7b1-5-shot\n",
      "parsing run bloom-7b1-2-shot\n",
      "parsing run bloom-7b1-1-shot\n",
      "parsing run Cerebras-GPT-13B-3-shot\n",
      "parsing run Cerebras-GPT-13B-2-shot\n",
      "parsing run Cerebras-GPT-13B-1-shot\n",
      "parsing run Cerebras-GPT-2.7B-3-shot\n",
      "parsing run Cerebras-GPT-2.7B-1-shot\n",
      "parsing run Cerebras-GPT-2.7B-2-shot\n",
      "parsing run Cerebras-6.7B-3-shot\n",
      "parsing run mt5-xxl-5-shot\n",
      "parsing run mt5-xxl-3-shot\n",
      "parsing run mt5-xxl-2-shot\n",
      "parsing run mt5-xxl-1-shot\n",
      "parsing run mt5-xl-5-shot\n",
      "parsing run mt5-xl-3-shot\n",
      "parsing run mt5-xl-2-shot\n",
      "parsing run mt5-xl-1-shot\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'llama-7b-hf-0-shot':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.392085        0.210658          0.257814   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.090686        0.044516          0.056308           0.295086   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k   model_name keyword_num  \n",
       " 0         0.15359          0.189891  0  llama-7b-hf        None  ,\n",
       " 'opt-iml-1.3b-2-shot-randomLabel':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.254038        0.541792          0.323467   \n",
       " 1       1           0.250447        0.532532          0.318229   \n",
       " 2       2           0.255916        0.544776          0.326354   \n",
       " 3       3           0.259374        0.552865          0.330481   \n",
       " 4       4           0.248244        0.530279          0.316266   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.070903        0.162568          0.090776           0.205852   \n",
       " 1           0.066989        0.154971          0.085965           0.203249   \n",
       " 2           0.069382        0.160431          0.089650           0.205566   \n",
       " 3           0.074456        0.169052          0.095332           0.209876   \n",
       " 4           0.066339        0.152946          0.085355           0.201068   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k    model_name keyword_num  \n",
       " 0        0.440876          0.261739  2  opt-iml-1.3b        None  \n",
       " 1        0.432866          0.257662  2  opt-iml-1.3b        None  \n",
       " 2        0.437696          0.261302  2  opt-iml-1.3b        None  \n",
       " 3        0.447491          0.266699  2  opt-iml-1.3b        None  \n",
       " 4        0.430690          0.255718  2  opt-iml-1.3b        None  ,\n",
       " 'Cerebras-GPT-13B-3-shot-length':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.475546        0.281175          0.327918   \n",
       " 1       1           0.469250        0.275045          0.324314   \n",
       " 2       2           0.471364        0.281883          0.328363   \n",
       " 3       3           0.446531        0.232414          0.280234   \n",
       " 4       4                NaN             NaN               NaN   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.118232        0.066759          0.078363           0.344569   \n",
       " 1           0.116716        0.063492          0.076076           0.343962   \n",
       " 2           0.120158        0.068408          0.080345           0.348299   \n",
       " 3           0.084935        0.047770          0.055491           0.370061   \n",
       " 4                NaN             NaN               NaN                NaN   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k        model_name keyword_num  \n",
       " 0        0.198133          0.232782  3  Cerebras-GPT-13B        None  \n",
       " 1        0.195348          0.232576  3  Cerebras-GPT-13B        None  \n",
       " 2        0.202386          0.237671  3  Cerebras-GPT-13B        None  \n",
       " 3        0.183600          0.224331  3  Cerebras-GPT-13B        None  \n",
       " 4             NaN               NaN  3  Cerebras-GPT-13B        None  ,\n",
       " 'mt5-xl-1-shot-3-keywords-raw':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.287852        0.436478          0.315287   \n",
       " 1       1           0.286305        0.436513          0.314186   \n",
       " 2       2           0.289008        0.442436          0.317505   \n",
       " 3       3           0.286872        0.442493          0.316316   \n",
       " 4       4           0.290281        0.440041          0.317494   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.065895        0.066410          0.059994           0.262187   \n",
       " 1           0.065385        0.067923          0.060196           0.262279   \n",
       " 2           0.068487        0.071047          0.063139           0.263924   \n",
       " 3           0.063043        0.066001          0.057779           0.260917   \n",
       " 4           0.066604        0.068324          0.061256           0.263825   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.395296          0.286669  1     mt5-xl           3  \n",
       " 1        0.397211          0.287299  1     mt5-xl           3  \n",
       " 2        0.398872          0.288343  1     mt5-xl           3  \n",
       " 3        0.398418          0.286475  1     mt5-xl           3  \n",
       " 4        0.397689          0.287956  1     mt5-xl           3  ,\n",
       " 'alpaca-native-3-shot-length':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.365866        0.363875          0.347798   \n",
       " 1       1           0.364660        0.362591          0.345863   \n",
       " 2       2           0.365257        0.362021          0.345660   \n",
       " 3       3           0.363484        0.362304          0.345445   \n",
       " 4       4           0.364314        0.366684          0.347590   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.088584        0.089039          0.083734           0.279553   \n",
       " 1           0.084502        0.085605          0.080359           0.276761   \n",
       " 2           0.086204        0.090866          0.083399           0.277870   \n",
       " 3           0.085152        0.088977          0.081867           0.276285   \n",
       " 4           0.085355        0.087509          0.081708           0.276376   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k     model_name keyword_num  \n",
       " 0        0.279845          0.266015  3  alpaca-native        None  \n",
       " 1        0.277637          0.262935  3  alpaca-native        None  \n",
       " 2        0.277689          0.263425  3  alpaca-native        None  \n",
       " 3        0.279117          0.263689  3  alpaca-native        None  \n",
       " 4        0.278809          0.263524  3  alpaca-native        None  ,\n",
       " 'alpaca-native-3-shot-3-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.437708        0.353391          0.366040   \n",
       " 1       1           0.433500        0.353653          0.363499   \n",
       " 2       2           0.430823        0.349833          0.362186   \n",
       " 3       3           0.438909        0.357545          0.369976   \n",
       " 4       4           0.431931        0.358655          0.364309   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.120533        0.095072          0.098890           0.332926   \n",
       " 1           0.118198        0.095388          0.096895           0.330674   \n",
       " 2           0.117732        0.094430          0.097790           0.331412   \n",
       " 3           0.120107        0.096168          0.099079           0.333912   \n",
       " 4           0.121184        0.099642          0.100512           0.331854   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k     model_name keyword_num  \n",
       " 0        0.264060          0.275477  3  alpaca-native           3  \n",
       " 1        0.265924          0.274074  3  alpaca-native           3  \n",
       " 2        0.266860          0.276855  3  alpaca-native           3  \n",
       " 3        0.267725          0.278404  3  alpaca-native           3  \n",
       " 4        0.272807          0.277688  3  alpaca-native           3  ,\n",
       " 'opt-1.3b-2-shot-focus':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.397671        0.300107          0.307066   \n",
       " 1       1           0.399302        0.305171          0.310137   \n",
       " 2       2           0.399051        0.306366          0.311347   \n",
       " 3       3           0.392300        0.307847          0.309468   \n",
       " 4       4           0.393551        0.297698          0.304254   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.097190        0.067855          0.071009           0.302923   \n",
       " 1           0.096613        0.069111          0.070905           0.302624   \n",
       " 2           0.093805        0.066025          0.068473           0.302897   \n",
       " 3           0.094620        0.072359          0.072423           0.299452   \n",
       " 4           0.093314        0.065726          0.067947           0.300565   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.224850          0.231386  2   opt-1.3b        None  \n",
       " 1        0.224845          0.229958  2   opt-1.3b        None  \n",
       " 2        0.227528          0.232379  2   opt-1.3b        None  \n",
       " 3        0.232500          0.233725  2   opt-1.3b        None  \n",
       " 4        0.222421          0.228269  2   opt-1.3b        None  ,\n",
       " 'alpaca-native-2-shot-3-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.440230        0.356988          0.368207   \n",
       " 1       1           0.429159        0.352884          0.360753   \n",
       " 2       2           0.438665        0.364721          0.369664   \n",
       " 3       3           0.424656        0.358227          0.361015   \n",
       " 4       4           0.433683        0.345453          0.359630   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.122480        0.096418          0.100003           0.335658   \n",
       " 1           0.117815        0.094418          0.096002           0.326129   \n",
       " 2           0.120865        0.101187          0.101175           0.333110   \n",
       " 3           0.116809        0.096152          0.097038           0.327960   \n",
       " 4           0.118625        0.091313          0.095810           0.330392   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k     model_name keyword_num  \n",
       " 0        0.269366          0.278262  2  alpaca-native           3  \n",
       " 1        0.263418          0.270546  2  alpaca-native           3  \n",
       " 2        0.273312          0.277993  2  alpaca-native           3  \n",
       " 3        0.271775          0.275591  2  alpaca-native           3  \n",
       " 4        0.260787          0.271991  2  alpaca-native           3  ,\n",
       " 'mt5-xl-1-shot-length':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.144250        0.283754          0.179515   \n",
       " 1       1           0.136096        0.267267          0.169558   \n",
       " 2       2           0.136619        0.276225          0.172277   \n",
       " 3       3           0.134980        0.268538          0.168648   \n",
       " 4       4           0.136758        0.266285          0.169858   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.030872        0.062824          0.038993           0.124638   \n",
       " 1           0.030358        0.058474          0.037258           0.119526   \n",
       " 2           0.030000        0.059794          0.037523           0.121175   \n",
       " 3           0.029017        0.057280          0.035940           0.118818   \n",
       " 4           0.030135        0.058090          0.037037           0.121412   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.247507          0.155503  1     mt5-xl        None  \n",
       " 1        0.234776          0.148789  1     mt5-xl        None  \n",
       " 2        0.243294          0.152332  1     mt5-xl        None  \n",
       " 3        0.235585          0.148104  1     mt5-xl        None  \n",
       " 4        0.236778          0.150829  1     mt5-xl        None  ,\n",
       " 'mt5-xl-2-shot-length':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.169651        0.276393          0.197921   \n",
       " 1       1           0.168564        0.269032          0.194945   \n",
       " 2       2           0.173901        0.272406          0.196883   \n",
       " 3       3           0.176685        0.274232          0.201013   \n",
       " 4       4           0.180258        0.283548          0.207039   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.043326        0.071318          0.050669           0.146898   \n",
       " 1           0.044073        0.068310          0.050317           0.146697   \n",
       " 2           0.045736        0.067457          0.050441           0.151755   \n",
       " 3           0.045146        0.068119          0.050074           0.155147   \n",
       " 4           0.048591        0.072769          0.054009           0.157135   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.238451          0.171008  2     mt5-xl        None  \n",
       " 1        0.232291          0.168813  2     mt5-xl        None  \n",
       " 2        0.239071          0.171934  2     mt5-xl        None  \n",
       " 3        0.239045          0.175841  2     mt5-xl        None  \n",
       " 4        0.245541          0.179674  2     mt5-xl        None  ,\n",
       " 'mt5-xl-3-shot-length':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.201715        0.273264          0.217654   \n",
       " 1       1           0.190132        0.260515          0.204263   \n",
       " 2       2           0.193005        0.268877          0.209990   \n",
       " 3       3           0.194281        0.272899          0.213073   \n",
       " 4       4           0.191163        0.269576          0.209841   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.055445        0.072837          0.058931           0.176872   \n",
       " 1           0.050350        0.067517          0.052572           0.167359   \n",
       " 2           0.052231        0.073346          0.056448           0.169638   \n",
       " 3           0.051379        0.069168          0.055320           0.170538   \n",
       " 4           0.050769        0.068489          0.054587           0.166401   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.236891          0.189750  3     mt5-xl        None  \n",
       " 1        0.226051          0.178397  3     mt5-xl        None  \n",
       " 2        0.233827          0.183464  3     mt5-xl        None  \n",
       " 3        0.236940          0.185899  3     mt5-xl        None  \n",
       " 4        0.232416          0.181816  3     mt5-xl        None  ,\n",
       " 'Cerebras-GPT-13B-1-shot-length':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.414860        0.314865          0.327452   \n",
       " 1       1           0.407746        0.322261          0.328863   \n",
       " 2       2           0.415268        0.314584          0.326789   \n",
       " 3       3           0.416661        0.320586          0.332895   \n",
       " 4       4           0.420565        0.318007          0.332733   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.100485        0.074709          0.077678           0.306923   \n",
       " 1           0.096872        0.073172          0.075185           0.301421   \n",
       " 2           0.102578        0.071150          0.075809           0.304969   \n",
       " 3           0.102907        0.076108          0.079245           0.308012   \n",
       " 4           0.098332        0.073686          0.076642           0.309326   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k        model_name keyword_num  \n",
       " 0        0.229697          0.239636  1  Cerebras-GPT-13B        None  \n",
       " 1        0.234041          0.239897  1  Cerebras-GPT-13B        None  \n",
       " 2        0.227234          0.236862  1  Cerebras-GPT-13B        None  \n",
       " 3        0.234066          0.243982  1  Cerebras-GPT-13B        None  \n",
       " 4        0.231298          0.242140  1  Cerebras-GPT-13B        None  ,\n",
       " 'opt-1.3b-3-shot-focus':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.392483        0.307397          0.308130   \n",
       " 1       1           0.405781        0.312012          0.316148   \n",
       " 2       2           0.403226        0.313012          0.316033   \n",
       " 3       3           0.370562        0.271284          0.280710   \n",
       " 4       4                NaN             NaN               NaN   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.096283        0.069854          0.070803           0.301327   \n",
       " 1           0.096846        0.071537          0.072807           0.308421   \n",
       " 2           0.101055        0.076248          0.076921           0.308065   \n",
       " 3           0.076840        0.071184          0.066089           0.314379   \n",
       " 4                NaN             NaN               NaN                NaN   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.230844          0.232808  3   opt-1.3b        None  \n",
       " 1        0.234212          0.237484  3   opt-1.3b        None  \n",
       " 2        0.234976          0.238384  3   opt-1.3b        None  \n",
       " 3        0.226236          0.234771  3   opt-1.3b        None  \n",
       " 4             NaN               NaN  3   opt-1.3b        None  ,\n",
       " 'opt-1.3b-1-shot-focus':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.363911        0.288617          0.284848   \n",
       " 1       1           0.371076        0.285579          0.288244   \n",
       " 2       2           0.360227        0.280055          0.281105   \n",
       " 3       3           0.360793        0.283369          0.280458   \n",
       " 4       4           0.367025        0.282539          0.286803   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.081540        0.063727          0.062255           0.280702   \n",
       " 1           0.078718        0.058996          0.058591           0.283340   \n",
       " 2           0.078534        0.057770          0.058656           0.277865   \n",
       " 3           0.072776        0.055978          0.055232           0.273194   \n",
       " 4           0.080636        0.058857          0.060496           0.279294   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.219694          0.216775  1   opt-1.3b        None  \n",
       " 1        0.214761          0.216600  1   opt-1.3b        None  \n",
       " 2        0.210748          0.212595  1   opt-1.3b        None  \n",
       " 3        0.211592          0.209912  1   opt-1.3b        None  \n",
       " 4        0.213093          0.216305  1   opt-1.3b        None  ,\n",
       " 'mt5-xl-3-shot-raw':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.235720        0.319267          0.253861   \n",
       " 1       1           0.223928        0.309401          0.242074   \n",
       " 2       2           0.227933        0.313569          0.246681   \n",
       " 3       3           0.230938        0.315265          0.249775   \n",
       " 4       4           0.233539        0.321322          0.252998   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.073965        0.097464          0.077560           0.206526   \n",
       " 1           0.064901        0.090784          0.069841           0.194799   \n",
       " 2           0.068274        0.093966          0.073164           0.200093   \n",
       " 3           0.068941        0.093757          0.073982           0.201783   \n",
       " 4           0.072574        0.096151          0.076520           0.202224   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.274385          0.220114  3     mt5-xl        None  \n",
       " 1        0.264558          0.208848  3     mt5-xl        None  \n",
       " 2        0.269195          0.214076  3     mt5-xl        None  \n",
       " 3        0.270114          0.216201  3     mt5-xl        None  \n",
       " 4        0.273180          0.217067  3     mt5-xl        None  ,\n",
       " 'opt-iml-1.3b-3-shot-focus':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.311082        0.548395          0.373208   \n",
       " 1       1           0.306114        0.549619          0.369696   \n",
       " 2       2           0.308811        0.546010          0.371468   \n",
       " 3       3           0.254452        0.426911          0.313393   \n",
       " 4       4                NaN             NaN               NaN   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.091379        0.168008          0.110192           0.253641   \n",
       " 1           0.091137        0.167386          0.109928           0.247682   \n",
       " 2           0.090881        0.166234          0.109886           0.247846   \n",
       " 3           0.034848        0.061667          0.043956           0.214205   \n",
       " 4                NaN             NaN               NaN                NaN   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k    model_name keyword_num  \n",
       " 0        0.444268          0.303372  3  opt-iml-1.3b        None  \n",
       " 1        0.442175          0.298097  3  opt-iml-1.3b        None  \n",
       " 2        0.436709          0.297520  3  opt-iml-1.3b        None  \n",
       " 3        0.342570          0.258929  3  opt-iml-1.3b        None  \n",
       " 4             NaN               NaN  3  opt-iml-1.3b        None  ,\n",
       " 'GPT3-davinci-003-2-shot-3-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.614168        0.445023          0.488058   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.285029        0.203061          0.222835           0.494301   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k        model_name keyword_num  \n",
       " 0         0.35588          0.391049  2  GPT3-davinci-003           3  ,\n",
       " 'opt-iml-1.3b-2-shot-focus':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.300856        0.559598          0.368097   \n",
       " 1       1           0.298347        0.560604          0.365170   \n",
       " 2       2           0.296154        0.560134          0.364370   \n",
       " 3       3           0.298854        0.561689          0.367748   \n",
       " 4       4           0.292068        0.550002          0.359327   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.092598        0.177754          0.113315           0.244251   \n",
       " 1           0.093082        0.181698          0.113792           0.243995   \n",
       " 2           0.088368        0.172162          0.108892           0.239024   \n",
       " 3           0.090695        0.179321          0.112161           0.243810   \n",
       " 4           0.083791        0.171215          0.104508           0.235528   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k    model_name keyword_num  \n",
       " 0        0.451117          0.297719  2  opt-iml-1.3b        None  \n",
       " 1        0.453922          0.297280  2  opt-iml-1.3b        None  \n",
       " 2        0.448448          0.292830  2  opt-iml-1.3b        None  \n",
       " 3        0.457817          0.299595  2  opt-iml-1.3b        None  \n",
       " 4        0.442857          0.289115  2  opt-iml-1.3b        None  ,\n",
       " 'opt-iml-1.3b-1-shot-focus':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.270541        0.542521          0.339260   \n",
       " 1       1           0.268078        0.541298          0.337012   \n",
       " 2       2           0.269625        0.538529          0.336951   \n",
       " 3       3           0.264738        0.538003          0.333179   \n",
       " 4       4           0.272864        0.544147          0.341190   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.086153        0.182497          0.108135           0.223792   \n",
       " 1           0.080502        0.171842          0.101635           0.219723   \n",
       " 2           0.083166        0.173320          0.103584           0.222448   \n",
       " 3           0.081257        0.177561          0.103211           0.218241   \n",
       " 4           0.083410        0.178520          0.104965           0.223041   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k    model_name keyword_num  \n",
       " 0        0.446720          0.279654  1  opt-iml-1.3b        None  \n",
       " 1        0.442719          0.275412  1  opt-iml-1.3b        None  \n",
       " 2        0.442678          0.277190  1  opt-iml-1.3b        None  \n",
       " 3        0.441750          0.273878  1  opt-iml-1.3b        None  \n",
       " 4        0.443489          0.278151  1  opt-iml-1.3b        None  ,\n",
       " 'mt5-xl-2-shot-raw':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.213348        0.333174          0.244574   \n",
       " 1       1           0.209170        0.325578          0.239151   \n",
       " 2       2           0.216256        0.334559          0.246390   \n",
       " 3       3           0.219584        0.340062          0.250347   \n",
       " 4       4           0.222366        0.340064          0.251971   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.063422        0.098509          0.071461           0.183427   \n",
       " 1           0.059476        0.095227          0.068423           0.179201   \n",
       " 2           0.061500        0.097693          0.070359           0.185709   \n",
       " 3           0.065994        0.103781          0.074921           0.188822   \n",
       " 4           0.067595        0.102141          0.074907           0.192183   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.282501          0.208764  2     mt5-xl        None  \n",
       " 1        0.275831          0.203660  2     mt5-xl        None  \n",
       " 2        0.284724          0.210680  2     mt5-xl        None  \n",
       " 3        0.288823          0.213881  2     mt5-xl        None  \n",
       " 4        0.289034          0.216037  2     mt5-xl        None  ,\n",
       " 'alpaca-native-1-shot-3-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.432437        0.353125          0.361718   \n",
       " 1       1           0.434075        0.345775          0.357787   \n",
       " 2       2           0.429583        0.344354          0.353915   \n",
       " 3       3           0.428641        0.347350          0.357610   \n",
       " 4       4           0.431116        0.341059          0.355824   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.121226        0.096005          0.099123           0.330483   \n",
       " 1           0.116109        0.091961          0.094770           0.326582   \n",
       " 2           0.116810        0.089713          0.092775           0.329857   \n",
       " 3           0.113068        0.091181          0.092176           0.322273   \n",
       " 4           0.119228        0.091165          0.095685           0.330141   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k     model_name keyword_num  \n",
       " 0        0.266396          0.273786  1  alpaca-native           3  \n",
       " 1        0.257053          0.267074  1  alpaca-native           3  \n",
       " 2        0.261083          0.268671  1  alpaca-native           3  \n",
       " 3        0.258329          0.266288  1  alpaca-native           3  \n",
       " 4        0.257295          0.269851  1  alpaca-native           3  ,\n",
       " 'GPT3-davinci-003-1-shot':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.603958        0.323395          0.399551   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.237807        0.126821          0.155966           0.469107   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k        model_name keyword_num  \n",
       " 0        0.247752          0.307232  1  GPT3-davinci-003        None  ,\n",
       " 'alpaca-native-1-shot-2-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.421006        0.337819          0.348990   \n",
       " 1       1           0.408140        0.335296          0.342706   \n",
       " 2       2           0.414921        0.336778          0.344958   \n",
       " 3       3           0.416813        0.337912          0.347471   \n",
       " 4       4           0.419827        0.337214          0.349102   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.109308        0.086311          0.088957           0.316902   \n",
       " 1           0.105897        0.083239          0.086144           0.307311   \n",
       " 2           0.106070        0.081452          0.084470           0.314076   \n",
       " 3           0.109693        0.087887          0.089909           0.316116   \n",
       " 4           0.106473        0.082772          0.086257           0.315525   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k     model_name keyword_num  \n",
       " 0        0.250335          0.259694  1  alpaca-native           2  \n",
       " 1        0.248603          0.255062  1  alpaca-native           2  \n",
       " 2        0.252193          0.258449  1  alpaca-native           2  \n",
       " 3        0.253262          0.260986  1  alpaca-native           2  \n",
       " 4        0.248898          0.259029  1  alpaca-native           2  ,\n",
       " 'mt5-xl-1-shot-raw':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.178518        0.332754          0.218909   \n",
       " 1       1           0.173666        0.326056          0.213719   \n",
       " 2       2           0.176983        0.331910          0.216641   \n",
       " 3       3           0.170631        0.316088          0.209103   \n",
       " 4       4           0.175261        0.330738          0.216730   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.046007        0.092584          0.057901           0.153327   \n",
       " 1           0.048374        0.092562          0.059750           0.149165   \n",
       " 2           0.046839        0.089553          0.056979           0.152282   \n",
       " 3           0.043807        0.084010          0.053941           0.146054   \n",
       " 4           0.045021        0.088607          0.056227           0.149743   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.284792          0.187640  1     mt5-xl        None  \n",
       " 1        0.277326          0.182792  1     mt5-xl        None  \n",
       " 2        0.282408          0.185493  1     mt5-xl        None  \n",
       " 3        0.268617          0.178330  1     mt5-xl        None  \n",
       " 4        0.279100          0.184028  1     mt5-xl        None  ,\n",
       " 'Cerebras-GPT-2.7B-2-shot-length':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.421183        0.258220          0.294168   \n",
       " 1       1           0.417949        0.268528          0.299380   \n",
       " 2       2           0.416938        0.256634          0.294074   \n",
       " 3       3           0.415787        0.257446          0.292560   \n",
       " 4       4           0.418491        0.252923          0.290656   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.092391        0.053908          0.061973           0.304095   \n",
       " 1           0.096336        0.059965          0.066679           0.303238   \n",
       " 2           0.089008        0.053142          0.061038           0.301284   \n",
       " 3           0.094526        0.055800          0.064201           0.301165   \n",
       " 4           0.096509        0.055198          0.063877           0.303638   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k         model_name keyword_num  \n",
       " 0        0.181117          0.208052  2  Cerebras-GPT-2.7B        None  \n",
       " 1        0.191348          0.213756  2  Cerebras-GPT-2.7B        None  \n",
       " 2        0.180741          0.208765  2  Cerebras-GPT-2.7B        None  \n",
       " 3        0.181751          0.207883  2  Cerebras-GPT-2.7B        None  \n",
       " 4        0.180321          0.207900  2  Cerebras-GPT-2.7B        None  ,\n",
       " 'Cerebras-GPT-2.7B-1-shot-length':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.390995        0.244497          0.275422   \n",
       " 1       1           0.400773        0.242352          0.277860   \n",
       " 2       2           0.396450        0.246598          0.278588   \n",
       " 3       3           0.391639        0.246095          0.277121   \n",
       " 4       4           0.401484        0.242656          0.280053   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.082328        0.050855          0.056615           0.287113   \n",
       " 1           0.084675        0.048760          0.056381           0.290481   \n",
       " 2           0.085648        0.052852          0.059173           0.290505   \n",
       " 3           0.082133        0.049469          0.056203           0.284415   \n",
       " 4           0.085937        0.050250          0.057957           0.294882   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k         model_name keyword_num  \n",
       " 0        0.175559          0.198597  1  Cerebras-GPT-2.7B        None  \n",
       " 1        0.172344          0.198205  1  Cerebras-GPT-2.7B        None  \n",
       " 2        0.179072          0.202038  1  Cerebras-GPT-2.7B        None  \n",
       " 3        0.175024          0.198180  1  Cerebras-GPT-2.7B        None  \n",
       " 4        0.173611          0.201830  1  Cerebras-GPT-2.7B        None  ,\n",
       " 'llama-7b-hf-3-shot-length':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.430525        0.307819          0.337969   \n",
       " 1       1           0.431369        0.304218          0.337899   \n",
       " 2       2           0.430706        0.303720          0.337245   \n",
       " 3       3           0.431262        0.305632          0.338953   \n",
       " 4       4           0.431912        0.303077          0.335082   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.106020        0.074601          0.082284           0.321389   \n",
       " 1           0.104768        0.071095          0.079677           0.320979   \n",
       " 2           0.105504        0.073461          0.081791           0.319088   \n",
       " 3           0.111306        0.075286          0.084443           0.319176   \n",
       " 4           0.103473        0.072555          0.079782           0.317369   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k   model_name keyword_num  \n",
       " 0        0.226893          0.250179  3  llama-7b-hf        None  \n",
       " 1        0.222988          0.248793  3  llama-7b-hf        None  \n",
       " 2        0.221570          0.247250  3  llama-7b-hf        None  \n",
       " 3        0.222757          0.248217  3  llama-7b-hf        None  \n",
       " 4        0.221011          0.244572  3  llama-7b-hf        None  ,\n",
       " 'llama-7b-hf-2-shot-length':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.437817        0.297973          0.334447   \n",
       " 1       1           0.437823        0.298590          0.333461   \n",
       " 2       2           0.437731        0.299081          0.334971   \n",
       " 3       3           0.432524        0.301063          0.335925   \n",
       " 4       4           0.433199        0.289429          0.327669   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.108965        0.072741          0.082048           0.325101   \n",
       " 1           0.107811        0.071504          0.080280           0.327196   \n",
       " 2           0.108097        0.072629          0.081563           0.325264   \n",
       " 3           0.106522        0.073313          0.081734           0.323529   \n",
       " 4           0.106858        0.067611          0.077856           0.323861   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k   model_name keyword_num  \n",
       " 0        0.217661          0.245633  2  llama-7b-hf        None  \n",
       " 1        0.219262          0.246127  2  llama-7b-hf        None  \n",
       " 2        0.220129          0.247282  2  llama-7b-hf        None  \n",
       " 3        0.222741          0.249369  2  llama-7b-hf        None  \n",
       " 4        0.213005          0.242082  2  llama-7b-hf        None  ,\n",
       " 'llama-7b-hf-1-shot-length':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.439367        0.277897          0.318736   \n",
       " 1       1           0.450958        0.281965          0.326740   \n",
       " 2       2           0.448881        0.277785          0.323256   \n",
       " 3       3           0.445983        0.280007          0.322505   \n",
       " 4       4           0.447630        0.278060          0.322963   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.107115        0.066075          0.075549           0.328260   \n",
       " 1           0.109954        0.066338          0.077502           0.337929   \n",
       " 2           0.114003        0.067016          0.079249           0.338061   \n",
       " 3           0.112976        0.066984          0.077712           0.333093   \n",
       " 4           0.104948        0.062699          0.073251           0.331115   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k   model_name keyword_num  \n",
       " 0        0.203697          0.234820  1  llama-7b-hf        None  \n",
       " 1        0.208550          0.242577  1  llama-7b-hf        None  \n",
       " 2        0.204417          0.239522  1  llama-7b-hf        None  \n",
       " 3        0.204726          0.237070  1  llama-7b-hf        None  \n",
       " 4        0.201622          0.235378  1  llama-7b-hf        None  ,\n",
       " 'Cerebras-GPT-2.7B-3-shot-length':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.428381        0.246044          0.286198   \n",
       " 1       1           0.431437        0.252376          0.292453   \n",
       " 2       2           0.428037        0.253304          0.292166   \n",
       " 3       3           0.413004        0.191295          0.237875   \n",
       " 4       4                NaN             NaN               NaN   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.094272        0.051296          0.060469           0.310706   \n",
       " 1           0.093832        0.053117          0.061481           0.309639   \n",
       " 2           0.094394        0.054648          0.062771           0.309744   \n",
       " 3           0.041039        0.022659          0.025954           0.302330   \n",
       " 4                NaN             NaN               NaN                NaN   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k         model_name keyword_num  \n",
       " 0        0.173820          0.203433  3  Cerebras-GPT-2.7B        None  \n",
       " 1        0.177008          0.206283  3  Cerebras-GPT-2.7B        None  \n",
       " 2        0.178140          0.206906  3  Cerebras-GPT-2.7B        None  \n",
       " 3        0.135537          0.171260  3  Cerebras-GPT-2.7B        None  \n",
       " 4             NaN               NaN  3  Cerebras-GPT-2.7B        None  ,\n",
       " 'opt-iml-1.3b-0-shot-instructions':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.322463        0.562517          0.387103   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.107508        0.196653           0.12965           0.259163   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k    model_name keyword_num  \n",
       " 0        0.452793          0.310881  0  opt-iml-1.3b        None  ,\n",
       " 'opt-iml-1.3b-1-shot-instructions':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.273128        0.555145          0.343112   \n",
       " 1       1           0.276679        0.556394          0.346053   \n",
       " 2       2           0.277501        0.555199          0.347956   \n",
       " 3       3           0.274783        0.553774          0.344842   \n",
       " 4       4           0.277631        0.554205          0.347986   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.083116        0.180354          0.105483           0.224462   \n",
       " 1           0.081429        0.175663          0.102578           0.223860   \n",
       " 2           0.083628        0.176963          0.105574           0.225741   \n",
       " 3           0.083327        0.179172          0.105377           0.222310   \n",
       " 4           0.081219        0.175343          0.103588           0.223548   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k    model_name keyword_num  \n",
       " 0        0.453115          0.280697  1  opt-iml-1.3b        None  \n",
       " 1        0.450321          0.279476  1  opt-iml-1.3b        None  \n",
       " 2        0.449793          0.282062  1  opt-iml-1.3b        None  \n",
       " 3        0.446760          0.278067  1  opt-iml-1.3b        None  \n",
       " 4        0.447099          0.280044  1  opt-iml-1.3b        None  ,\n",
       " 'opt-iml-1.3b-3-shot-instructions':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.288680        0.554468          0.354966   \n",
       " 1       1           0.285192        0.550266          0.352431   \n",
       " 2       2           0.289434        0.552558          0.357076   \n",
       " 3       3           0.318467        0.491631          0.380622   \n",
       " 4       4                NaN             NaN               NaN   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.081369        0.163890          0.100108           0.231898   \n",
       " 1           0.079659        0.159824          0.098387           0.230061   \n",
       " 2           0.084045        0.170222          0.104324           0.232921   \n",
       " 3           0.071212        0.095385          0.079802           0.253220   \n",
       " 4                NaN             NaN               NaN                NaN   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k    model_name keyword_num  \n",
       " 0        0.442157          0.283828  3  opt-iml-1.3b        None  \n",
       " 1        0.441348          0.283197  3  opt-iml-1.3b        None  \n",
       " 2        0.442713          0.286259  3  opt-iml-1.3b        None  \n",
       " 3        0.367821          0.295268  3  opt-iml-1.3b        None  \n",
       " 4             NaN               NaN  3  opt-iml-1.3b        None  ,\n",
       " 'opt-iml-1.3b-2-shot-instructions':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.284371        0.560589          0.354357   \n",
       " 1       1           0.288276        0.570281          0.357879   \n",
       " 2       2           0.289320        0.566421          0.358568   \n",
       " 3       3           0.284030        0.555831          0.352474   \n",
       " 4       4           0.284718        0.564724          0.354676   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.082752        0.174638          0.104207           0.229237   \n",
       " 1           0.087795        0.183619          0.109364           0.233528   \n",
       " 2           0.086133        0.180088          0.107751           0.233401   \n",
       " 3           0.082569        0.173091          0.103425           0.229140   \n",
       " 4           0.083429        0.175316          0.104496           0.228436   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k    model_name keyword_num  \n",
       " 0        0.451667          0.284979  2  opt-iml-1.3b        None  \n",
       " 1        0.459876          0.288853  2  opt-iml-1.3b        None  \n",
       " 2        0.456631          0.288495  2  opt-iml-1.3b        None  \n",
       " 3        0.447713          0.283571  2  opt-iml-1.3b        None  \n",
       " 4        0.455194          0.284420  2  opt-iml-1.3b        None  ,\n",
       " 'opt-iml-1.3b-3-shot-replaceName':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.130306        0.322182          0.174007   \n",
       " 1       1           0.130087        0.320093          0.172507   \n",
       " 2       2           0.117590        0.305231          0.160144   \n",
       " 3       3                NaN             NaN               NaN   \n",
       " 4       4                NaN             NaN               NaN   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.030239        0.080183          0.040638           0.109362   \n",
       " 1           0.030341        0.079273          0.040012           0.108365   \n",
       " 2           0.024759        0.073897          0.034801           0.097497   \n",
       " 3                NaN             NaN               NaN                NaN   \n",
       " 4                NaN             NaN               NaN                NaN   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k    model_name keyword_num  \n",
       " 0        0.268400          0.145469  3  opt-iml-1.3b        None  \n",
       " 1        0.267249          0.143481  3  opt-iml-1.3b        None  \n",
       " 2        0.252845          0.132479  3  opt-iml-1.3b        None  \n",
       " 3             NaN               NaN  3  opt-iml-1.3b        None  \n",
       " 4             NaN               NaN  3  opt-iml-1.3b        None  ,\n",
       " 'opt-iml-1.3b-1-shot-replaceName':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.122929        0.297925          0.162879   \n",
       " 1       1           0.111656        0.279649          0.148791   \n",
       " 2       2           0.118491        0.286379          0.155849   \n",
       " 3       3           0.122747        0.294171          0.162234   \n",
       " 4       4           0.118301        0.291638          0.157438   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.027485        0.072838          0.037160           0.102539   \n",
       " 1           0.023246        0.066924          0.031724           0.092060   \n",
       " 2           0.030391        0.078787          0.040230           0.099067   \n",
       " 3           0.029895        0.074934          0.039542           0.102197   \n",
       " 4           0.027270        0.070661          0.036317           0.097502   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k    model_name keyword_num  \n",
       " 0        0.248773          0.135784  1  opt-iml-1.3b        None  \n",
       " 1        0.231937          0.122451  1  opt-iml-1.3b        None  \n",
       " 2        0.241393          0.130284  1  opt-iml-1.3b        None  \n",
       " 3        0.245269          0.134650  1  opt-iml-1.3b        None  \n",
       " 4        0.240234          0.129463  1  opt-iml-1.3b        None  ,\n",
       " 'opt-iml-1.3b-2-shot-length':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.294911        0.554515          0.361665   \n",
       " 1       1           0.289424        0.553389          0.356977   \n",
       " 2       2           0.291350        0.546625          0.357463   \n",
       " 3       3           0.296356        0.560773          0.365939   \n",
       " 4       4           0.288308        0.553796          0.356998   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.085057        0.167573          0.104963           0.237504   \n",
       " 1           0.086111        0.171494          0.106315           0.233171   \n",
       " 2           0.081769        0.164013          0.101516           0.232994   \n",
       " 3           0.085295        0.173739          0.106775           0.235249   \n",
       " 4           0.079568        0.165261          0.099480           0.230843   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k    model_name keyword_num  \n",
       " 0        0.445340          0.290708  2  opt-iml-1.3b        None  \n",
       " 1        0.444517          0.286935  2  opt-iml-1.3b        None  \n",
       " 2        0.436413          0.284944  2  opt-iml-1.3b        None  \n",
       " 3        0.446697          0.290342  2  opt-iml-1.3b        None  \n",
       " 4        0.444183          0.285575  2  opt-iml-1.3b        None  ,\n",
       " 'opt-iml-1.3b-1-shot-length':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.258968        0.524933          0.327001   \n",
       " 1       1           0.265486        0.532698          0.333645   \n",
       " 2       2           0.259164        0.519989          0.325277   \n",
       " 3       3           0.261637        0.528419          0.329527   \n",
       " 4       4           0.266062        0.526313          0.332067   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.072609        0.161568          0.094065           0.210530   \n",
       " 1           0.076445        0.167302          0.098070           0.213915   \n",
       " 2           0.076027        0.163644          0.096400           0.210952   \n",
       " 3           0.077642        0.168782          0.098994           0.213187   \n",
       " 4           0.075866        0.163327          0.096327           0.213954   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k    model_name keyword_num  \n",
       " 0        0.426285          0.265405  1  opt-iml-1.3b        None  \n",
       " 1        0.432269          0.269024  1  opt-iml-1.3b        None  \n",
       " 2        0.423974          0.264507  1  opt-iml-1.3b        None  \n",
       " 3        0.430046          0.267932  1  opt-iml-1.3b        None  \n",
       " 4        0.424151          0.266827  1  opt-iml-1.3b        None  ,\n",
       " 'opt-iml-1.3b-3-shot-length':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.303770        0.535369          0.363904   \n",
       " 1       1           0.298111        0.540033          0.362110   \n",
       " 2       2           0.301152        0.535654          0.363275   \n",
       " 3       3           0.348603        0.494467          0.397366   \n",
       " 4       4                NaN             NaN               NaN   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.085350        0.155780          0.101997           0.243553   \n",
       " 1           0.083988        0.156338          0.101778           0.239544   \n",
       " 2           0.083458        0.156714          0.101609           0.239928   \n",
       " 3           0.075887        0.104222          0.086002           0.256295   \n",
       " 4                NaN             NaN               NaN                NaN   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k    model_name keyword_num  \n",
       " 0        0.426526          0.290646  3  opt-iml-1.3b        None  \n",
       " 1        0.431345          0.289859  3  opt-iml-1.3b        None  \n",
       " 2        0.425360          0.288757  3  opt-iml-1.3b        None  \n",
       " 3        0.357760          0.291177  3  opt-iml-1.3b        None  \n",
       " 4             NaN               NaN  3  opt-iml-1.3b        None  ,\n",
       " 'bloom-7b1-2-shot-replaceName':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.301848        0.216274          0.227793   \n",
       " 1       1           0.296211        0.215475          0.222720   \n",
       " 2       2           0.296691        0.215094          0.225315   \n",
       " 3       3           0.296710        0.213796          0.223702   \n",
       " 4       4           0.294811        0.211985          0.223862   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.061172        0.043303          0.045366           0.221776   \n",
       " 1           0.057894        0.040343          0.042062           0.220347   \n",
       " 2           0.055104        0.042114          0.041845           0.216171   \n",
       " 3           0.056615        0.040762          0.041829           0.216436   \n",
       " 4           0.055016        0.040982          0.042177           0.217406   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.159263          0.166980  2  bloom-7b1        None  \n",
       " 1        0.156550          0.162978  2  bloom-7b1        None  \n",
       " 2        0.155965          0.162925  2  bloom-7b1        None  \n",
       " 3        0.153708          0.161297  2  bloom-7b1        None  \n",
       " 4        0.154662          0.163616  2  bloom-7b1        None  ,\n",
       " 'bloom-7b1-3-shot-replaceName':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.293625        0.209492          0.219257   \n",
       " 1       1           0.295654        0.204963          0.221401   \n",
       " 2       2           0.295443        0.212633          0.222630   \n",
       " 3       3           0.296634        0.208992          0.221642   \n",
       " 4       4           0.291968        0.210405          0.220851   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.057025        0.040721          0.042066           0.213409   \n",
       " 1           0.058827        0.040717          0.043051           0.214637   \n",
       " 2           0.051974        0.037882          0.039078           0.210647   \n",
       " 3           0.055004        0.040031          0.041430           0.214524   \n",
       " 4           0.056542        0.041678          0.042371           0.213312   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.151082          0.158018  3  bloom-7b1        None  \n",
       " 1        0.148612          0.160007  3  bloom-7b1        None  \n",
       " 2        0.150396          0.157397  3  bloom-7b1        None  \n",
       " 3        0.150729          0.159432  3  bloom-7b1        None  \n",
       " 4        0.152639          0.160005  3  bloom-7b1        None  ,\n",
       " 'bloom-7b1-1-shot-replaceName':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.291731        0.258588          0.247120   \n",
       " 1       1           0.299704        0.271996          0.256665   \n",
       " 2       2           0.304971        0.267698          0.256013   \n",
       " 3       3           0.300827        0.263669          0.252676   \n",
       " 4       4           0.298546        0.253333          0.247425   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.059362        0.054407          0.050501           0.215623   \n",
       " 1           0.056973        0.050927          0.047431           0.222060   \n",
       " 2           0.064365        0.055467          0.052366           0.227901   \n",
       " 3           0.061820        0.054576          0.051548           0.224191   \n",
       " 4           0.055839        0.052136          0.048198           0.220071   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.191292          0.182351  1  bloom-7b1        None  \n",
       " 1        0.198611          0.188293  1  bloom-7b1        None  \n",
       " 2        0.199119          0.190616  1  bloom-7b1        None  \n",
       " 3        0.196833          0.187792  1  bloom-7b1        None  \n",
       " 4        0.188078          0.182315  1  bloom-7b1        None  ,\n",
       " 'opt-1.3b-3-shot-replaceName':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.231567        0.199303          0.190226   \n",
       " 1       1           0.230676        0.209463          0.195034   \n",
       " 2       2           0.227765        0.188492          0.186896   \n",
       " 3       3                NaN             NaN               NaN   \n",
       " 4       4                NaN             NaN               NaN   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.046095        0.037275          0.036113           0.180896   \n",
       " 1           0.042364        0.036692          0.034183           0.175981   \n",
       " 2           0.040954        0.031838          0.032464           0.174677   \n",
       " 3                NaN             NaN               NaN                NaN   \n",
       " 4                NaN             NaN               NaN                NaN   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.154933          0.147447  3   opt-1.3b        None  \n",
       " 1        0.159199          0.147465  3   opt-1.3b        None  \n",
       " 2        0.142202          0.141357  3   opt-1.3b        None  \n",
       " 3             NaN               NaN  3   opt-1.3b        None  \n",
       " 4             NaN               NaN  3   opt-1.3b        None  ,\n",
       " 'opt-1.3b-2-shot-nameReplace':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.217621        0.202503          0.184413   \n",
       " 1       1                NaN             NaN               NaN   \n",
       " 2       2                NaN             NaN               NaN   \n",
       " 3       3                NaN             NaN               NaN   \n",
       " 4       4                NaN             NaN               NaN   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.036415        0.035917          0.031067            0.16125   \n",
       " 1                NaN             NaN               NaN                NaN   \n",
       " 2                NaN             NaN               NaN                NaN   \n",
       " 3                NaN             NaN               NaN                NaN   \n",
       " 4                NaN             NaN               NaN                NaN   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.147084           0.13449  2   opt-1.3b        None  \n",
       " 1             NaN               NaN  2   opt-1.3b        None  \n",
       " 2             NaN               NaN  2   opt-1.3b        None  \n",
       " 3             NaN               NaN  2   opt-1.3b        None  \n",
       " 4             NaN               NaN  2   opt-1.3b        None  ,\n",
       " 'opt-1.3b-1-shot-nameReplace':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.195177        0.189286          0.168848   \n",
       " 1       1           0.203782        0.187453          0.173669   \n",
       " 2       2           0.189895        0.183415          0.163945   \n",
       " 3       3           0.196802        0.186784          0.166595   \n",
       " 4       4           0.206649        0.193378          0.176147   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.032127        0.030397          0.027249           0.151540   \n",
       " 1           0.032655        0.030271          0.027553           0.156549   \n",
       " 2           0.028751        0.029009          0.024614           0.143481   \n",
       " 3           0.029624        0.028190          0.024298           0.147107   \n",
       " 4           0.033036        0.029530          0.026802           0.156853   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.145147          0.129691  1   opt-1.3b        None  \n",
       " 1        0.142330          0.131819  1   opt-1.3b        None  \n",
       " 2        0.137936          0.122874  1   opt-1.3b        None  \n",
       " 3        0.137963          0.122686  1   opt-1.3b        None  \n",
       " 4        0.144529          0.131940  1   opt-1.3b        None  ,\n",
       " 'bloom-7b1-3-shot-length':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.438901        0.312434          0.334451   \n",
       " 1       1           0.433166        0.307045          0.328038   \n",
       " 2       2           0.438006        0.305807          0.331012   \n",
       " 3       3           0.440333        0.309465          0.335587   \n",
       " 4       4           0.435704        0.301191          0.324263   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.105452        0.073608          0.078724           0.318203   \n",
       " 1           0.104548        0.071085          0.076418           0.314063   \n",
       " 2           0.107324        0.070414          0.077194           0.319422   \n",
       " 3           0.109338        0.074108          0.080951           0.322748   \n",
       " 4           0.104693        0.071036          0.076016           0.319197   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.223767          0.240212  3  bloom-7b1        None  \n",
       " 1        0.219252          0.235095  3  bloom-7b1        None  \n",
       " 2        0.218323          0.237736  3  bloom-7b1        None  \n",
       " 3        0.223018          0.242868  3  bloom-7b1        None  \n",
       " 4        0.216387          0.234086  3  bloom-7b1        None  ,\n",
       " 'Cerebras-GPT-13B-1-shot-3-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.472062        0.348218          0.365830   \n",
       " 1       1           0.475901        0.350671          0.369215   \n",
       " 2       2           0.472641        0.348052          0.362142   \n",
       " 3       3           0.466234        0.334222          0.352867   \n",
       " 4       4           0.469540        0.343011          0.359729   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.133559        0.097295          0.101327           0.350840   \n",
       " 1           0.137219        0.094734          0.101190           0.355314   \n",
       " 2           0.131944        0.092370          0.096102           0.351353   \n",
       " 3           0.132242        0.089664          0.095138           0.347916   \n",
       " 4           0.127692        0.091312          0.095183           0.347627   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k        model_name keyword_num  \n",
       " 0        0.255698          0.268645  1  Cerebras-GPT-13B           3  \n",
       " 1        0.258511          0.272681  1  Cerebras-GPT-13B           3  \n",
       " 2        0.254847          0.265475  1  Cerebras-GPT-13B           3  \n",
       " 3        0.246063          0.260205  1  Cerebras-GPT-13B           3  \n",
       " 4        0.252298          0.264324  1  Cerebras-GPT-13B           3  ,\n",
       " 'bloom-7b1-2-shot-length':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.429556        0.312477          0.332673   \n",
       " 1       1           0.423776        0.311407          0.328138   \n",
       " 2       2           0.424560        0.316099          0.332536   \n",
       " 3       3           0.425168        0.312894          0.324819   \n",
       " 4       4           0.422583        0.307173          0.325142   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.107492        0.074491          0.080365           0.317878   \n",
       " 1           0.105055        0.074041          0.078765           0.313707   \n",
       " 2           0.105735        0.079476          0.083447           0.312031   \n",
       " 3           0.100886        0.073636          0.075256           0.314865   \n",
       " 4           0.103561        0.072241          0.077107           0.314274   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.226745          0.242893  2  bloom-7b1        None  \n",
       " 1        0.225347          0.239249  2  bloom-7b1        None  \n",
       " 2        0.230067          0.242719  2  bloom-7b1        None  \n",
       " 3        0.228398          0.238136  2  bloom-7b1        None  \n",
       " 4        0.223935          0.238152  2  bloom-7b1        None  ,\n",
       " 'bloom-7b1-1-shot-length':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.401186        0.319690          0.324593   \n",
       " 1       1           0.402655        0.325146          0.328996   \n",
       " 2       2           0.401962        0.325977          0.328299   \n",
       " 3       3           0.403275        0.320601          0.325416   \n",
       " 4       4           0.411699        0.329038          0.336160   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.100478        0.074815          0.077111           0.300218   \n",
       " 1           0.099142        0.076861          0.078181           0.300400   \n",
       " 2           0.098951        0.079674          0.079337           0.303757   \n",
       " 3           0.098865        0.075924          0.077094           0.299083   \n",
       " 4           0.104536        0.082901          0.084237           0.307234   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.235166          0.239799  1  bloom-7b1        None  \n",
       " 1        0.239684          0.243249  1  bloom-7b1        None  \n",
       " 2        0.242544          0.245180  1  bloom-7b1        None  \n",
       " 3        0.235205          0.238779  1  bloom-7b1        None  \n",
       " 4        0.242278          0.248125  1  bloom-7b1        None  ,\n",
       " 'opt-1.3b-2-shot-2-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.411068        0.325161          0.326267   \n",
       " 1       1           0.411989        0.327841          0.325985   \n",
       " 2       2           0.414899        0.331845          0.332545   \n",
       " 3       3           0.409317        0.320139          0.324256   \n",
       " 4       4           0.411531        0.327745          0.326595   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.100922        0.076259          0.077004           0.306724   \n",
       " 1           0.102619        0.078408          0.078004           0.306299   \n",
       " 2           0.100465        0.077341          0.078445           0.310802   \n",
       " 3           0.104925        0.077573          0.079589           0.309660   \n",
       " 4           0.100888        0.077868          0.077740           0.304998   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.238167          0.240255  2   opt-1.3b           2  \n",
       " 1        0.238706          0.238158  2   opt-1.3b           2  \n",
       " 2        0.244613          0.246388  2   opt-1.3b           2  \n",
       " 3        0.237774          0.241932  2   opt-1.3b           2  \n",
       " 4        0.240492          0.239609  2   opt-1.3b           2  ,\n",
       " 'opt-1.3b-2-shot-1-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.388047        0.301939          0.304455   \n",
       " 1       1           0.395489        0.304137          0.306313   \n",
       " 2       2           0.393260        0.302360          0.306365   \n",
       " 3       3           0.387257        0.308156          0.307279   \n",
       " 4       4           0.398146        0.308393          0.312065   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.086681        0.062964          0.064290           0.290688   \n",
       " 1           0.093192        0.068674          0.068581           0.291149   \n",
       " 2           0.088826        0.064383          0.065937           0.291193   \n",
       " 3           0.087817        0.067556          0.067100           0.288996   \n",
       " 4           0.090405        0.068868          0.068559           0.292714   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.222508          0.225151  2   opt-1.3b           1  \n",
       " 1        0.219820          0.221510  2   opt-1.3b           1  \n",
       " 2        0.220466          0.224161  2   opt-1.3b           1  \n",
       " 3        0.226753          0.226297  2   opt-1.3b           1  \n",
       " 4        0.223950          0.226761  2   opt-1.3b           1  ,\n",
       " 'opt-1.3b-2-shot-3-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.430354        0.333588          0.337743   \n",
       " 1       1           0.428178        0.327681          0.334539   \n",
       " 2       2           0.431579        0.325393          0.336297   \n",
       " 3       3           0.424600        0.327982          0.334560   \n",
       " 4       4           0.428077        0.328522          0.335768   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.114209        0.082418          0.085491           0.320617   \n",
       " 1           0.113635        0.083067          0.084968           0.317674   \n",
       " 2           0.109628        0.077503          0.081496           0.322612   \n",
       " 3           0.107663        0.080064          0.082178           0.317699   \n",
       " 4           0.114327        0.082793          0.085328           0.321660   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.242646          0.247280  2   opt-1.3b           3  \n",
       " 1        0.237869          0.243843  2   opt-1.3b           3  \n",
       " 2        0.237470          0.247301  2   opt-1.3b           3  \n",
       " 3        0.241978          0.246992  2   opt-1.3b           3  \n",
       " 4        0.241543          0.248229  2   opt-1.3b           3  ,\n",
       " 'opt-1.3b-3-shot-length':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.382558        0.311854          0.313209   \n",
       " 1       1           0.380067        0.313511          0.313707   \n",
       " 2       2           0.381380        0.318181          0.316544   \n",
       " 3       3           0.421736        0.231468          0.268380   \n",
       " 4       4                NaN             NaN               NaN   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.083690        0.067239          0.066924           0.281710   \n",
       " 1           0.085084        0.066985          0.067736           0.278620   \n",
       " 2           0.086638        0.071446          0.070427           0.279778   \n",
       " 3           0.102251        0.037278          0.050526           0.316038   \n",
       " 4                NaN             NaN               NaN                NaN   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.226596          0.228060  3   opt-1.3b        None  \n",
       " 1        0.224335          0.226172  3   opt-1.3b        None  \n",
       " 2        0.229391          0.229185  3   opt-1.3b        None  \n",
       " 3        0.169447          0.196115  3   opt-1.3b        None  \n",
       " 4             NaN               NaN  3   opt-1.3b        None  ,\n",
       " 'opt-1.3b-2-shot-length':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.386187        0.308276          0.311598   \n",
       " 1       1           0.379722        0.301663          0.303473   \n",
       " 2       2           0.376374        0.293297          0.299842   \n",
       " 3       3           0.384925        0.316017          0.315877   \n",
       " 4       4           0.376316        0.298608          0.303202   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.082305        0.063124          0.063947           0.284481   \n",
       " 1           0.087292        0.066268          0.066605           0.278403   \n",
       " 2           0.079224        0.056710          0.059675           0.274674   \n",
       " 3           0.087910        0.069677          0.069727           0.283287   \n",
       " 4           0.081209        0.060748          0.063074           0.273621   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.222725          0.226254  2   opt-1.3b        None  \n",
       " 1        0.215855          0.218549  2   opt-1.3b        None  \n",
       " 2        0.211686          0.216926  2   opt-1.3b        None  \n",
       " 3        0.229256          0.229705  2   opt-1.3b        None  \n",
       " 4        0.213095          0.217492  2   opt-1.3b        None  ,\n",
       " 'opt-1.3b-1-shot-length':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.353653        0.296266          0.285902   \n",
       " 1       1           0.346009        0.297758          0.285832   \n",
       " 2       2           0.357421        0.296640          0.291690   \n",
       " 3       3           0.349658        0.297806          0.287622   \n",
       " 4       4           0.357119        0.301534          0.297975   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.072855        0.063394          0.058485           0.260150   \n",
       " 1           0.069553        0.057941          0.055939           0.255681   \n",
       " 2           0.072756        0.062713          0.059768           0.265378   \n",
       " 3           0.071726        0.058833          0.056699           0.260906   \n",
       " 4           0.067816        0.057551          0.055673           0.263273   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.217028          0.208541  1   opt-1.3b        None  \n",
       " 1        0.216442          0.208620  1   opt-1.3b        None  \n",
       " 2        0.217142          0.214246  1   opt-1.3b        None  \n",
       " 3        0.218240          0.212023  1   opt-1.3b        None  \n",
       " 4        0.220341          0.217873  1   opt-1.3b        None  ,\n",
       " 'alpaca-native-3-shot-2-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.423605        0.343228          0.354063   \n",
       " 1       1           0.420074        0.348680          0.354579   \n",
       " 2       2           0.424542        0.340153          0.353626   \n",
       " 3       3           0.425027        0.339136          0.353847   \n",
       " 4       4           0.420368        0.343746          0.350664   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.108497        0.086862          0.089312           0.320339   \n",
       " 1           0.106489        0.087260          0.088851           0.318842   \n",
       " 2           0.106058        0.083061          0.086444           0.320707   \n",
       " 3           0.110602        0.085595          0.089941           0.322678   \n",
       " 4           0.113567        0.088016          0.090944           0.320804   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k     model_name keyword_num  \n",
       " 0        0.255847          0.265138  3  alpaca-native           2  \n",
       " 1        0.260453          0.266128  3  alpaca-native           2  \n",
       " 2        0.253477          0.264893  3  alpaca-native           2  \n",
       " 3        0.252766          0.265359  3  alpaca-native           2  \n",
       " 4        0.257576          0.264723  3  alpaca-native           2  ,\n",
       " 'opt-1.3b-1-shot-3-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.408094        0.326911          0.325425   \n",
       " 1       1           0.408041        0.322139          0.321705   \n",
       " 2       2           0.401270        0.323653          0.320828   \n",
       " 3       3           0.405445        0.327007          0.321014   \n",
       " 4       4           0.405911        0.333203          0.329895   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.103238        0.079465          0.079212           0.300660   \n",
       " 1           0.097870        0.071589          0.072560           0.303933   \n",
       " 2           0.097584        0.074993          0.074859           0.304050   \n",
       " 3           0.107235        0.078602          0.078642           0.307320   \n",
       " 4           0.098894        0.078967          0.077380           0.303082   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.239588          0.237621  1   opt-1.3b           3  \n",
       " 1        0.235769          0.235806  1   opt-1.3b           3  \n",
       " 2        0.241570          0.240208  1   opt-1.3b           3  \n",
       " 3        0.240759          0.238602  1   opt-1.3b           3  \n",
       " 4        0.246533          0.244155  1   opt-1.3b           3  ,\n",
       " 'opt-1.3b-1-shot-2-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.381121        0.317536          0.308093   \n",
       " 1       1           0.380200        0.317744          0.307612   \n",
       " 2       2           0.378965        0.316557          0.308230   \n",
       " 3       3           0.383364        0.327784          0.314305   \n",
       " 4       4           0.388846        0.321787          0.315635   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.089589        0.073434          0.069839           0.283973   \n",
       " 1           0.089506        0.069705          0.068093           0.284389   \n",
       " 2           0.092883        0.072128          0.071924           0.288795   \n",
       " 3           0.093273        0.074070          0.072203           0.285397   \n",
       " 4           0.094054        0.074571          0.073241           0.289229   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.234665          0.227175  1   opt-1.3b           2  \n",
       " 1        0.232384          0.225553  1   opt-1.3b           2  \n",
       " 2        0.235963          0.231395  1   opt-1.3b           2  \n",
       " 3        0.241776          0.231805  1   opt-1.3b           2  \n",
       " 4        0.237815          0.232375  1   opt-1.3b           2  ,\n",
       " 'opt-1.3b-1-shot-1-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.361618        0.310404          0.294118   \n",
       " 1       1           0.361158        0.302857          0.290725   \n",
       " 2       2           0.358197        0.303773          0.291849   \n",
       " 3       3           0.354806        0.299709          0.288360   \n",
       " 4       4           0.363272        0.306436          0.297581   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.079708        0.067002          0.062723           0.266931   \n",
       " 1           0.073949        0.061813          0.057838           0.267070   \n",
       " 2           0.079020        0.063684          0.061260           0.267972   \n",
       " 3           0.075429        0.057752          0.056548           0.264077   \n",
       " 4           0.079440        0.064793          0.062580           0.271861   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.228650          0.215207  1   opt-1.3b           1  \n",
       " 1        0.222083          0.212393  1   opt-1.3b           1  \n",
       " 2        0.224287          0.215772  1   opt-1.3b           1  \n",
       " 3        0.220204          0.211707  1   opt-1.3b           1  \n",
       " 4        0.225919          0.219611  1   opt-1.3b           1  ,\n",
       " 'alpaca-native-3-shot-1-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.411425        0.327318          0.339007   \n",
       " 1       1           0.405448        0.329611          0.337156   \n",
       " 2       2           0.406546        0.328104          0.338419   \n",
       " 3       3           0.407739        0.326661          0.339002   \n",
       " 4       4           0.402588        0.327004          0.333841   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.097664        0.076344          0.078645           0.308097   \n",
       " 1           0.092648        0.076360          0.076977           0.300727   \n",
       " 2           0.093592        0.072926          0.075490           0.304619   \n",
       " 3           0.095169        0.074776          0.077751           0.302860   \n",
       " 4           0.092922        0.072163          0.073852           0.297974   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k     model_name keyword_num  \n",
       " 0        0.241510          0.251365  3  alpaca-native           1  \n",
       " 1        0.241673          0.248077  3  alpaca-native           1  \n",
       " 2        0.243281          0.251365  3  alpaca-native           1  \n",
       " 3        0.239683          0.249241  3  alpaca-native           1  \n",
       " 4        0.240600          0.245428  3  alpaca-native           1  ,\n",
       " 'Cerebras-GPT-13B-1-shot-2-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.456728        0.335606          0.353602   \n",
       " 1       1           0.462411        0.336997          0.354939   \n",
       " 2       2           0.456381        0.331778          0.348181   \n",
       " 3       3           0.457336        0.329826          0.349063   \n",
       " 4       4           0.459980        0.334219          0.353033   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.123323        0.091224          0.094439           0.338037   \n",
       " 1           0.123168        0.083292          0.089777           0.342658   \n",
       " 2           0.121474        0.082788          0.087811           0.335382   \n",
       " 3           0.118283        0.081901          0.086932           0.333532   \n",
       " 4           0.122786        0.086704          0.091838           0.340941   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k        model_name keyword_num  \n",
       " 0        0.245924          0.258832  1  Cerebras-GPT-13B           2  \n",
       " 1        0.245412          0.259806  1  Cerebras-GPT-13B           2  \n",
       " 2        0.239781          0.252245  1  Cerebras-GPT-13B           2  \n",
       " 3        0.237493          0.252069  1  Cerebras-GPT-13B           2  \n",
       " 4        0.245097          0.259082  1  Cerebras-GPT-13B           2  ,\n",
       " 'Cerebras-GPT-13B-1-shot-1-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.448598        0.318592          0.338705   \n",
       " 1       1           0.446369        0.323045          0.339997   \n",
       " 2       2           0.438992        0.313095          0.329654   \n",
       " 3       3           0.444747        0.308875          0.331600   \n",
       " 4       4           0.446409        0.313842          0.334530   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.116242        0.079836          0.084635           0.329852   \n",
       " 1           0.108863        0.074991          0.079863           0.326088   \n",
       " 2           0.109097        0.073279          0.077451           0.323923   \n",
       " 3           0.107018        0.073239          0.077766           0.322523   \n",
       " 4           0.105493        0.072084          0.076665           0.327145   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k        model_name keyword_num  \n",
       " 0        0.229838          0.245443  1  Cerebras-GPT-13B           1  \n",
       " 1        0.233260          0.245806  1  Cerebras-GPT-13B           1  \n",
       " 2        0.226866          0.239352  1  Cerebras-GPT-13B           1  \n",
       " 3        0.220505          0.237084  1  Cerebras-GPT-13B           1  \n",
       " 4        0.226395          0.242121  1  Cerebras-GPT-13B           1  ,\n",
       " 'Cerebras-GPT-13B-3-shot-2-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.494704        0.295398          0.343796   \n",
       " 1       1           0.507223        0.303709          0.352811   \n",
       " 2       2           0.494568        0.302664          0.348037   \n",
       " 3       3           0.583543        0.351181          0.395579   \n",
       " 4       4                NaN             NaN               NaN   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.132576        0.073050          0.086919           0.359377   \n",
       " 1           0.142510        0.078962          0.093326           0.370179   \n",
       " 2           0.139524        0.080512          0.093288           0.365025   \n",
       " 3           0.171861        0.107436          0.116114           0.433369   \n",
       " 4                NaN             NaN               NaN                NaN   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k        model_name keyword_num  \n",
       " 0        0.207614          0.244150  3  Cerebras-GPT-13B           2  \n",
       " 1        0.215908          0.252751  3  Cerebras-GPT-13B           2  \n",
       " 2        0.217860          0.252034  3  Cerebras-GPT-13B           2  \n",
       " 3        0.257985          0.290892  3  Cerebras-GPT-13B           2  \n",
       " 4             NaN               NaN  3  Cerebras-GPT-13B           2  ,\n",
       " 'alpaca-native-2-shot-2-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.423500        0.346103          0.355348   \n",
       " 1       1           0.422885        0.346524          0.354936   \n",
       " 2       2           0.415958        0.347254          0.353002   \n",
       " 3       3           0.418953        0.350862          0.356101   \n",
       " 4       4           0.422071        0.341657          0.353022   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.109313        0.089062          0.090590           0.316514   \n",
       " 1           0.116252        0.097051          0.097289           0.319450   \n",
       " 2           0.103470        0.086301          0.087248           0.316553   \n",
       " 3           0.107071        0.088824          0.089603           0.315153   \n",
       " 4           0.112747        0.087309          0.091648           0.320283   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k     model_name keyword_num  \n",
       " 0        0.257376          0.264194  2  alpaca-native           2  \n",
       " 1        0.260764          0.266678  2  alpaca-native           2  \n",
       " 2        0.260270          0.265778  2  alpaca-native           2  \n",
       " 3        0.261544          0.265964  2  alpaca-native           2  \n",
       " 4        0.256379          0.265759  2  alpaca-native           2  ,\n",
       " 'Cerebras-GPT-13B-3-shot-3-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.513796        0.306455          0.357381   \n",
       " 1       1           0.514037        0.309280          0.360459   \n",
       " 2       2           0.511010        0.312495          0.360471   \n",
       " 3       3           0.475776        0.257172          0.310530   \n",
       " 4       4                NaN             NaN               NaN   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.146639        0.078965          0.094695           0.376463   \n",
       " 1           0.148073        0.081707          0.097458           0.376302   \n",
       " 2           0.148140        0.085841          0.100036           0.376882   \n",
       " 3           0.093506        0.047866          0.058364           0.361727   \n",
       " 4                NaN             NaN               NaN                NaN   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k        model_name keyword_num  \n",
       " 0        0.216958          0.255731  3  Cerebras-GPT-13B           3  \n",
       " 1        0.220545          0.258789  3  Cerebras-GPT-13B           3  \n",
       " 2        0.224232          0.260728  3  Cerebras-GPT-13B           3  \n",
       " 3        0.186187          0.227833  3  Cerebras-GPT-13B           3  \n",
       " 4             NaN               NaN  3  Cerebras-GPT-13B           3  ,\n",
       " 'llama-7b-hf-2-shot-2-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.466144        0.298770          0.340999   \n",
       " 1       1           0.453087        0.301025          0.335817   \n",
       " 2       2           0.460844        0.296297          0.337227   \n",
       " 3       3           0.460424        0.299554          0.338870   \n",
       " 4       4           0.462219        0.294090          0.336721   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.126977        0.079004          0.090379           0.349937   \n",
       " 1           0.125704        0.080823          0.089904           0.340495   \n",
       " 2           0.121492        0.074922          0.086128           0.344301   \n",
       " 3           0.125009        0.077539          0.088436           0.347194   \n",
       " 4           0.125854        0.076424          0.088112           0.346386   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k   model_name keyword_num  \n",
       " 0        0.218900          0.251646  2  llama-7b-hf           2  \n",
       " 1        0.222063          0.248616  2  llama-7b-hf           2  \n",
       " 2        0.216687          0.248197  2  llama-7b-hf           2  \n",
       " 3        0.221601          0.251881  2  llama-7b-hf           2  \n",
       " 4        0.217256          0.249414  2  llama-7b-hf           2  ,\n",
       " 'opt-1.3b-3-shot':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.374400        0.327483          0.307189   \n",
       " 1       1           0.375047        0.328875          0.311868   \n",
       " 2       2           0.375237        0.336720          0.317863   \n",
       " 3       3           0.287079        0.297745          0.258769   \n",
       " 4       4                NaN             NaN               NaN   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.088375        0.073061          0.068896           0.283734   \n",
       " 1           0.082751        0.070769          0.066793           0.280105   \n",
       " 2           0.092419        0.079588          0.075218           0.285714   \n",
       " 3           0.026190        0.052500          0.034804           0.254213   \n",
       " 4                NaN             NaN               NaN                NaN   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.243324          0.229688  3   opt-1.3b        None  \n",
       " 1        0.241350          0.230012  3   opt-1.3b        None  \n",
       " 2        0.250079          0.238161  3   opt-1.3b        None  \n",
       " 3        0.253382          0.225436  3   opt-1.3b        None  \n",
       " 4             NaN               NaN  3   opt-1.3b        None  ,\n",
       " 'opt-1.3b-2-shot':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.371891        0.318963          0.305973   \n",
       " 1       1           0.376002        0.325521          0.305723   \n",
       " 2       2           0.374511        0.318892          0.305678   \n",
       " 3       3           0.375457        0.322239          0.309910   \n",
       " 4       4           0.376971        0.317872          0.306052   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.081518        0.066900          0.064350           0.278276   \n",
       " 1           0.087116        0.072914          0.067956           0.282538   \n",
       " 2           0.083637        0.066107          0.064540           0.279534   \n",
       " 3           0.080483        0.068450          0.065447           0.281522   \n",
       " 4           0.084676        0.068755          0.066603           0.281973   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.233217          0.225557  2   opt-1.3b        None  \n",
       " 1        0.238478          0.225270  2   opt-1.3b        None  \n",
       " 2        0.232241          0.224274  2   opt-1.3b        None  \n",
       " 3        0.236827          0.228748  2   opt-1.3b        None  \n",
       " 4        0.232246          0.224902  2   opt-1.3b        None  ,\n",
       " 'opt-1.3b-1-shot':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.352868        0.311211          0.291734   \n",
       " 1       1           0.345888        0.309088          0.285479   \n",
       " 2       2           0.346354        0.309306          0.286307   \n",
       " 3       3           0.348034        0.309475          0.288476   \n",
       " 4       4           0.354224        0.315390          0.295711   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.075431        0.064328          0.060231           0.261468   \n",
       " 1           0.067757        0.058459          0.053416           0.256259   \n",
       " 2           0.070934        0.060118          0.056207           0.261357   \n",
       " 3           0.069841        0.061295          0.056186           0.257781   \n",
       " 4           0.071391        0.063658          0.059011           0.267418   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.226973          0.213016  1   opt-1.3b        None  \n",
       " 1        0.224527          0.207736  1   opt-1.3b        None  \n",
       " 2        0.229151          0.213384  1   opt-1.3b        None  \n",
       " 3        0.226047          0.211328  1   opt-1.3b        None  \n",
       " 4        0.234258          0.220806  1   opt-1.3b        None  ,\n",
       " 'alpaca-native-2-shot-1-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.403914        0.327718          0.334668   \n",
       " 1       1           0.399964        0.316831          0.327499   \n",
       " 2       2           0.404935        0.332414          0.339501   \n",
       " 3       3           0.395144        0.333148          0.334081   \n",
       " 4       4           0.404295        0.321926          0.333203   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.094946        0.076953          0.077105           0.304154   \n",
       " 1           0.092546        0.071055          0.074126           0.300315   \n",
       " 2           0.096730        0.079319          0.081015           0.304149   \n",
       " 3           0.093291        0.077668          0.078356           0.297427   \n",
       " 4           0.094071        0.069786          0.073913           0.304241   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k     model_name keyword_num  \n",
       " 0        0.244820          0.249604  2  alpaca-native           1  \n",
       " 1        0.234738          0.243632  2  alpaca-native           1  \n",
       " 2        0.247312          0.253275  2  alpaca-native           1  \n",
       " 3        0.248405          0.249310  2  alpaca-native           1  \n",
       " 4        0.238666          0.247885  2  alpaca-native           1  ,\n",
       " 'Cerebras-GPT-13B-3-shot-1-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.484851        0.281648          0.330095   \n",
       " 1       1           0.489058        0.282758          0.333538   \n",
       " 2       2           0.488837        0.286705          0.336252   \n",
       " 3       3           0.526466        0.246727          0.304172   \n",
       " 4       4                NaN             NaN               NaN   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.123341        0.066444          0.079559           0.350601   \n",
       " 1           0.123508        0.067484          0.080726           0.352794   \n",
       " 2           0.128619        0.070168          0.083569           0.357256   \n",
       " 3           0.145671        0.056402          0.073315           0.421903   \n",
       " 4                NaN             NaN               NaN                NaN   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k        model_name keyword_num  \n",
       " 0        0.195856          0.232430  3  Cerebras-GPT-13B           1  \n",
       " 1        0.198967          0.236247  3  Cerebras-GPT-13B           1  \n",
       " 2        0.203434          0.240475  3  Cerebras-GPT-13B           1  \n",
       " 3        0.200169          0.246379  3  Cerebras-GPT-13B           1  \n",
       " 4             NaN               NaN  3  Cerebras-GPT-13B           1  ,\n",
       " 'alpaca-native-1-shot-1-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.397515        0.320673          0.329006   \n",
       " 1       1           0.402054        0.328378          0.332290   \n",
       " 2       2           0.404990        0.323397          0.332453   \n",
       " 3       3           0.395861        0.314500          0.323878   \n",
       " 4       4           0.393247        0.318109          0.325550   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.093281        0.074032          0.075907           0.297325   \n",
       " 1           0.096704        0.075554          0.076675           0.302806   \n",
       " 2           0.098340        0.072426          0.076320           0.304437   \n",
       " 3           0.091774        0.070578          0.072891           0.294941   \n",
       " 4           0.094145        0.074692          0.076209           0.292885   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k     model_name keyword_num  \n",
       " 0        0.239276          0.244744  1  alpaca-native           1  \n",
       " 1        0.245673          0.248241  1  alpaca-native           1  \n",
       " 2        0.238652          0.246404  1  alpaca-native           1  \n",
       " 3        0.231994          0.239254  1  alpaca-native           1  \n",
       " 4        0.234336          0.240036  1  alpaca-native           1  ,\n",
       " 'Cerebras-GPT-2.7B-3-shot-3-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.489312        0.274281          0.324928   \n",
       " 1       1           0.492775        0.271066          0.324727   \n",
       " 2       2           0.481503        0.265692          0.319168   \n",
       " 3       3                NaN             NaN               NaN   \n",
       " 4       4                NaN             NaN               NaN   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.134625        0.068470          0.082549           0.359682   \n",
       " 1           0.129931        0.065405          0.079650           0.361264   \n",
       " 2           0.120060        0.059919          0.074026           0.348515   \n",
       " 3                NaN             NaN               NaN                NaN   \n",
       " 4                NaN             NaN               NaN                NaN   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k         model_name keyword_num  \n",
       " 0        0.194908          0.232903  3  Cerebras-GPT-2.7B           3  \n",
       " 1        0.192566          0.232547  3  Cerebras-GPT-2.7B           3  \n",
       " 2        0.187383          0.226731  3  Cerebras-GPT-2.7B           3  \n",
       " 3             NaN               NaN  3  Cerebras-GPT-2.7B           3  \n",
       " 4             NaN               NaN  3  Cerebras-GPT-2.7B           3  ,\n",
       " 'Cerebras-GPT-2.7B-2-shot-3-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.481644        0.281560          0.326559   \n",
       " 1       1           0.477881        0.272848          0.320258   \n",
       " 2       2           0.479794        0.279556          0.325553   \n",
       " 3       3           0.475515        0.277485          0.323420   \n",
       " 4       4           0.481757        0.273997          0.323321   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.122696        0.068901          0.079992           0.353689   \n",
       " 1           0.125929        0.066172          0.078490           0.351664   \n",
       " 2           0.121715        0.067636          0.079516           0.351231   \n",
       " 3           0.123677        0.067562          0.080071           0.349052   \n",
       " 4           0.128917        0.066701          0.080709           0.352653   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k         model_name keyword_num  \n",
       " 0        0.201260          0.234915  2  Cerebras-GPT-2.7B           3  \n",
       " 1        0.193895          0.229567  2  Cerebras-GPT-2.7B           3  \n",
       " 2        0.198688          0.233185  2  Cerebras-GPT-2.7B           3  \n",
       " 3        0.197374          0.232106  2  Cerebras-GPT-2.7B           3  \n",
       " 4        0.193960          0.231047  2  Cerebras-GPT-2.7B           3  ,\n",
       " 'Cerebras-GPT-2.7B-1-shot-3-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.447959        0.291356          0.321341   \n",
       " 1       1           0.453486        0.286132          0.317598   \n",
       " 2       2           0.454327        0.289453          0.321366   \n",
       " 3       3           0.456732        0.286932          0.321089   \n",
       " 4       4           0.452005        0.285621          0.319754   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.118976        0.072346          0.080920           0.331799   \n",
       " 1           0.118236        0.068884          0.078415           0.334082   \n",
       " 2           0.121590        0.073650          0.081604           0.336357   \n",
       " 3           0.116587        0.068612          0.077459           0.334624   \n",
       " 4           0.112801        0.067159          0.076516           0.333254   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k         model_name keyword_num  \n",
       " 0        0.211341          0.233968  1  Cerebras-GPT-2.7B           3  \n",
       " 1        0.206614          0.230081  1  Cerebras-GPT-2.7B           3  \n",
       " 2        0.209569          0.233574  1  Cerebras-GPT-2.7B           3  \n",
       " 3        0.205345          0.231313  1  Cerebras-GPT-2.7B           3  \n",
       " 4        0.205220          0.231167  1  Cerebras-GPT-2.7B           3  ,\n",
       " 'Cerebras-GPT-2.7B-3-shot-2-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.476851        0.260096          0.311606   \n",
       " 1       1           0.481116        0.262024          0.313694   \n",
       " 2       2           0.474190        0.263062          0.313749   \n",
       " 3       3           0.416925        0.216929          0.253486   \n",
       " 4       4                NaN             NaN               NaN   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.124656        0.062169          0.076103           0.348500   \n",
       " 1           0.124063        0.063001          0.076394           0.352047   \n",
       " 2           0.109422        0.059181          0.070345           0.342801   \n",
       " 3           0.118442        0.056149          0.068348           0.325163   \n",
       " 4                NaN             NaN               NaN                NaN   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k         model_name keyword_num  \n",
       " 0        0.183402          0.221972  3  Cerebras-GPT-2.7B           2  \n",
       " 1        0.184808          0.223413  3  Cerebras-GPT-2.7B           2  \n",
       " 2        0.183433          0.220956  3  Cerebras-GPT-2.7B           2  \n",
       " 3        0.161192          0.192659  3  Cerebras-GPT-2.7B           2  \n",
       " 4             NaN               NaN  3  Cerebras-GPT-2.7B           2  ,\n",
       " 'Cerebras-GPT-2.7B-2-shot-2-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.463492        0.269188          0.313328   \n",
       " 1       1           0.461331        0.269492          0.311817   \n",
       " 2       2           0.457097        0.265792          0.308351   \n",
       " 3       3           0.450648        0.273809          0.313513   \n",
       " 4       4           0.468898        0.264589          0.312275   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.112922        0.063496          0.074071           0.337782   \n",
       " 1           0.118268        0.064295          0.074940           0.335354   \n",
       " 2           0.111745        0.061384          0.071797           0.335416   \n",
       " 3           0.107843        0.061900          0.072152           0.324644   \n",
       " 4           0.117639        0.060936          0.073704           0.341513   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k         model_name keyword_num  \n",
       " 0        0.190561          0.223266  2  Cerebras-GPT-2.7B           2  \n",
       " 1        0.190925          0.222079  2  Cerebras-GPT-2.7B           2  \n",
       " 2        0.188329          0.220429  2  Cerebras-GPT-2.7B           2  \n",
       " 3        0.191606          0.221104  2  Cerebras-GPT-2.7B           2  \n",
       " 4        0.187751          0.223054  2  Cerebras-GPT-2.7B           2  ,\n",
       " 'Cerebras-GPT-2.7B-1-shot-2-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.426436        0.278948          0.306484   \n",
       " 1       1           0.434452        0.283396          0.312771   \n",
       " 2       2           0.431373        0.281450          0.308462   \n",
       " 3       3           0.430620        0.274749          0.304906   \n",
       " 4       4           0.437606        0.278668          0.309295   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.104023        0.063230          0.070644           0.313392   \n",
       " 1           0.105732        0.065861          0.073229           0.317152   \n",
       " 2           0.105559        0.063543          0.070089           0.317202   \n",
       " 3           0.106374        0.061309          0.070002           0.316029   \n",
       " 4           0.105410        0.063910          0.071472           0.319363   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k         model_name keyword_num  \n",
       " 0        0.199056          0.220361  1  Cerebras-GPT-2.7B           2  \n",
       " 1        0.202051          0.224176  1  Cerebras-GPT-2.7B           2  \n",
       " 2        0.203065          0.222774  1  Cerebras-GPT-2.7B           2  \n",
       " 3        0.196239          0.219480  1  Cerebras-GPT-2.7B           2  \n",
       " 4        0.200224          0.222348  1  Cerebras-GPT-2.7B           2  ,\n",
       " 'Cerebras-GPT-2.7B-3-shot-1-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.454434        0.254782          0.300039   \n",
       " 1       1           0.461262        0.247130          0.297328   \n",
       " 2       2           0.450217        0.252635          0.299776   \n",
       " 3       3           0.473965        0.266057          0.312647   \n",
       " 4       4                NaN             NaN               NaN   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.107448        0.055229          0.066013           0.328358   \n",
       " 1           0.101509        0.050887          0.061813           0.330524   \n",
       " 2           0.105217        0.055861          0.067067           0.325801   \n",
       " 3           0.147662        0.089148          0.108000           0.351600   \n",
       " 4                NaN             NaN               NaN                NaN   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k         model_name keyword_num  \n",
       " 0        0.177559          0.211219  3  Cerebras-GPT-2.7B           1  \n",
       " 1        0.171909          0.208311  3  Cerebras-GPT-2.7B           1  \n",
       " 2        0.177693          0.212387  3  Cerebras-GPT-2.7B           1  \n",
       " 3        0.193369          0.228806  3  Cerebras-GPT-2.7B           1  \n",
       " 4             NaN               NaN  3  Cerebras-GPT-2.7B           1  ,\n",
       " 'Cerebras-GPT-2.7B-2-shot-1-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.440329        0.254427          0.297263   \n",
       " 1       1           0.443522        0.261751          0.299676   \n",
       " 2       2           0.439488        0.260666          0.298118   \n",
       " 3       3           0.434145        0.249698          0.292370   \n",
       " 4       4           0.445860        0.253413          0.297228   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.098122        0.055160          0.064653           0.320076   \n",
       " 1           0.104047        0.058928          0.067243           0.324543   \n",
       " 2           0.102967        0.058981          0.067336           0.321271   \n",
       " 3           0.097032        0.052857          0.062830           0.315190   \n",
       " 4           0.100809        0.053268          0.063489           0.320167   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k         model_name keyword_num  \n",
       " 0        0.180389          0.211965  2  Cerebras-GPT-2.7B           1  \n",
       " 1        0.185769          0.214388  2  Cerebras-GPT-2.7B           1  \n",
       " 2        0.185337          0.213399  2  Cerebras-GPT-2.7B           1  \n",
       " 3        0.175322          0.207278  2  Cerebras-GPT-2.7B           1  \n",
       " 4        0.177462          0.209271  2  Cerebras-GPT-2.7B           1  ,\n",
       " 'Cerebras-GPT-2.7B-1-shot-1-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.410325        0.259108          0.287994   \n",
       " 1       1           0.413966        0.262379          0.292078   \n",
       " 2       2           0.413159        0.269225          0.294036   \n",
       " 3       3           0.408748        0.256040          0.284615   \n",
       " 4       4           0.422501        0.264513          0.296288   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.090587        0.053929          0.059625           0.296948   \n",
       " 1           0.092470        0.054413          0.061502           0.300493   \n",
       " 2           0.094322        0.057720          0.063760           0.302345   \n",
       " 3           0.087614        0.050921          0.057993           0.299073   \n",
       " 4           0.093123        0.055546          0.062625           0.309129   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k         model_name keyword_num  \n",
       " 0        0.182777          0.204176  1  Cerebras-GPT-2.7B           1  \n",
       " 1        0.186770          0.208184  1  Cerebras-GPT-2.7B           1  \n",
       " 2        0.191666          0.210884  1  Cerebras-GPT-2.7B           1  \n",
       " 3        0.182264          0.204353  1  Cerebras-GPT-2.7B           1  \n",
       " 4        0.188776          0.212899  1  Cerebras-GPT-2.7B           1  ,\n",
       " 'Cerebras-GPT-6.7B-3-shot-2-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.493981        0.294623          0.341204   \n",
       " 1       1           0.491757        0.296368          0.341755   \n",
       " 2       2           0.494440        0.297449          0.344777   \n",
       " 3       3           0.436092        0.238594          0.289984   \n",
       " 4       4                NaN             NaN               NaN   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.132355        0.072781          0.085314           0.358864   \n",
       " 1           0.131848        0.072244          0.085208           0.355531   \n",
       " 2           0.138693        0.077496          0.091111           0.360018   \n",
       " 3           0.082381        0.053925          0.061412           0.359076   \n",
       " 4                NaN             NaN               NaN                NaN   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k         model_name keyword_num  \n",
       " 0        0.207036          0.241720  3  Cerebras-GPT-6.7B           2  \n",
       " 1        0.207795          0.241141  3  Cerebras-GPT-6.7B           2  \n",
       " 2        0.211611          0.246650  3  Cerebras-GPT-6.7B           2  \n",
       " 3        0.193384          0.235991  3  Cerebras-GPT-6.7B           2  \n",
       " 4             NaN               NaN  3  Cerebras-GPT-6.7B           2  ,\n",
       " 'Cerebras-GPT-6.7B-1-shot-3-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.477882        0.329002          0.357630   \n",
       " 1       1           0.476260        0.330729          0.357130   \n",
       " 2       2           0.489856        0.335488          0.365386   \n",
       " 3       3           0.482733        0.335385          0.359898   \n",
       " 4       4           0.488828        0.330645          0.359345   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.128556        0.083331          0.091729           0.349500   \n",
       " 1           0.134196        0.085154          0.094625           0.350091   \n",
       " 2           0.140659        0.088727          0.098937           0.359307   \n",
       " 3           0.140620        0.089757          0.097854           0.360600   \n",
       " 4           0.140083        0.087248          0.096790           0.362485   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k         model_name keyword_num  \n",
       " 0        0.236342          0.257814  1  Cerebras-GPT-6.7B           3  \n",
       " 1        0.236168          0.257627  1  Cerebras-GPT-6.7B           3  \n",
       " 2        0.241734          0.264439  1  Cerebras-GPT-6.7B           3  \n",
       " 3        0.244304          0.264172  1  Cerebras-GPT-6.7B           3  \n",
       " 4        0.240929          0.262607  1  Cerebras-GPT-6.7B           3  ,\n",
       " 'Cerebras-GPT-6.7B-2-shot-3-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.507705        0.320978          0.365097   \n",
       " 1       1           0.506733        0.313847          0.356934   \n",
       " 2       2           0.501645        0.320804          0.361279   \n",
       " 3       3           0.496936        0.317764          0.358422   \n",
       " 4       4           0.503397        0.314013          0.358320   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.153240        0.088650          0.103047           0.374557   \n",
       " 1           0.152984        0.085345          0.099280           0.376799   \n",
       " 2           0.141813        0.083450          0.096040           0.370867   \n",
       " 3           0.146937        0.085904          0.098994           0.365494   \n",
       " 4           0.142490        0.081642          0.095124           0.370279   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k         model_name keyword_num  \n",
       " 0        0.231014          0.264448  2  Cerebras-GPT-6.7B           3  \n",
       " 1        0.225043          0.258532  2  Cerebras-GPT-6.7B           3  \n",
       " 2        0.230263          0.261997  2  Cerebras-GPT-6.7B           3  \n",
       " 3        0.227565          0.258471  2  Cerebras-GPT-6.7B           3  \n",
       " 4        0.225501          0.258818  2  Cerebras-GPT-6.7B           3  ,\n",
       " 'Cerebras-GPT-6.7B-3-shot-1-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.486108        0.274616          0.326318   \n",
       " 1       1           0.486355        0.272153          0.323331   \n",
       " 2       2           0.486125        0.278041          0.328051   \n",
       " 3       3           0.536577        0.271868          0.326444   \n",
       " 4       4                NaN             NaN               NaN   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.123337        0.064177          0.077769           0.350715   \n",
       " 1           0.121922        0.065082          0.078064           0.351826   \n",
       " 2           0.121931        0.066425          0.079312           0.350055   \n",
       " 3           0.109221        0.055396          0.066054           0.387696   \n",
       " 4                NaN             NaN               NaN                NaN   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k         model_name keyword_num  \n",
       " 0        0.191987          0.230050  3  Cerebras-GPT-6.7B           1  \n",
       " 1        0.190732          0.228294  3  Cerebras-GPT-6.7B           1  \n",
       " 2        0.193826          0.230610  3  Cerebras-GPT-6.7B           1  \n",
       " 3        0.209942          0.246333  3  Cerebras-GPT-6.7B           1  \n",
       " 4             NaN               NaN  3  Cerebras-GPT-6.7B           1  ,\n",
       " 'Cerebras-GPT-6.7B-2-shot-2-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.492008        0.299127          0.344076   \n",
       " 1       1           0.489316        0.299283          0.341278   \n",
       " 2       2           0.490038        0.302582          0.344730   \n",
       " 3       3           0.484320        0.304122          0.345503   \n",
       " 4       4           0.486098        0.297424          0.340128   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.134378        0.076441          0.089304           0.356537   \n",
       " 1           0.135414        0.074939          0.088001           0.362084   \n",
       " 2           0.132250        0.076160          0.088514           0.360357   \n",
       " 3           0.131890        0.077476          0.089629           0.351721   \n",
       " 4           0.133360        0.072606          0.085768           0.355000   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k         model_name keyword_num  \n",
       " 0        0.211078          0.244338  2  Cerebras-GPT-6.7B           2  \n",
       " 1        0.214195          0.246560  2  Cerebras-GPT-6.7B           2  \n",
       " 2        0.216485          0.248890  2  Cerebras-GPT-6.7B           2  \n",
       " 3        0.215160          0.245972  2  Cerebras-GPT-6.7B           2  \n",
       " 4        0.210166          0.242406  2  Cerebras-GPT-6.7B           2  ,\n",
       " 'Cerebras-GPT-6.7B-1-shot-2-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.462219        0.311603          0.341155   \n",
       " 1       1           0.463167        0.311571          0.341325   \n",
       " 2       2           0.474294        0.318758          0.346885   \n",
       " 3       3           0.469179        0.311320          0.340885   \n",
       " 4       4           0.472948        0.314136          0.345949   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.120545        0.078515          0.086270           0.338104   \n",
       " 1           0.125286        0.075800          0.085779           0.341686   \n",
       " 2           0.129466        0.079814          0.088428           0.346670   \n",
       " 3           0.122872        0.075110          0.084054           0.343531   \n",
       " 4           0.126468        0.078210          0.087962           0.344375   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k         model_name keyword_num  \n",
       " 0        0.223725          0.245853  1  Cerebras-GPT-6.7B           2  \n",
       " 1        0.222957          0.246310  1  Cerebras-GPT-6.7B           2  \n",
       " 2        0.228310          0.249534  1  Cerebras-GPT-6.7B           2  \n",
       " 3        0.222999          0.245468  1  Cerebras-GPT-6.7B           2  \n",
       " 4        0.224555          0.247926  1  Cerebras-GPT-6.7B           2  ,\n",
       " 'Cerebras-GPT-6.7B-1-shot-1-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.464744        0.286131          0.325319   \n",
       " 1       1           0.464368        0.285808          0.324762   \n",
       " 2       2           0.455819        0.291040          0.323104   \n",
       " 3       3           0.464485        0.285247          0.321982   \n",
       " 4       4           0.470850        0.294725          0.331847   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.113707        0.065435          0.075484           0.336318   \n",
       " 1           0.110338        0.062116          0.071973           0.337667   \n",
       " 2           0.116532        0.066929          0.076432           0.334742   \n",
       " 3           0.120587        0.066467          0.077023           0.335761   \n",
       " 4           0.119165        0.069473          0.079277           0.338771   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k         model_name keyword_num  \n",
       " 0        0.202861          0.231415  1  Cerebras-GPT-6.7B           1  \n",
       " 1        0.201769          0.231091  1  Cerebras-GPT-6.7B           1  \n",
       " 2        0.207538          0.232466  1  Cerebras-GPT-6.7B           1  \n",
       " 3        0.201025          0.228327  1  Cerebras-GPT-6.7B           1  \n",
       " 4        0.207092          0.234541  1  Cerebras-GPT-6.7B           1  ,\n",
       " 'Cerebras-GPT-6.7B-2-shot-1-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.479766        0.278523          0.328012   \n",
       " 1       1           0.485832        0.279066          0.325224   \n",
       " 2       2           0.481652        0.277991          0.325546   \n",
       " 3       3           0.480734        0.278475          0.324425   \n",
       " 4       4           0.483878        0.274726          0.323892   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.125118        0.066421          0.080361           0.349588   \n",
       " 1           0.126388        0.065672          0.078785           0.352289   \n",
       " 2           0.123122        0.065834          0.078102           0.348838   \n",
       " 3           0.127839        0.066954          0.080184           0.350922   \n",
       " 4           0.122107        0.061660          0.075280           0.351364   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k         model_name keyword_num  \n",
       " 0        0.196206          0.233578  2  Cerebras-GPT-6.7B           1  \n",
       " 1        0.196101          0.230492  2  Cerebras-GPT-6.7B           1  \n",
       " 2        0.195419          0.230850  2  Cerebras-GPT-6.7B           1  \n",
       " 3        0.196541          0.231054  2  Cerebras-GPT-6.7B           1  \n",
       " 4        0.192181          0.228991  2  Cerebras-GPT-6.7B           1  ,\n",
       " 'llama-7b-hf-3-shot-3-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.473169        0.309363          0.350544   \n",
       " 1       1           0.478415        0.313384          0.355171   \n",
       " 2       2           0.482775        0.316679          0.358968   \n",
       " 3       3           0.469996        0.311015          0.349262   \n",
       " 4       4           0.472365        0.317878          0.355608   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.138200        0.084978          0.097703           0.358605   \n",
       " 1           0.140592        0.086425          0.099200           0.366833   \n",
       " 2           0.135593        0.084383          0.096347           0.364832   \n",
       " 3           0.137156        0.086909          0.097742           0.356387   \n",
       " 4           0.138368        0.088253          0.099603           0.356087   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k   model_name keyword_num  \n",
       " 0        0.229801          0.261759  3  llama-7b-hf           3  \n",
       " 1        0.235162          0.268045  3  llama-7b-hf           3  \n",
       " 2        0.233824          0.266787  3  llama-7b-hf           3  \n",
       " 3        0.230023          0.259768  3  llama-7b-hf           3  \n",
       " 4        0.233924          0.263499  3  llama-7b-hf           3  ,\n",
       " 'llama-7b-hf-3-shot-2-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.464449        0.296982          0.339795   \n",
       " 1       1           0.465597        0.300243          0.344011   \n",
       " 2       2           0.464919        0.301884          0.343173   \n",
       " 3       3           0.463057        0.299573          0.341449   \n",
       " 4       4           0.462803        0.304043          0.342978   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.127518        0.076631          0.089122           0.349219   \n",
       " 1           0.127186        0.077656          0.089704           0.348496   \n",
       " 2           0.126728        0.079881          0.091150           0.351616   \n",
       " 3           0.131781        0.080879          0.093532           0.350705   \n",
       " 4           0.124112        0.078405          0.089205           0.347612   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k   model_name keyword_num  \n",
       " 0        0.218774          0.251613  3  llama-7b-hf           2  \n",
       " 1        0.219293          0.252943  3  llama-7b-hf           2  \n",
       " 2        0.224514          0.256221  3  llama-7b-hf           2  \n",
       " 3        0.220521          0.253565  3  llama-7b-hf           2  \n",
       " 4        0.223575          0.253683  3  llama-7b-hf           2  ,\n",
       " 'llama-7b-hf-3-shot-1-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.462288        0.282674          0.328499   \n",
       " 1       1           0.454479        0.274814          0.320915   \n",
       " 2       2           0.455591        0.278434          0.326184   \n",
       " 3       3           0.459139        0.280876          0.327618   \n",
       " 4       4           0.460022        0.279863          0.327187   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.118673        0.068217          0.080656           0.344016   \n",
       " 1           0.113504        0.065565          0.077196           0.339731   \n",
       " 2           0.115380        0.067221          0.079773           0.338146   \n",
       " 3           0.121084        0.069933          0.082724           0.344227   \n",
       " 4           0.117755        0.068903          0.081106           0.342536   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k   model_name keyword_num  \n",
       " 0        0.204669          0.239783  3  llama-7b-hf           1  \n",
       " 1        0.199779          0.235362  3  llama-7b-hf           1  \n",
       " 2        0.201488          0.237784  3  llama-7b-hf           1  \n",
       " 3        0.204536          0.240638  3  llama-7b-hf           1  \n",
       " 4        0.203359          0.239469  3  llama-7b-hf           1  ,\n",
       " 'llama-7b-hf-2-shot-3-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.474531        0.307416          0.349614   \n",
       " 1       1           0.465525        0.309194          0.346545   \n",
       " 2       2           0.476267        0.314030          0.353584   \n",
       " 3       3           0.467868        0.311813          0.349607   \n",
       " 4       4           0.479801        0.308527          0.352416   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.135131        0.084137          0.096617           0.362041   \n",
       " 1           0.130966        0.083068          0.093452           0.351776   \n",
       " 2           0.133713        0.084189          0.095914           0.357321   \n",
       " 3           0.133526        0.084522          0.095956           0.353796   \n",
       " 4           0.140333        0.085244          0.098988           0.362545   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k   model_name keyword_num  \n",
       " 0        0.228435          0.261786  2  llama-7b-hf           3  \n",
       " 1        0.229964          0.258521  2  llama-7b-hf           3  \n",
       " 2        0.230534          0.261230  2  llama-7b-hf           3  \n",
       " 3        0.230751          0.260367  2  llama-7b-hf           3  \n",
       " 4        0.227841          0.262129  2  llama-7b-hf           3  ,\n",
       " 'llama-7b-hf-2-shot-1-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.454860        0.277010          0.322566   \n",
       " 1       1           0.445342        0.279449          0.320046   \n",
       " 2       2           0.458183        0.277141          0.322173   \n",
       " 3       3           0.456848        0.279631          0.323798   \n",
       " 4       4           0.454644        0.274854          0.320381   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.118832        0.068577          0.080824           0.337749   \n",
       " 1           0.112885        0.068333          0.078637           0.331647   \n",
       " 2           0.111419        0.064258          0.075553           0.338225   \n",
       " 3           0.117422        0.068231          0.079996           0.339994   \n",
       " 4           0.115064        0.067329          0.078938           0.340413   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k   model_name keyword_num  \n",
       " 0        0.200201          0.235094  2  llama-7b-hf           1  \n",
       " 1        0.202646          0.233887  2  llama-7b-hf           1  \n",
       " 2        0.199798          0.233995  2  llama-7b-hf           1  \n",
       " 3        0.203343          0.236879  2  llama-7b-hf           1  \n",
       " 4        0.201223          0.236087  2  llama-7b-hf           1  ,\n",
       " 'opt-iml-1.3b-3-shot-3-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.317968        0.576351          0.385338   \n",
       " 1       1           0.316543        0.574921          0.384689   \n",
       " 2       2           0.322901        0.585740          0.392214   \n",
       " 3       3           0.279691        0.492727          0.346598   \n",
       " 4       4                NaN             NaN               NaN   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.091190        0.173704          0.111377           0.253875   \n",
       " 1           0.099562        0.183490          0.120008           0.256607   \n",
       " 2           0.101441        0.192686          0.124813           0.259456   \n",
       " 3           0.039610        0.076579          0.049831           0.233841   \n",
       " 4                NaN             NaN               NaN                NaN   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k    model_name keyword_num  \n",
       " 0        0.457652          0.306694  3  opt-iml-1.3b           3  \n",
       " 1        0.462841          0.310360  3  opt-iml-1.3b           3  \n",
       " 2        0.468871          0.314403  3  opt-iml-1.3b           3  \n",
       " 3        0.396061          0.285024  3  opt-iml-1.3b           3  \n",
       " 4             NaN               NaN  3  opt-iml-1.3b           3  ,\n",
       " 'opt-iml-1.3b-3-shot-2-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.314565        0.572812          0.381039   \n",
       " 1       1           0.304986        0.563718          0.372584   \n",
       " 2       2           0.313546        0.573867          0.381541   \n",
       " 3       3           0.274009        0.437818          0.331805   \n",
       " 4       4                NaN             NaN               NaN   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.090222        0.174496          0.110393           0.250414   \n",
       " 1           0.088805        0.171440          0.109169           0.243974   \n",
       " 2           0.097388        0.182539          0.118588           0.252817   \n",
       " 3           0.055411        0.090476          0.068687           0.213413   \n",
       " 4                NaN             NaN               NaN                NaN   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k    model_name keyword_num  \n",
       " 0        0.455205          0.302786  3  opt-iml-1.3b           2  \n",
       " 1        0.449719          0.297131  3  opt-iml-1.3b           2  \n",
       " 2        0.459595          0.306464  3  opt-iml-1.3b           2  \n",
       " 3        0.330909          0.255596  3  opt-iml-1.3b           2  \n",
       " 4             NaN               NaN  3  opt-iml-1.3b           2  ,\n",
       " 'opt-iml-1.3b-3-shot-1-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.307732        0.559441          0.372443   \n",
       " 1       1           0.310836        0.563910          0.376855   \n",
       " 2       2           0.311939        0.570289          0.379631   \n",
       " 3       3           0.249961        0.481111          0.318007   \n",
       " 4       4                NaN             NaN               NaN   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.091486        0.174714          0.111374           0.247515   \n",
       " 1           0.094344        0.176244          0.114713           0.251432   \n",
       " 2           0.098077        0.184543          0.119530           0.252040   \n",
       " 3           0.032468        0.056579          0.040725           0.208762   \n",
       " 4                NaN             NaN               NaN                NaN   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k    model_name keyword_num  \n",
       " 0        0.448827          0.298675  3  opt-iml-1.3b           1  \n",
       " 1        0.453253          0.303613  3  opt-iml-1.3b           1  \n",
       " 2        0.458586          0.305942  3  opt-iml-1.3b           1  \n",
       " 3        0.372222          0.258419  3  opt-iml-1.3b           1  \n",
       " 4             NaN               NaN  3  opt-iml-1.3b           1  ,\n",
       " 'Cerebras-GPT-13B-2-shot-3-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.503934        0.317137          0.360087   \n",
       " 1       1           0.501251        0.326577          0.363576   \n",
       " 2       2           0.496767        0.328412          0.364158   \n",
       " 3       3           0.501012        0.324669          0.362885   \n",
       " 4       4           0.505745        0.309160          0.355945   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.148016        0.087482          0.100277           0.373793   \n",
       " 1           0.143474        0.089381          0.099959           0.369061   \n",
       " 2           0.138447        0.086088          0.096946           0.364675   \n",
       " 3           0.139633        0.084980          0.096723           0.367292   \n",
       " 4           0.141577        0.080955          0.094671           0.369430   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k        model_name keyword_num  \n",
       " 0        0.229836          0.262542  2  Cerebras-GPT-13B           3  \n",
       " 1        0.235034          0.263140  2  Cerebras-GPT-13B           3  \n",
       " 2        0.236510          0.263419  2  Cerebras-GPT-13B           3  \n",
       " 3        0.233173          0.261934  2  Cerebras-GPT-13B           3  \n",
       " 4        0.219817          0.255243  2  Cerebras-GPT-13B           3  ,\n",
       " 'Cerebras-GPT-13B-2-shot-2-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.492520        0.309281          0.351262   \n",
       " 1       1           0.482663        0.309516          0.345787   \n",
       " 2       2           0.485894        0.313628          0.350962   \n",
       " 3       3           0.489417        0.317172          0.355582   \n",
       " 4       4           0.491361        0.305443          0.348526   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.140266        0.082495          0.094767           0.361951   \n",
       " 1           0.131483        0.077916          0.088880           0.357854   \n",
       " 2           0.127243        0.077367          0.087637           0.354301   \n",
       " 3           0.135700        0.081248          0.093047           0.355856   \n",
       " 4           0.132699        0.075797          0.088686           0.355638   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k        model_name keyword_num  \n",
       " 0        0.222345          0.254314  2  Cerebras-GPT-13B           2  \n",
       " 1        0.223462          0.251580  2  Cerebras-GPT-13B           2  \n",
       " 2        0.224560          0.252377  2  Cerebras-GPT-13B           2  \n",
       " 3        0.225494          0.254319  2  Cerebras-GPT-13B           2  \n",
       " 4        0.216958          0.248367  2  Cerebras-GPT-13B           2  ,\n",
       " 'llama-7b-hf-1-shot-3-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.459877        0.299418          0.336683   \n",
       " 1       1           0.476547        0.301105          0.343553   \n",
       " 2       2           0.468373        0.297595          0.338197   \n",
       " 3       3           0.459757        0.297508          0.334287   \n",
       " 4       4           0.467466        0.296112          0.338339   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.130302        0.081291          0.092168           0.347227   \n",
       " 1           0.133292        0.080318          0.092052           0.358435   \n",
       " 2           0.134356        0.078584          0.091057           0.351237   \n",
       " 3           0.136115        0.083365          0.094264           0.354346   \n",
       " 4           0.125024        0.075214          0.086797           0.347671   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k   model_name keyword_num  \n",
       " 0        0.222303          0.250981  1  llama-7b-hf           3  \n",
       " 1        0.221585          0.254296  1  llama-7b-hf           3  \n",
       " 2        0.218046          0.248934  1  llama-7b-hf           3  \n",
       " 3        0.225529          0.254148  1  llama-7b-hf           3  \n",
       " 4        0.216791          0.248378  1  llama-7b-hf           3  ,\n",
       " 'llama-7b-hf-1-shot-2-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.441840        0.295112          0.326769   \n",
       " 1       1           0.461679        0.294857          0.333957   \n",
       " 2       2           0.454932        0.288710          0.327933   \n",
       " 3       3           0.445473        0.290412          0.325274   \n",
       " 4       4           0.445936        0.288980          0.324392   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.116569        0.075897          0.084158           0.331772   \n",
       " 1           0.121398        0.074124          0.084724           0.342286   \n",
       " 2           0.123369        0.072820          0.084004           0.340313   \n",
       " 3           0.123692        0.077132          0.086656           0.336888   \n",
       " 4           0.117074        0.072361          0.082240           0.330314   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k   model_name keyword_num  \n",
       " 0        0.218345          0.242239  1  llama-7b-hf           2  \n",
       " 1        0.213733          0.243548  1  llama-7b-hf           2  \n",
       " 2        0.212399          0.241455  1  llama-7b-hf           2  \n",
       " 3        0.216511          0.243176  1  llama-7b-hf           2  \n",
       " 4        0.211640          0.237779  1  llama-7b-hf           2  ,\n",
       " 'Cerebras-GPT-13B-2-shot-1-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.472456        0.293963          0.333388   \n",
       " 1       1           0.473862        0.291295          0.330819   \n",
       " 2       2           0.473159        0.294610          0.333353   \n",
       " 3       3           0.475680        0.298486          0.338045   \n",
       " 4       4           0.470958        0.289765          0.329667   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.121599        0.070957          0.081397           0.345020   \n",
       " 1           0.116183        0.067078          0.076832           0.343283   \n",
       " 2           0.115431        0.067833          0.077604           0.340667   \n",
       " 3           0.121438        0.070313          0.081136           0.344635   \n",
       " 4           0.120880        0.067921          0.079313           0.343699   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k        model_name keyword_num  \n",
       " 0        0.208653          0.238869  2  Cerebras-GPT-13B           1  \n",
       " 1        0.206553          0.235363  2  Cerebras-GPT-13B           1  \n",
       " 2        0.206667          0.235312  2  Cerebras-GPT-13B           1  \n",
       " 3        0.210258          0.239870  2  Cerebras-GPT-13B           1  \n",
       " 4        0.205973          0.235838  2  Cerebras-GPT-13B           1  ,\n",
       " 'llama-7b-hf-1-shot-1-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.436705        0.274179          0.311831   \n",
       " 1       1           0.443862        0.277175          0.316062   \n",
       " 2       2           0.442192        0.271166          0.311493   \n",
       " 3       3           0.432813        0.271821          0.309173   \n",
       " 4       4           0.446256        0.271544          0.312260   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.106214        0.062943          0.072180           0.324040   \n",
       " 1           0.113118        0.065662          0.076330           0.331703   \n",
       " 2           0.115366        0.063744          0.075708           0.330320   \n",
       " 3           0.106437        0.061346          0.071313           0.323581   \n",
       " 4           0.108045        0.062207          0.072601           0.326387   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k   model_name keyword_num  \n",
       " 0        0.199039          0.227348  1  llama-7b-hf           1  \n",
       " 1        0.202037          0.231770  1  llama-7b-hf           1  \n",
       " 2        0.197646          0.228015  1  llama-7b-hf           1  \n",
       " 3        0.198741          0.227243  1  llama-7b-hf           1  \n",
       " 4        0.195318          0.224984  1  llama-7b-hf           1  ,\n",
       " 'bloom-7b1-3-shot-3-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.473484        0.340358          0.365344   \n",
       " 1       1           0.468339        0.334303          0.359928   \n",
       " 2       2           0.473329        0.344314          0.368278   \n",
       " 3       3           0.474412        0.337985          0.364616   \n",
       " 4       4           0.470986        0.334763          0.359483   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.137190        0.096794          0.103524           0.355008   \n",
       " 1           0.131021        0.089352          0.096819           0.350281   \n",
       " 2           0.137610        0.095765          0.103109           0.354529   \n",
       " 3           0.140436        0.095747          0.103508           0.357913   \n",
       " 4           0.134112        0.090297          0.097427           0.351154   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.251636          0.270665  3  bloom-7b1           3  \n",
       " 1        0.246847          0.266727  3  bloom-7b1           3  \n",
       " 2        0.252949          0.272145  3  bloom-7b1           3  \n",
       " 3        0.250420          0.271143  3  bloom-7b1           3  \n",
       " 4        0.247068          0.265563  3  bloom-7b1           3  ,\n",
       " 'bloom-7b1-3-shot-2-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.457583        0.321843          0.348347   \n",
       " 1       1           0.455132        0.319612          0.346763   \n",
       " 2       2           0.456638        0.328881          0.352420   \n",
       " 3       3           0.460427        0.319935          0.348512   \n",
       " 4       4           0.455254        0.312493          0.340313   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.126256        0.085714          0.092993           0.341456   \n",
       " 1           0.121759        0.081685          0.089060           0.338646   \n",
       " 2           0.126605        0.088014          0.093931           0.340394   \n",
       " 3           0.125184        0.084820          0.091820           0.340599   \n",
       " 4           0.121399        0.080321          0.087830           0.337330   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.236366          0.256700  3  bloom-7b1           2  \n",
       " 1        0.234937          0.255404  3  bloom-7b1           2  \n",
       " 2        0.239754          0.257976  3  bloom-7b1           2  \n",
       " 3        0.232701          0.254229  3  bloom-7b1           2  \n",
       " 4        0.229134          0.249651  3  bloom-7b1           2  ,\n",
       " 'bloom-7b1-3-shot-1-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.457831        0.285416          0.326356   \n",
       " 1       1           0.455976        0.283287          0.323072   \n",
       " 2       2           0.453540        0.284642          0.324460   \n",
       " 3       3           0.456664        0.277194          0.320105   \n",
       " 4       4           0.450887        0.274379          0.315009   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.111248        0.066997          0.076984           0.331461   \n",
       " 1           0.110047        0.066343          0.075593           0.331393   \n",
       " 2           0.115138        0.069133          0.079353           0.330576   \n",
       " 3           0.109827        0.063572          0.073730           0.330406   \n",
       " 4           0.107986        0.063680          0.073478           0.329741   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.203264          0.233285  3  bloom-7b1           1  \n",
       " 1        0.203015          0.232119  3  bloom-7b1           1  \n",
       " 2        0.202796          0.232504  3  bloom-7b1           1  \n",
       " 3        0.195611          0.227123  3  bloom-7b1           1  \n",
       " 4        0.197090          0.227054  3  bloom-7b1           1  ,\n",
       " 'bloom-7b1-2-shot-3-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.468570        0.353427          0.369598   \n",
       " 1       1           0.466983        0.350022          0.364366   \n",
       " 2       2           0.469467        0.350845          0.368701   \n",
       " 3       3           0.467675        0.340873          0.361805   \n",
       " 4       4           0.472303        0.346783          0.367142   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.134466        0.098173          0.102854           0.353976   \n",
       " 1           0.139826        0.098226          0.103952           0.353886   \n",
       " 2           0.135660        0.098312          0.102969           0.348893   \n",
       " 3           0.133827        0.093349          0.099554           0.351571   \n",
       " 4           0.141711        0.097941          0.105532           0.354501   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.262600          0.275911  2  bloom-7b1           3  \n",
       " 1        0.261434          0.272861  2  bloom-7b1           3  \n",
       " 2        0.256455          0.270681  2  bloom-7b1           3  \n",
       " 3        0.253114          0.269112  2  bloom-7b1           3  \n",
       " 4        0.255567          0.272063  2  bloom-7b1           3  ,\n",
       " 'bloom-7b1-2-shot-2-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.459485        0.326459          0.351849   \n",
       " 1       1           0.453758        0.326119          0.349315   \n",
       " 2       2           0.447855        0.329696          0.349380   \n",
       " 3       3           0.452593        0.328029          0.349958   \n",
       " 4       4           0.455662        0.325459          0.349234   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.127476        0.087137          0.094071           0.340406   \n",
       " 1           0.121084        0.082421          0.088891           0.334394   \n",
       " 2           0.116825        0.084650          0.089779           0.330974   \n",
       " 3           0.123310        0.085974          0.091881           0.337792   \n",
       " 4           0.121694        0.085462          0.091478           0.336576   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.237568          0.257587  2  bloom-7b1           2  \n",
       " 1        0.236327          0.253943  2  bloom-7b1           2  \n",
       " 2        0.241643          0.256384  2  bloom-7b1           2  \n",
       " 3        0.240789          0.257978  2  bloom-7b1           2  \n",
       " 4        0.237568          0.255233  2  bloom-7b1           2  ,\n",
       " 'bloom-7b1-2-shot-1-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.459399        0.284282          0.324744   \n",
       " 1       1           0.457340        0.280953          0.321249   \n",
       " 2       2           0.453917        0.283542          0.323055   \n",
       " 3       3           0.452585        0.281651          0.320924   \n",
       " 4       4           0.448924        0.285300          0.323085   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.116900        0.067702          0.078721           0.336593   \n",
       " 1           0.113104        0.065076          0.075137           0.332437   \n",
       " 2           0.110149        0.066303          0.075675           0.328878   \n",
       " 3           0.112366        0.069284          0.078124           0.329294   \n",
       " 4           0.109077        0.070079          0.078148           0.327746   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.203966          0.234145  2  bloom-7b1           1  \n",
       " 1        0.199417          0.229354  2  bloom-7b1           1  \n",
       " 2        0.203013          0.231684  2  bloom-7b1           1  \n",
       " 3        0.201823          0.230399  2  bloom-7b1           1  \n",
       " 4        0.204965          0.232760  2  bloom-7b1           1  ,\n",
       " 'bloom-7b1-1-shot-3-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.459026        0.353011          0.362138   \n",
       " 1       1           0.465646        0.359569          0.374243   \n",
       " 2       2           0.465182        0.362454          0.372009   \n",
       " 3       3           0.461216        0.354308          0.365652   \n",
       " 4       4           0.468360        0.354618          0.369911   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.132547        0.096516          0.099980           0.350055   \n",
       " 1           0.134701        0.101514          0.105446           0.350176   \n",
       " 2           0.136845        0.102396          0.105060           0.349163   \n",
       " 3           0.128811        0.094776          0.098298           0.346640   \n",
       " 4           0.136213        0.100168          0.104306           0.352058   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.265993          0.272835  1  bloom-7b1           3  \n",
       " 1        0.266581          0.278427  1  bloom-7b1           3  \n",
       " 2        0.267685          0.275478  1  bloom-7b1           3  \n",
       " 3        0.262436          0.271563  1  bloom-7b1           3  \n",
       " 4        0.263885          0.275439  1  bloom-7b1           3  ,\n",
       " 'bloom-7b1-1-shot-1-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.446513        0.288406          0.322701   \n",
       " 1       1           0.442436        0.290033          0.323077   \n",
       " 2       2           0.450214        0.290634          0.325950   \n",
       " 3       3           0.445874        0.276845          0.315525   \n",
       " 4       4           0.448796        0.287910          0.323992   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.109271        0.064508          0.074241           0.326790   \n",
       " 1           0.103530        0.066504          0.073938           0.325076   \n",
       " 2           0.113698        0.069404          0.078743           0.331204   \n",
       " 3           0.105794        0.062047          0.071266           0.321304   \n",
       " 4           0.109974        0.069732          0.077807           0.329858   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.207127          0.232628  1  bloom-7b1           1  \n",
       " 1        0.210049          0.234596  1  bloom-7b1           1  \n",
       " 2        0.209675          0.235955  1  bloom-7b1           1  \n",
       " 3        0.195512          0.223502  1  bloom-7b1           1  \n",
       " 4        0.209356          0.235754  1  bloom-7b1           1  ,\n",
       " 'bloom-7b1-1-shot-2-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.450310        0.337186          0.354827   \n",
       " 1       1           0.443479        0.336068          0.350965   \n",
       " 2       2           0.450024        0.334010          0.352269   \n",
       " 3       3           0.443770        0.335120          0.348133   \n",
       " 4       4           0.444819        0.329852          0.347191   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.126367        0.088774          0.095617           0.336391   \n",
       " 1           0.117238        0.087289          0.090514           0.327818   \n",
       " 2           0.127569        0.090047          0.095785           0.336800   \n",
       " 3           0.119096        0.088614          0.091277           0.327961   \n",
       " 4           0.117270        0.086193          0.090489           0.331289   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.249048          0.261945  1  bloom-7b1           2  \n",
       " 1        0.246138          0.257390  1  bloom-7b1           2  \n",
       " 2        0.247142          0.261069  1  bloom-7b1           2  \n",
       " 3        0.245649          0.254657  1  bloom-7b1           2  \n",
       " 4        0.244066          0.256757  1  bloom-7b1           2  ,\n",
       " 'flan-t5-xl-3-shot':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.520816        0.621847          0.538806   \n",
       " 1       1           0.518654        0.623238          0.539115   \n",
       " 2       2           0.518399        0.624017          0.538473   \n",
       " 3       3           0.519675        0.624948          0.539986   \n",
       " 4       4           0.519236        0.625418          0.540083   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.287144        0.347105          0.297579           0.438064   \n",
       " 1           0.286233        0.348029          0.297773           0.436277   \n",
       " 2           0.284628        0.348247          0.296882           0.435967   \n",
       " 3           0.286681        0.350171          0.299026           0.437639   \n",
       " 4           0.286560        0.349548          0.298562           0.435997   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k  model_name keyword_num  \n",
       " 0        0.523275          0.453502  3  flan-t5-xl        None  \n",
       " 1        0.523908          0.453538  3  flan-t5-xl        None  \n",
       " 2        0.525336          0.453288  3  flan-t5-xl        None  \n",
       " 3        0.526390          0.455062  3  flan-t5-xl        None  \n",
       " 4        0.525559          0.453908  3  flan-t5-xl        None  ,\n",
       " 'flan-t5-xl-2-shot':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.517420        0.624946          0.538074   \n",
       " 1       1           0.518220        0.627812          0.539279   \n",
       " 2       2           0.518575        0.630011          0.540956   \n",
       " 3       3           0.519109        0.627037          0.540836   \n",
       " 4       4           0.517967        0.626827          0.539790   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.284209        0.347159          0.296171           0.434758   \n",
       " 1           0.286224        0.349365          0.297537           0.436555   \n",
       " 2           0.287790        0.353457          0.300859           0.440115   \n",
       " 3           0.286834        0.350628          0.299406           0.437549   \n",
       " 4           0.285234        0.350163          0.298307           0.436465   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k  model_name keyword_num  \n",
       " 0        0.525309          0.452477  2  flan-t5-xl        None  \n",
       " 1        0.528179          0.454271  2  flan-t5-xl        None  \n",
       " 2        0.535241          0.459539  2  flan-t5-xl        None  \n",
       " 3        0.529230          0.456350  2  flan-t5-xl        None  \n",
       " 4        0.529264          0.455543  2  flan-t5-xl        None  ,\n",
       " 'alpaca-native-3-shot':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.408797        0.290400          0.317583   \n",
       " 1       1           0.405413        0.297376          0.321098   \n",
       " 2       2           0.407226        0.297530          0.321898   \n",
       " 3       3           0.409555        0.293999          0.321314   \n",
       " 4       4           0.400686        0.294942          0.316756   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.093376        0.064578          0.070914           0.306155   \n",
       " 1           0.090812        0.063918          0.069944           0.302004   \n",
       " 2           0.091721        0.065574          0.071060           0.305289   \n",
       " 3           0.093002        0.064590          0.071389           0.306928   \n",
       " 4           0.092232        0.066207          0.071548           0.300685   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k     model_name keyword_num  \n",
       " 0        0.214934          0.235652  3  alpaca-native        None  \n",
       " 1        0.219731          0.237583  3  alpaca-native        None  \n",
       " 2        0.219568          0.238756  3  alpaca-native        None  \n",
       " 3        0.216372          0.237834  3  alpaca-native        None  \n",
       " 4        0.218262          0.235499  3  alpaca-native        None  ,\n",
       " 'opt-iml-1.3b-2-shot-3-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.317978        0.592052          0.389100   \n",
       " 1       1           0.312189        0.591001          0.383795   \n",
       " 2       2           0.311315        0.594161          0.384824   \n",
       " 3       3           0.312560        0.590589          0.384423   \n",
       " 4       4           0.302023        0.585445          0.376016   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.103256        0.197606          0.126307           0.256399   \n",
       " 1           0.100152        0.195241          0.123545           0.251844   \n",
       " 2           0.096802        0.196154          0.121046           0.251020   \n",
       " 3           0.098609        0.193531          0.121699           0.251386   \n",
       " 4           0.089026        0.183541          0.112028           0.243536   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k    model_name keyword_num  \n",
       " 0        0.475471          0.313021  2  opt-iml-1.3b           3  \n",
       " 1        0.473106          0.308204  2  opt-iml-1.3b           3  \n",
       " 2        0.477709          0.309451  2  opt-iml-1.3b           3  \n",
       " 3        0.474959          0.308796  2  opt-iml-1.3b           3  \n",
       " 4        0.470483          0.302355  2  opt-iml-1.3b           3  ,\n",
       " 'opt-iml-1.3b-1-shot-1-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.279281        0.568449          0.353109   \n",
       " 1       1           0.284631        0.573256          0.357035   \n",
       " 2       2           0.286639        0.571188          0.358326   \n",
       " 3       3           0.288802        0.571748          0.361381   \n",
       " 4       4           0.290419        0.569687          0.360549   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.087909        0.187883          0.112286           0.230386   \n",
       " 1           0.084797        0.185439          0.108082           0.230541   \n",
       " 2           0.087641        0.181912          0.109709           0.233457   \n",
       " 3           0.090965        0.191923          0.114844           0.235996   \n",
       " 4           0.090787        0.187575          0.112883           0.235705   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k    model_name keyword_num  \n",
       " 0        0.467121          0.290369  1  opt-iml-1.3b           1  \n",
       " 1        0.464523          0.288777  1  opt-iml-1.3b           1  \n",
       " 2        0.463913          0.291005  1  opt-iml-1.3b           1  \n",
       " 3        0.467352          0.294909  1  opt-iml-1.3b           1  \n",
       " 4        0.462156          0.292042  1  opt-iml-1.3b           1  ,\n",
       " 'mt5-xxl-3-shot-3-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.197254        0.203805          0.185758   \n",
       " 1       1           0.197254        0.203805          0.185758   \n",
       " 2       2           0.197254        0.203805          0.185758   \n",
       " 3       3           0.197254        0.203805          0.185758   \n",
       " 4       4           0.197254        0.203805          0.185758   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.000404        0.000343          0.000331             0.1955   \n",
       " 1           0.000404        0.000343          0.000331             0.1955   \n",
       " 2           0.000404        0.000343          0.000331             0.1955   \n",
       " 3           0.000404        0.000343          0.000331             0.1955   \n",
       " 4           0.000404        0.000343          0.000331             0.1955   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.201445          0.183843  3    mt5-xxl           3  \n",
       " 1        0.201445          0.183843  3    mt5-xxl           3  \n",
       " 2        0.201445          0.183843  3    mt5-xxl           3  \n",
       " 3        0.201445          0.183843  3    mt5-xxl           3  \n",
       " 4        0.201445          0.183843  3    mt5-xxl           3  ,\n",
       " 'alpaca-native-2-shot':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.409791        0.289698          0.317390   \n",
       " 1       1           0.401420        0.286575          0.312098   \n",
       " 2       2           0.407564        0.298420          0.323357   \n",
       " 3       3           0.403933        0.290595          0.316699   \n",
       " 4       4           0.408874        0.286869          0.314624   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.098054        0.065774          0.073172           0.307270   \n",
       " 1           0.089514        0.061289          0.067533           0.297406   \n",
       " 2           0.092176        0.067179          0.072201           0.304388   \n",
       " 3           0.088341        0.063451          0.068925           0.299189   \n",
       " 4           0.096398        0.064594          0.071362           0.307584   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k     model_name keyword_num  \n",
       " 0        0.213257          0.235128  2  alpaca-native        None  \n",
       " 1        0.208623          0.228295  2  alpaca-native        None  \n",
       " 2        0.219815          0.239127  2  alpaca-native        None  \n",
       " 3        0.211815          0.232029  2  alpaca-native        None  \n",
       " 4        0.212050          0.233536  2  alpaca-native        None  ,\n",
       " 'mt5-xxl-3-shot-2-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.132478        0.185453          0.143185   \n",
       " 1       1           0.132478        0.185453          0.143185   \n",
       " 2       2           0.132478        0.185453          0.143185   \n",
       " 3       3           0.132478        0.185453          0.143185   \n",
       " 4       4           0.132478        0.185453          0.143185   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.000047        0.000111          0.000066           0.131561   \n",
       " 1           0.000047        0.000111          0.000066           0.131561   \n",
       " 2           0.000047        0.000111          0.000066           0.131561   \n",
       " 3           0.000047        0.000111          0.000066           0.131561   \n",
       " 4           0.000047        0.000111          0.000066           0.131561   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0         0.18401          0.142129  3    mt5-xxl           2  \n",
       " 1         0.18401          0.142129  3    mt5-xxl           2  \n",
       " 2         0.18401          0.142129  3    mt5-xxl           2  \n",
       " 3         0.18401          0.142129  3    mt5-xxl           2  \n",
       " 4         0.18401          0.142129  3    mt5-xxl           2  ,\n",
       " 'opt-iml-1.3b-2-shot-1-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.300584        0.571015          0.369475   \n",
       " 1       1           0.294522        0.577975          0.366550   \n",
       " 2       2           0.295859        0.574490          0.367641   \n",
       " 3       3           0.302148        0.578580          0.373262   \n",
       " 4       4           0.295321        0.580063          0.368288   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.092639        0.181613          0.113852           0.243182   \n",
       " 1           0.090873        0.189873          0.113912           0.240286   \n",
       " 2           0.091170        0.187026          0.114300           0.239138   \n",
       " 3           0.094024        0.186440          0.115882           0.244926   \n",
       " 4           0.086013        0.179533          0.108190           0.236886   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k    model_name keyword_num  \n",
       " 0        0.460133          0.298040  2  opt-iml-1.3b           1  \n",
       " 1        0.469546          0.297954  2  opt-iml-1.3b           1  \n",
       " 2        0.463767          0.296574  2  opt-iml-1.3b           1  \n",
       " 3        0.467018          0.301365  2  opt-iml-1.3b           1  \n",
       " 4        0.465693          0.295135  2  opt-iml-1.3b           1  ,\n",
       " 'opt-iml-1.3b-2-shot-2-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.306940        0.584948          0.376827   \n",
       " 1       1           0.302366        0.582279          0.372955   \n",
       " 2       2           0.298100        0.572214          0.369089   \n",
       " 3       3           0.301743        0.581072          0.373672   \n",
       " 4       4           0.297242        0.582316          0.371017   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.094565        0.186497          0.116188           0.248452   \n",
       " 1           0.092415        0.185689          0.114571           0.241885   \n",
       " 2           0.090409        0.182925          0.113156           0.241429   \n",
       " 3           0.094844        0.187728          0.117164           0.245341   \n",
       " 4           0.083625        0.176121          0.106073           0.236557   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k    model_name keyword_num  \n",
       " 0        0.472305          0.304254  2  opt-iml-1.3b           2  \n",
       " 1        0.462339          0.297042  2  opt-iml-1.3b           2  \n",
       " 2        0.462377          0.298269  2  opt-iml-1.3b           2  \n",
       " 3        0.468724          0.302264  2  opt-iml-1.3b           2  \n",
       " 4        0.465798          0.295499  2  opt-iml-1.3b           2  ,\n",
       " 'opt-iml-1.3b-1-shot-3-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.295617        0.584515          0.369212   \n",
       " 1       1           0.298915        0.590736          0.373068   \n",
       " 2       2           0.291657        0.582666          0.364943   \n",
       " 3       3           0.291305        0.578823          0.364765   \n",
       " 4       4           0.296088        0.574189          0.367430   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.093583        0.193734          0.117327           0.240737   \n",
       " 1           0.093332        0.194737          0.117295           0.243015   \n",
       " 2           0.096416        0.200446          0.120996           0.235213   \n",
       " 3           0.094381        0.199185          0.118889           0.236855   \n",
       " 4           0.091525        0.189741          0.114873           0.239527   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k    model_name keyword_num  \n",
       " 0        0.473887          0.299540  1  opt-iml-1.3b           3  \n",
       " 1        0.480560          0.302838  1  opt-iml-1.3b           3  \n",
       " 2        0.470585          0.294108  1  opt-iml-1.3b           3  \n",
       " 3        0.469900          0.295941  1  opt-iml-1.3b           3  \n",
       " 4        0.465014          0.296955  1  opt-iml-1.3b           3  ,\n",
       " 'opt-iml-1.3b-1-shot-2-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.284796        0.578043          0.359350   \n",
       " 1       1           0.291808        0.583459          0.365243   \n",
       " 2       2           0.285136        0.573797          0.357701   \n",
       " 3       3           0.288595        0.576028          0.361893   \n",
       " 4       4           0.287045        0.569874          0.359612   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.086767        0.185804          0.109978           0.233406   \n",
       " 1           0.088252        0.189949          0.112071           0.235973   \n",
       " 2           0.090860        0.192245          0.114290           0.231223   \n",
       " 3           0.086599        0.184165          0.109106           0.231075   \n",
       " 4           0.085958        0.182943          0.108773           0.230638   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k    model_name keyword_num  \n",
       " 0        0.470679          0.293285  1  opt-iml-1.3b           2  \n",
       " 1        0.473284          0.295166  1  opt-iml-1.3b           2  \n",
       " 2        0.466063          0.289693  1  opt-iml-1.3b           2  \n",
       " 3        0.460750          0.288964  1  opt-iml-1.3b           2  \n",
       " 4        0.458191          0.288579  1  opt-iml-1.3b           2  ,\n",
       " 'mt5-xxl-3-shot-1-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.097040        0.163780          0.109685   \n",
       " 1       1           0.092303        0.161459          0.106054   \n",
       " 2       2           0.098471        0.167673          0.111110   \n",
       " 3       3           0.093824        0.161915          0.106581   \n",
       " 4       4           0.089825        0.159184          0.102371   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.014528        0.011923          0.012166           0.094050   \n",
       " 1           0.012769        0.010373          0.010366           0.090437   \n",
       " 2           0.016376        0.014618          0.013641           0.096103   \n",
       " 3           0.010613        0.009635          0.008914           0.090613   \n",
       " 4           0.010171        0.008423          0.008283           0.088182   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.160211          0.106617  3    mt5-xxl           1  \n",
       " 1        0.158531          0.103896  3    mt5-xxl           1  \n",
       " 2        0.164042          0.108367  3    mt5-xxl           1  \n",
       " 3        0.158078          0.103312  3    mt5-xxl           1  \n",
       " 4        0.156713          0.100634  3    mt5-xxl           1  ,\n",
       " 'alpaca-native-1-shot':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.405391        0.282007          0.310173   \n",
       " 1       1           0.412078        0.281363          0.312348   \n",
       " 2       2           0.407123        0.280806          0.309494   \n",
       " 3       3           0.407814        0.291126          0.315758   \n",
       " 4       4           0.408484        0.284210          0.313072   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.092951        0.061658          0.068725           0.303192   \n",
       " 1           0.096546        0.061549          0.069675           0.306929   \n",
       " 2           0.094137        0.060858          0.068096           0.303803   \n",
       " 3           0.093521        0.063797          0.069419           0.302754   \n",
       " 4           0.091377        0.062063          0.068388           0.305875   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k     model_name keyword_num  \n",
       " 0        0.207486          0.229037  1  alpaca-native        None  \n",
       " 1        0.205001          0.229395  1  alpaca-native        None  \n",
       " 2        0.205985          0.227860  1  alpaca-native        None  \n",
       " 3        0.211181          0.230373  1  alpaca-native        None  \n",
       " 4        0.209389          0.231503  1  alpaca-native        None  ,\n",
       " 'mt5-xxl-2-shot-3-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.197254        0.203805          0.185758   \n",
       " 1       1           0.197254        0.203805          0.185758   \n",
       " 2       2           0.197254        0.203805          0.185758   \n",
       " 3       3           0.197254        0.203805          0.185758   \n",
       " 4       4           0.197254        0.203805          0.185758   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.000404        0.000343          0.000331             0.1955   \n",
       " 1           0.000404        0.000343          0.000331             0.1955   \n",
       " 2           0.000404        0.000343          0.000331             0.1955   \n",
       " 3           0.000404        0.000343          0.000331             0.1955   \n",
       " 4           0.000404        0.000343          0.000331             0.1955   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.201445          0.183843  2    mt5-xxl           3  \n",
       " 1        0.201445          0.183843  2    mt5-xxl           3  \n",
       " 2        0.201445          0.183843  2    mt5-xxl           3  \n",
       " 3        0.201445          0.183843  2    mt5-xxl           3  \n",
       " 4        0.201445          0.183843  2    mt5-xxl           3  ,\n",
       " 'mt5-xxl-2-shot-2-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.132478        0.185453          0.143185   \n",
       " 1       1           0.132478        0.185453          0.143185   \n",
       " 2       2           0.132478        0.185453          0.143185   \n",
       " 3       3           0.132478        0.185453          0.143185   \n",
       " 4       4           0.132478        0.185453          0.143185   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.000047        0.000111          0.000066           0.131561   \n",
       " 1           0.000047        0.000111          0.000066           0.131561   \n",
       " 2           0.000047        0.000111          0.000066           0.131561   \n",
       " 3           0.000047        0.000111          0.000066           0.131561   \n",
       " 4           0.000047        0.000111          0.000066           0.131561   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0         0.18401          0.142129  2    mt5-xxl           2  \n",
       " 1         0.18401          0.142129  2    mt5-xxl           2  \n",
       " 2         0.18401          0.142129  2    mt5-xxl           2  \n",
       " 3         0.18401          0.142129  2    mt5-xxl           2  \n",
       " 4         0.18401          0.142129  2    mt5-xxl           2  ,\n",
       " 'mt5-xxl-2-shot-1-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.074671        0.153110          0.093013   \n",
       " 1       1           0.077273        0.150057          0.092538   \n",
       " 2       2           0.073065        0.148252          0.090228   \n",
       " 3       3           0.078984        0.155885          0.096864   \n",
       " 4       4           0.076783        0.151416          0.093488   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.003538        0.004819          0.003722           0.073476   \n",
       " 1           0.005772        0.004554          0.004379           0.076816   \n",
       " 2           0.002380        0.002503          0.002290           0.072370   \n",
       " 3           0.004622        0.005888          0.004848           0.076767   \n",
       " 4           0.004663        0.004812          0.004258           0.075562   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.150969          0.091527  2    mt5-xxl           1  \n",
       " 1        0.149507          0.092062  2    mt5-xxl           1  \n",
       " 2        0.147416          0.089506  2    mt5-xxl           1  \n",
       " 3        0.152529          0.094316  2    mt5-xxl           1  \n",
       " 4        0.149683          0.092144  2    mt5-xxl           1  ,\n",
       " 'mt5-xxl-1-shot-3-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.197254        0.203805          0.185758   \n",
       " 1       1           0.197254        0.203805          0.185758   \n",
       " 2       2           0.197254        0.203805          0.185758   \n",
       " 3       3           0.197254        0.203805          0.185758   \n",
       " 4       4           0.197254        0.203805          0.185758   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.000404        0.000343          0.000331             0.1955   \n",
       " 1           0.000404        0.000343          0.000331             0.1955   \n",
       " 2           0.000404        0.000343          0.000331             0.1955   \n",
       " 3           0.000404        0.000343          0.000331             0.1955   \n",
       " 4           0.000404        0.000343          0.000331             0.1955   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.201445          0.183843  1    mt5-xxl           3  \n",
       " 1        0.201445          0.183843  1    mt5-xxl           3  \n",
       " 2        0.201445          0.183843  1    mt5-xxl           3  \n",
       " 3        0.201445          0.183843  1    mt5-xxl           3  \n",
       " 4        0.201445          0.183843  1    mt5-xxl           3  ,\n",
       " 'mt5-xxl-1-shot-2-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.132478        0.185453          0.143185   \n",
       " 1       1           0.132478        0.185453          0.143185   \n",
       " 2       2           0.132478        0.185453          0.143185   \n",
       " 3       3           0.132478        0.185453          0.143185   \n",
       " 4       4           0.132478        0.185453          0.143185   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.000047        0.000111          0.000066           0.131561   \n",
       " 1           0.000047        0.000111          0.000066           0.131561   \n",
       " 2           0.000047        0.000111          0.000066           0.131561   \n",
       " 3           0.000047        0.000111          0.000066           0.131561   \n",
       " 4           0.000047        0.000111          0.000066           0.131561   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0         0.18401          0.142129  1    mt5-xxl           2  \n",
       " 1         0.18401          0.142129  1    mt5-xxl           2  \n",
       " 2         0.18401          0.142129  1    mt5-xxl           2  \n",
       " 3         0.18401          0.142129  1    mt5-xxl           2  \n",
       " 4         0.18401          0.142129  1    mt5-xxl           2  ,\n",
       " 'llama-7b-hf-2-shot':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.437671        0.265685          0.310381   \n",
       " 1       1           0.423863        0.263383          0.303390   \n",
       " 2       2           0.436480        0.258411          0.304840   \n",
       " 3       3           0.423201        0.261422          0.302913   \n",
       " 4       4           0.434595        0.259540          0.304687   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.106896        0.061260          0.072295           0.324801   \n",
       " 1           0.101557        0.060294          0.070178           0.318110   \n",
       " 2           0.105790        0.059166          0.070802           0.323473   \n",
       " 3           0.101061        0.061060          0.070881           0.314505   \n",
       " 4           0.104727        0.059114          0.070628           0.326289   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k   model_name keyword_num  \n",
       " 0        0.191619          0.225881  2  llama-7b-hf        None  \n",
       " 1        0.193081          0.223985  2  llama-7b-hf        None  \n",
       " 2        0.187295          0.222540  2  llama-7b-hf        None  \n",
       " 3        0.190871          0.222327  2  llama-7b-hf        None  \n",
       " 4        0.190207          0.225033  2  llama-7b-hf        None  ,\n",
       " 'mt5-xl-3-shot-3-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.450434        0.378413          0.383987   \n",
       " 1       1           0.450730        0.378566          0.384202   \n",
       " 2       2           0.458081        0.381524          0.389166   \n",
       " 3       3           0.450008        0.378856          0.384578   \n",
       " 4       4           0.449494        0.380428          0.384605   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.183154        0.138372          0.146022           0.400386   \n",
       " 1           0.181935        0.137834          0.145555           0.400664   \n",
       " 2           0.187947        0.142863          0.150652           0.406763   \n",
       " 3           0.180673        0.138509          0.145735           0.401788   \n",
       " 4           0.187178        0.142972          0.150305           0.400496   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.325011          0.334940  3     mt5-xl           3  \n",
       " 1        0.324318          0.334899  3     mt5-xl           3  \n",
       " 2        0.327941          0.339333  3     mt5-xl           3  \n",
       " 3        0.327374          0.337264  3     mt5-xl           3  \n",
       " 4        0.329186          0.337194  3     mt5-xl           3  ,\n",
       " 'llama-7b-hf-3-shot':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.432104        0.264662          0.307585   \n",
       " 1       1           0.438885        0.266297          0.310536   \n",
       " 2       2           0.431114        0.266170          0.309271   \n",
       " 3       3           0.434821        0.269787          0.312412   \n",
       " 4       4           0.430962        0.267862          0.309903   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.105050        0.061836          0.072232           0.325239   \n",
       " 1           0.107845        0.061465          0.072811           0.325294   \n",
       " 2           0.107626        0.062515          0.073961           0.325420   \n",
       " 3           0.104205        0.062573          0.072943           0.327006   \n",
       " 4           0.105016        0.063196          0.073438           0.322369   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k   model_name keyword_num  \n",
       " 0        0.195135          0.228213  3  llama-7b-hf        None  \n",
       " 1        0.192547          0.226252  3  llama-7b-hf        None  \n",
       " 2        0.195704          0.229245  3  llama-7b-hf        None  \n",
       " 3        0.198439          0.231386  3  llama-7b-hf        None  \n",
       " 4        0.196231          0.228537  3  llama-7b-hf        None  ,\n",
       " 'mt5-xxl-1-shot-1-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.069763        0.148318          0.088401   \n",
       " 1       1           0.068089        0.145508          0.086212   \n",
       " 2       2           0.070790        0.148035          0.088796   \n",
       " 3       3           0.068660        0.146143          0.086762   \n",
       " 4       4           0.067257        0.145204          0.085717   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.001265        0.001998          0.001422           0.068977   \n",
       " 1           0.000618        0.000805          0.000639           0.067798   \n",
       " 2           0.002644        0.002796          0.002570           0.070148   \n",
       " 3           0.001493        0.001671          0.001462           0.068421   \n",
       " 4           0.000575        0.000795          0.000637           0.067049   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.146852          0.087414  1    mt5-xxl           1  \n",
       " 1        0.145247          0.085955  1    mt5-xxl           1  \n",
       " 2        0.146808          0.088024  1    mt5-xxl           1  \n",
       " 3        0.145814          0.086499  1    mt5-xxl           1  \n",
       " 4        0.144940          0.085488  1    mt5-xxl           1  ,\n",
       " 'mt5-xl-2-shot-3-keywords':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.443624        0.406640          0.395813   \n",
       " 1       1           0.445501        0.407109          0.397181   \n",
       " 2       2           0.442143        0.405106          0.395197   \n",
       " 3       3           0.450754        0.411729          0.401913   \n",
       " 4       4           0.448250        0.406301          0.398209   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.176455        0.147336          0.148866           0.393641   \n",
       " 1           0.180894        0.149484          0.151777           0.392819   \n",
       " 2           0.178552        0.149333          0.151088           0.391422   \n",
       " 3           0.182134        0.151353          0.154105           0.398254   \n",
       " 4           0.187799        0.154095          0.156798           0.397875   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.349340          0.345232  2     mt5-xl           3  \n",
       " 1        0.348266          0.344590  2     mt5-xl           3  \n",
       " 2        0.347496          0.344228  2     mt5-xl           3  \n",
       " 3        0.351911          0.348959  2     mt5-xl           3  \n",
       " 4        0.349683          0.347582  2     mt5-xl           3  ,\n",
       " 'mt5-xl-3-shot-2-keyword':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.390603        0.373044          0.355953   \n",
       " 1       1           0.390298        0.370551          0.354826   \n",
       " 2       2           0.384914        0.369092          0.351656   \n",
       " 3       3           0.391674        0.370662          0.356204   \n",
       " 4       4           0.387613        0.371507          0.353438   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.147148        0.126763          0.126016           0.344660   \n",
       " 1           0.147865        0.127706          0.127153           0.345106   \n",
       " 2           0.144568        0.127666          0.125779           0.340056   \n",
       " 3           0.149421        0.130628          0.129549           0.347112   \n",
       " 4           0.148890        0.129007          0.127615           0.344263   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.321600          0.310163  3     mt5-xl           2  \n",
       " 1        0.319375          0.309431  3     mt5-xl           2  \n",
       " 2        0.317610          0.306560  3     mt5-xl           2  \n",
       " 3        0.319479          0.310907  3     mt5-xl           2  \n",
       " 4        0.322798          0.310439  3     mt5-xl           2  ,\n",
       " 'mt5-xl-3-shot-1-keyword':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.325065        0.361396          0.320222   \n",
       " 1       1           0.321344        0.361328          0.317474   \n",
       " 2       2           0.321658        0.355351          0.314775   \n",
       " 3       3           0.320679        0.359515          0.317648   \n",
       " 4       4           0.322104        0.360519          0.318484   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.111693        0.117282          0.106144           0.285225   \n",
       " 1           0.110120        0.118821          0.105444           0.278836   \n",
       " 2           0.112133        0.117604          0.105452           0.282264   \n",
       " 3           0.109509        0.117941          0.105814           0.280786   \n",
       " 4           0.114404        0.120778          0.109198           0.283367   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.311032          0.278146  3     mt5-xl           1  \n",
       " 1        0.308505          0.272997  3     mt5-xl           1  \n",
       " 2        0.305160          0.273034  3     mt5-xl           1  \n",
       " 3        0.308863          0.275351  3     mt5-xl           1  \n",
       " 4        0.311463          0.277551  3     mt5-xl           1  ,\n",
       " 'mt5-xl-2-shot-2-keyword':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.377249        0.396809          0.361642   \n",
       " 1       1           0.379124        0.396397          0.361750   \n",
       " 2       2           0.379901        0.400766          0.364127   \n",
       " 3       3           0.377880        0.394783          0.360592   \n",
       " 4       4           0.381160        0.394109          0.362367   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.141561        0.139931          0.130979           0.330492   \n",
       " 1           0.142740        0.139339          0.131027           0.330448   \n",
       " 2           0.139076        0.137070          0.128323           0.331285   \n",
       " 3           0.138779        0.135350          0.127236           0.330466   \n",
       " 4           0.144351        0.139955          0.132048           0.335058   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.339670          0.313031  2     mt5-xl           2  \n",
       " 1        0.338554          0.311896  2     mt5-xl           2  \n",
       " 2        0.343186          0.314099  2     mt5-xl           2  \n",
       " 3        0.338155          0.311849  2     mt5-xl           2  \n",
       " 4        0.338653          0.314571  2     mt5-xl           2  ,\n",
       " 'mt5-xl-2-shot-1-keyword':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.314398        0.386553          0.324556   \n",
       " 1       1           0.315790        0.389167          0.326057   \n",
       " 2       2           0.312738        0.384537          0.323110   \n",
       " 3       3           0.316258        0.386961          0.325928   \n",
       " 4       4           0.317966        0.386061          0.326340   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.108229        0.128164          0.108754           0.269861   \n",
       " 1           0.107225        0.126275          0.107673           0.271420   \n",
       " 2           0.106497        0.125927          0.107271           0.269254   \n",
       " 3           0.108966        0.128362          0.109275           0.272377   \n",
       " 4           0.112254        0.131794          0.112193           0.274666   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.326115          0.276008  2     mt5-xl           1  \n",
       " 1        0.329012          0.277918  2     mt5-xl           1  \n",
       " 2        0.326592          0.276154  2     mt5-xl           1  \n",
       " 3        0.329016          0.278730  2     mt5-xl           1  \n",
       " 4        0.328462          0.279573  2     mt5-xl           1  ,\n",
       " 'mt5-xl-1-shot-3-keyword':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.435668        0.456239          0.415833   \n",
       " 1       1           0.428496        0.450832          0.410678   \n",
       " 2       2           0.429378        0.451776          0.410923   \n",
       " 3       3           0.428140        0.448505          0.408737   \n",
       " 4       4           0.427577        0.446597          0.407214   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.173703        0.169932          0.159608           0.380973   \n",
       " 1           0.170280        0.164613          0.155637           0.374287   \n",
       " 2           0.169746        0.163789          0.155074           0.374318   \n",
       " 3           0.173671        0.164436          0.156904           0.374976   \n",
       " 4           0.172651        0.164137          0.156454           0.374550   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.389286          0.359337  1     mt5-xl           3  \n",
       " 1        0.384335          0.354179  1     mt5-xl           3  \n",
       " 2        0.382407          0.352979  1     mt5-xl           3  \n",
       " 3        0.381924          0.352771  1     mt5-xl           3  \n",
       " 4        0.381459          0.352203  1     mt5-xl           3  ,\n",
       " 'mt5-xl-1-shot-2-keyword':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.364190        0.442471          0.372455   \n",
       " 1       1           0.366042        0.439176          0.372267   \n",
       " 2       2           0.364100        0.439719          0.372258   \n",
       " 3       3           0.365207        0.442040          0.374032   \n",
       " 4       4           0.361940        0.437573          0.370729   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.134475        0.154882          0.134000           0.311738   \n",
       " 1           0.136910        0.152691          0.134281           0.313502   \n",
       " 2           0.136266        0.154596          0.135150           0.316797   \n",
       " 3           0.134863        0.152518          0.133888           0.315507   \n",
       " 4           0.134384        0.152269          0.133486           0.313601   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.375490          0.317281  1     mt5-xl           2  \n",
       " 1        0.371311          0.316477  1     mt5-xl           2  \n",
       " 2        0.377795          0.321499  1     mt5-xl           2  \n",
       " 3        0.376690          0.320807  1     mt5-xl           2  \n",
       " 4        0.374932          0.319187  1     mt5-xl           2  ,\n",
       " 'mt5-xl-1-shot-1-keyword':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.292010        0.420914          0.322290   \n",
       " 1       1           0.296435        0.426180          0.327425   \n",
       " 2       2           0.295440        0.430054          0.328151   \n",
       " 3       3           0.296828        0.424162          0.327956   \n",
       " 4       4           0.292563        0.420636          0.323630   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.100288        0.144227          0.109819           0.246213   \n",
       " 1           0.104588        0.147207          0.113555           0.248779   \n",
       " 2           0.103256        0.148017          0.113052           0.248954   \n",
       " 3           0.102463        0.144417          0.111743           0.249440   \n",
       " 4           0.100346        0.142684          0.109609           0.246216   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.351452          0.270294  1     mt5-xl           1  \n",
       " 1        0.355695          0.273559  1     mt5-xl           1  \n",
       " 2        0.358307          0.275051  1     mt5-xl           1  \n",
       " 3        0.353135          0.274150  1     mt5-xl           1  \n",
       " 4        0.350051          0.270737  1     mt5-xl           1  ,\n",
       " 'bloom-3b-5-shot':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.430828        0.277476          0.306624   \n",
       " 1       1           0.430446        0.274711          0.304147   \n",
       " 2       2           0.436325        0.278242          0.309229   \n",
       " 3       3           0.429306        0.275791          0.306416   \n",
       " 4       4           0.425062        0.286732          0.310845   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.097957        0.060999          0.068153           0.312366   \n",
       " 1           0.093230        0.058359          0.063872           0.313207   \n",
       " 2           0.096749        0.059238          0.066537           0.311271   \n",
       " 3           0.095702        0.061276          0.067546           0.313809   \n",
       " 4           0.095300        0.059357          0.065612           0.309418   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.196241          0.218562  5   bloom-3b        None  \n",
       " 1        0.194231          0.216975  5   bloom-3b        None  \n",
       " 2        0.194657          0.217382  5   bloom-3b        None  \n",
       " 3        0.198063          0.220774  5   bloom-3b        None  \n",
       " 4        0.203544          0.222006  5   bloom-3b        None  ,\n",
       " 'Cerebras-GPT-6.7B-2-shot':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.476642        0.267452          0.315792   \n",
       " 1       1           0.476252        0.265045          0.313737   \n",
       " 2       2           0.479764        0.261893          0.314436   \n",
       " 3       3           0.475657        0.268140          0.317792   \n",
       " 4       4           0.472903        0.264242          0.312728   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.121202        0.060595          0.074501           0.346163   \n",
       " 1           0.120570        0.061376          0.074330           0.348122   \n",
       " 2           0.116000        0.059318          0.072006           0.349380   \n",
       " 3           0.119557        0.063691          0.076055           0.345840   \n",
       " 4           0.120199        0.062037          0.074997           0.344840   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k         model_name keyword_num  \n",
       " 0        0.187628          0.223673  2  Cerebras-GPT-6.7B        None  \n",
       " 1        0.185646          0.222417  2  Cerebras-GPT-6.7B        None  \n",
       " 2        0.184279          0.223511  2  Cerebras-GPT-6.7B        None  \n",
       " 3        0.189247          0.226202  2  Cerebras-GPT-6.7B        None  \n",
       " 4        0.186848          0.222727  2  Cerebras-GPT-6.7B        None  ,\n",
       " 'Cerebras-GPT-6.7B-1-shot':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.457037        0.271076          0.310482   \n",
       " 1       1           0.460305        0.262863          0.307554   \n",
       " 2       2           0.457640        0.265356          0.306358   \n",
       " 3       3           0.459516        0.264809          0.305560   \n",
       " 4       4           0.457633        0.262353          0.305092   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.112572        0.061505          0.071467           0.333622   \n",
       " 1           0.109104        0.056605          0.068143           0.334252   \n",
       " 2           0.108772        0.057935          0.068471           0.336241   \n",
       " 3           0.111163        0.058460          0.068981           0.334174   \n",
       " 4           0.112454        0.057418          0.069073           0.336507   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k         model_name keyword_num  \n",
       " 0        0.192297          0.221682  1  Cerebras-GPT-6.7B        None  \n",
       " 1        0.184727          0.218192  1  Cerebras-GPT-6.7B        None  \n",
       " 2        0.187247          0.218727  1  Cerebras-GPT-6.7B        None  \n",
       " 3        0.185987          0.216679  1  Cerebras-GPT-6.7B        None  \n",
       " 4        0.187099          0.219041  1  Cerebras-GPT-6.7B        None  ,\n",
       " 'llama-7b-hf-1-shot':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.431931        0.252426          0.297348   \n",
       " 1       1           0.437103        0.250974          0.296973   \n",
       " 2       2           0.423837        0.248366          0.292270   \n",
       " 3       3           0.422479        0.249433          0.291386   \n",
       " 4       4           0.427976        0.249376          0.293450   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.102890        0.057693          0.068770           0.322528   \n",
       " 1           0.105282        0.057676          0.068879           0.322644   \n",
       " 2           0.101924        0.055305          0.066367           0.317199   \n",
       " 3           0.102662        0.057682          0.067817           0.315080   \n",
       " 4           0.098162        0.053510          0.064106           0.316756   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k   model_name keyword_num  \n",
       " 0        0.183735          0.217739  1  llama-7b-hf        None  \n",
       " 1        0.181442          0.215789  1  llama-7b-hf        None  \n",
       " 2        0.181877          0.215124  1  llama-7b-hf        None  \n",
       " 3        0.181688          0.213436  1  llama-7b-hf        None  \n",
       " 4        0.180380          0.213234  1  llama-7b-hf        None  ,\n",
       " 'opt-iml-1.3b-3-shot':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.275302        0.562388          0.345240   \n",
       " 1       1           0.277373        0.558654          0.347269   \n",
       " 2       2           0.278842        0.556453          0.348904   \n",
       " 3       3           0.277418        0.550946          0.346180   \n",
       " 4       4           0.274954        0.553990          0.343956   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.077666        0.170340          0.097789           0.222434   \n",
       " 1           0.079981        0.171410          0.100625           0.225200   \n",
       " 2           0.079549        0.170472          0.100709           0.225227   \n",
       " 3           0.077605        0.166647          0.098301           0.220738   \n",
       " 4           0.077538        0.167608          0.097302           0.221771   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k    model_name keyword_num  \n",
       " 0        0.453218          0.277719  3  opt-iml-1.3b        None  \n",
       " 1        0.452121          0.280890  3  opt-iml-1.3b        None  \n",
       " 2        0.449567          0.281363  3  opt-iml-1.3b        None  \n",
       " 3        0.439228          0.275065  3  opt-iml-1.3b        None  \n",
       " 4        0.447808          0.277001  3  opt-iml-1.3b        None  ,\n",
       " 'opt-iml-1.3b-2-shot':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.274320        0.557800          0.344490   \n",
       " 1       1           0.271005        0.558589          0.342353   \n",
       " 2       2           0.273105        0.554241          0.342104   \n",
       " 3       3           0.275747        0.559856          0.346665   \n",
       " 4       4           0.267853        0.554134          0.338268   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.079050        0.171996          0.099626           0.220749   \n",
       " 1           0.075425        0.168336          0.096078           0.218451   \n",
       " 2           0.077171        0.171117          0.097677           0.220369   \n",
       " 3           0.079976        0.173681          0.101121           0.224059   \n",
       " 4           0.074487        0.167733          0.095302           0.215444   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k    model_name keyword_num  \n",
       " 0        0.449691          0.276545  2  opt-iml-1.3b        None  \n",
       " 1        0.448912          0.275078  2  opt-iml-1.3b        None  \n",
       " 2        0.447938          0.275181  2  opt-iml-1.3b        None  \n",
       " 3        0.454142          0.280897  2  opt-iml-1.3b        None  \n",
       " 4        0.447629          0.271883  2  opt-iml-1.3b        None  ,\n",
       " 'opt-iml-1.3b-1-shot':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.252706        0.520571          0.318363   \n",
       " 1       1           0.252311        0.523946          0.319170   \n",
       " 2       2           0.255965        0.516127          0.319616   \n",
       " 3       3           0.259432        0.529732          0.326895   \n",
       " 4       4           0.253842        0.516054          0.319137   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.072936        0.158215          0.092133           0.206221   \n",
       " 1           0.069985        0.156554          0.089530           0.204734   \n",
       " 2           0.074342        0.161717          0.093681           0.206463   \n",
       " 3           0.074729        0.165098          0.095138           0.209722   \n",
       " 4           0.071514        0.158423          0.091435           0.203865   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k    model_name keyword_num  \n",
       " 0        0.424696          0.259261  1  opt-iml-1.3b        None  \n",
       " 1        0.423685          0.258240  1  opt-iml-1.3b        None  \n",
       " 2        0.419641          0.257952  1  opt-iml-1.3b        None  \n",
       " 3        0.427061          0.263428  1  opt-iml-1.3b        None  \n",
       " 4        0.414667          0.255852  1  opt-iml-1.3b        None  ,\n",
       " 'bloom-3b-3-shot':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.423920        0.274508          0.299422   \n",
       " 1       1           0.421544        0.274770          0.299930   \n",
       " 2       2           0.429524        0.271181          0.301401   \n",
       " 3       3           0.426642        0.270086          0.298865   \n",
       " 4       4           0.422577        0.270867          0.299487   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.093202        0.057404          0.062260           0.310011   \n",
       " 1           0.089691        0.058805          0.062718           0.302099   \n",
       " 2           0.098341        0.059134          0.066256           0.310880   \n",
       " 3           0.095436        0.059445          0.064981           0.309474   \n",
       " 4           0.093521        0.057500          0.064053           0.305875   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.194704          0.214085  3   bloom-3b        None  \n",
       " 1        0.193436          0.211665  3   bloom-3b        None  \n",
       " 2        0.191774          0.214553  3   bloom-3b        None  \n",
       " 3        0.192144          0.213095  3   bloom-3b        None  \n",
       " 4        0.192020          0.213382  3   bloom-3b        None  ,\n",
       " 'bloom-3b-2-shot':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.422086        0.261727          0.294260   \n",
       " 1       1           0.415053        0.266735          0.291092   \n",
       " 2       2           0.422470        0.266322          0.294926   \n",
       " 3       3           0.412088        0.264067          0.290228   \n",
       " 4       4           0.423337        0.274901          0.299414   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.091234        0.052875          0.060581           0.305427   \n",
       " 1           0.089562        0.055607          0.060224           0.302566   \n",
       " 2           0.090818        0.055860          0.061774           0.306998   \n",
       " 3           0.085638        0.052320          0.057428           0.298550   \n",
       " 4           0.091405        0.058774          0.063312           0.305349   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.185396          0.209799  2   bloom-3b        None  \n",
       " 1        0.189996          0.208192  2   bloom-3b        None  \n",
       " 2        0.188646          0.210527  2   bloom-3b        None  \n",
       " 3        0.187094          0.206363  2   bloom-3b        None  \n",
       " 4        0.193952          0.211891  2   bloom-3b        None  ,\n",
       " 'bloom-3b-1-shot':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.385609        0.278956          0.289405   \n",
       " 1       1           0.389904        0.282546          0.290895   \n",
       " 2       2           0.388124        0.281078          0.290774   \n",
       " 3       3           0.396155        0.272478          0.289160   \n",
       " 4       4           0.393492        0.275203          0.291346   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.081336        0.055034          0.058296           0.283752   \n",
       " 1           0.080644        0.057154          0.058601           0.286052   \n",
       " 2           0.078673        0.056107          0.057097           0.284107   \n",
       " 3           0.080541        0.053731          0.056849           0.288200   \n",
       " 4           0.082224        0.056240          0.059583           0.287422   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.200596          0.208805  1   bloom-3b        None  \n",
       " 1        0.203245          0.209562  1   bloom-3b        None  \n",
       " 2        0.200855          0.209529  1   bloom-3b        None  \n",
       " 3        0.194725          0.207268  1   bloom-3b        None  \n",
       " 4        0.197182          0.209460  1   bloom-3b        None  ,\n",
       " 'bloom-7b1-3-shot':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.437732        0.296954          0.325205   \n",
       " 1       1           0.441939        0.293096          0.324836   \n",
       " 2       2           0.437394        0.286401          0.320360   \n",
       " 3       3           0.435849        0.282023          0.315286   \n",
       " 4       4           0.440969        0.284700          0.318157   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.106035        0.072034          0.077909           0.321164   \n",
       " 1           0.108350        0.070662          0.077954           0.324448   \n",
       " 2           0.107842        0.066483          0.075751           0.322240   \n",
       " 3           0.104864        0.067877          0.075584           0.321676   \n",
       " 4           0.107891        0.067274          0.075059           0.324932   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.213819          0.235001  3  bloom-7b1        None  \n",
       " 1        0.209898          0.234292  3  bloom-7b1        None  \n",
       " 2        0.205900          0.232090  3  bloom-7b1        None  \n",
       " 3        0.202965          0.228504  3  bloom-7b1        None  \n",
       " 4        0.205076          0.230417  3  bloom-7b1        None  ,\n",
       " 'bloom-7b1-5-shot':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.434945        0.285681          0.317874   \n",
       " 1       1           0.436449        0.282715          0.317228   \n",
       " 2       2           0.428941        0.291614          0.321497   \n",
       " 3       3           0.429495        0.284217          0.315617   \n",
       " 4       4           0.424935        0.284473          0.314951   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.107235        0.068142          0.076391           0.319388   \n",
       " 1           0.103156        0.064078          0.072650           0.318825   \n",
       " 2           0.108885        0.071057          0.078822           0.316139   \n",
       " 3           0.105817        0.067360          0.075279           0.314510   \n",
       " 4           0.103132        0.065184          0.072852           0.308813   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.205385          0.229984  5  bloom-7b1        None  \n",
       " 1        0.202147          0.227995  5  bloom-7b1        None  \n",
       " 2        0.209497          0.232744  5  bloom-7b1        None  \n",
       " 3        0.204041          0.227905  5  bloom-7b1        None  \n",
       " 4        0.200513          0.224083  5  bloom-7b1        None  ,\n",
       " 'bloom-7b1-2-shot':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.440946        0.284364          0.318600   \n",
       " 1       1           0.441744        0.286907          0.316919   \n",
       " 2       2           0.444291        0.283313          0.318781   \n",
       " 3       3           0.434921        0.280885          0.314480   \n",
       " 4       4           0.438698        0.281452          0.318391   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.108011        0.066194          0.075043           0.325326   \n",
       " 1           0.106416        0.064793          0.072173           0.323868   \n",
       " 2           0.102998        0.065310          0.073620           0.321441   \n",
       " 3           0.104349        0.066182          0.073943           0.324039   \n",
       " 4           0.110074        0.066323          0.076131           0.322243   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.205595          0.231755  2  bloom-7b1        None  \n",
       " 1        0.204690          0.227511  2  bloom-7b1        None  \n",
       " 2        0.201112          0.227344  2  bloom-7b1        None  \n",
       " 3        0.205061          0.230846  2  bloom-7b1        None  \n",
       " 4        0.200829          0.229134  2  bloom-7b1        None  ,\n",
       " 'bloom-7b1-1-shot':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.424849        0.292030          0.317299   \n",
       " 1       1           0.427457        0.297854          0.321774   \n",
       " 2       2           0.422711        0.295399          0.317942   \n",
       " 3       3           0.419846        0.283574          0.308887   \n",
       " 4       4           0.430558        0.294262          0.321027   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.103488        0.068473          0.074597           0.313347   \n",
       " 1           0.099339        0.067411          0.073015           0.314268   \n",
       " 2           0.096076        0.063870          0.069262           0.312373   \n",
       " 3           0.099449        0.065640          0.071239           0.307658   \n",
       " 4           0.104767        0.070633          0.076667           0.316802   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.210754          0.230590  1  bloom-7b1        None  \n",
       " 1        0.215709          0.234005  1  bloom-7b1        None  \n",
       " 2        0.212465          0.230663  1  bloom-7b1        None  \n",
       " 3        0.203676          0.222833  1  bloom-7b1        None  \n",
       " 4        0.213173          0.233124  1  bloom-7b1        None  ,\n",
       " 'Cerebras-GPT-13B-3-shot':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.473963        0.266568          0.315077   \n",
       " 1       1           0.477251        0.265131          0.314228   \n",
       " 2       2           0.473552        0.267655          0.316198   \n",
       " 3       3           0.476107        0.269340          0.319550   \n",
       " 4       4           0.471823        0.268800          0.316046   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.117134        0.061423          0.073575           0.346376   \n",
       " 1           0.117762        0.060093          0.072756           0.346549   \n",
       " 2           0.117065        0.061367          0.073590           0.346155   \n",
       " 3           0.119295        0.063801          0.076832           0.348309   \n",
       " 4           0.109801        0.060141          0.070684           0.342129   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k        model_name keyword_num  \n",
       " 0        0.187437          0.223951  3  Cerebras-GPT-13B        None  \n",
       " 1        0.185830          0.222308  3  Cerebras-GPT-13B        None  \n",
       " 2        0.189164          0.225506  3  Cerebras-GPT-13B        None  \n",
       " 3        0.190079          0.228039  3  Cerebras-GPT-13B        None  \n",
       " 4        0.188788          0.223927  3  Cerebras-GPT-13B        None  ,\n",
       " 'Cerebras-GPT-13B-2-shot':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.464778        0.264428          0.310331   \n",
       " 1       1           0.465538        0.265901          0.310217   \n",
       " 2       2           0.470675        0.268302          0.314930   \n",
       " 3       3           0.467007        0.270745          0.315684   \n",
       " 4       4           0.463105        0.261865          0.308940   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.107494        0.058612          0.068796           0.336376   \n",
       " 1           0.108547        0.056571          0.067611           0.339318   \n",
       " 2           0.109593        0.058339          0.069674           0.340698   \n",
       " 3           0.108963        0.061367          0.071788           0.339604   \n",
       " 4           0.106760        0.056116          0.067614           0.334997   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k        model_name keyword_num  \n",
       " 0        0.184605          0.218947  2  Cerebras-GPT-13B        None  \n",
       " 1        0.186137          0.220037  2  Cerebras-GPT-13B        None  \n",
       " 2        0.187609          0.222600  2  Cerebras-GPT-13B        None  \n",
       " 3        0.191499          0.224982  2  Cerebras-GPT-13B        None  \n",
       " 4        0.184304          0.218688  2  Cerebras-GPT-13B        None  ,\n",
       " 'Cerebras-GPT-13B-1-shot':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.440558        0.280108          0.310862   \n",
       " 1       1           0.440882        0.276795          0.308275   \n",
       " 2       2           0.441438        0.271706          0.307060   \n",
       " 3       3           0.440341        0.269768          0.304665   \n",
       " 4       4           0.451407        0.272358          0.309968   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.107019        0.064301          0.071879           0.322121   \n",
       " 1           0.101371        0.059688          0.067724           0.317326   \n",
       " 2           0.104001        0.060252          0.068694           0.322471   \n",
       " 3           0.103138        0.058722          0.067571           0.320240   \n",
       " 4           0.103478        0.058106          0.067312           0.330028   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k        model_name keyword_num  \n",
       " 0        0.199160          0.222702  1  Cerebras-GPT-13B        None  \n",
       " 1        0.194926          0.218011  1  Cerebras-GPT-13B        None  \n",
       " 2        0.193961          0.220422  1  Cerebras-GPT-13B        None  \n",
       " 3        0.190404          0.216752  1  Cerebras-GPT-13B        None  \n",
       " 4        0.193654          0.221907  1  Cerebras-GPT-13B        None  ,\n",
       " 'Cerebras-GPT-2.7B-3-shot':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.423818        0.276157          0.303564   \n",
       " 1       1           0.418407        0.267110          0.298324   \n",
       " 2       2           0.421248        0.279534          0.307947   \n",
       " 3       3           0.473432        0.232676          0.275781   \n",
       " 4       4                NaN             NaN               NaN   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.100494        0.061363          0.068447           0.311393   \n",
       " 1           0.093745        0.056475          0.063840           0.304324   \n",
       " 2           0.097090        0.061931          0.068570           0.311781   \n",
       " 3           0.116537        0.052420          0.063987           0.363226   \n",
       " 4                NaN             NaN               NaN                NaN   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k         model_name keyword_num  \n",
       " 0        0.196909          0.218427  3  Cerebras-GPT-2.7B        None  \n",
       " 1        0.188782          0.212605  3  Cerebras-GPT-2.7B        None  \n",
       " 2        0.201058          0.223605  3  Cerebras-GPT-2.7B        None  \n",
       " 3        0.161724          0.199908  3  Cerebras-GPT-2.7B        None  \n",
       " 4             NaN               NaN  3  Cerebras-GPT-2.7B        None  ,\n",
       " 'Cerebras-GPT-2.7B-1-shot':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.390649        0.277961          0.293974   \n",
       " 1       1           0.385975        0.273465          0.290003   \n",
       " 2       2           0.390626        0.277688          0.294590   \n",
       " 3       3           0.384018        0.268861          0.286730   \n",
       " 4       4           0.393350        0.268710          0.289563   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.089276        0.062059          0.065343           0.291167   \n",
       " 1           0.085997        0.057969          0.062014           0.283549   \n",
       " 2           0.087221        0.059855          0.063863           0.289799   \n",
       " 3           0.079686        0.055336          0.058934           0.281614   \n",
       " 4           0.087381        0.056797          0.062135           0.290942   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k         model_name keyword_num  \n",
       " 0        0.201927          0.215252  1  Cerebras-GPT-2.7B        None  \n",
       " 1        0.196512          0.209557  1  Cerebras-GPT-2.7B        None  \n",
       " 2        0.200326          0.214497  1  Cerebras-GPT-2.7B        None  \n",
       " 3        0.192655          0.206827  1  Cerebras-GPT-2.7B        None  \n",
       " 4        0.194081          0.210370  1  Cerebras-GPT-2.7B        None  ,\n",
       " 'Cerebras-GPT-2.7B-2-shot':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.411344        0.276992          0.303018   \n",
       " 1       1           0.413818        0.287906          0.309409   \n",
       " 2       2           0.413759        0.276993          0.303159   \n",
       " 3       3           0.409830        0.276223          0.302710   \n",
       " 4       4           0.412363        0.270408          0.299015   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.091348        0.058637          0.065171           0.301379   \n",
       " 1           0.097470        0.064826          0.070178           0.304825   \n",
       " 2           0.091684        0.058133          0.064481           0.301829   \n",
       " 3           0.089914        0.057658          0.064106           0.303099   \n",
       " 4           0.097609        0.059779          0.067418           0.303480   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k         model_name keyword_num  \n",
       " 0        0.197269          0.217596  2  Cerebras-GPT-2.7B        None  \n",
       " 1        0.205958          0.223530  2  Cerebras-GPT-2.7B        None  \n",
       " 2        0.196863          0.217384  2  Cerebras-GPT-2.7B        None  \n",
       " 3        0.198231          0.219386  2  Cerebras-GPT-2.7B        None  \n",
       " 4        0.193203          0.215656  2  Cerebras-GPT-2.7B        None  ,\n",
       " 'Cerebras-6.7B-3-shot':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.471769        0.276960          0.322585   \n",
       " 1       1           0.476150        0.268293          0.316708   \n",
       " 2       2           0.465782        0.276930          0.320845   \n",
       " 3       3           0.463989        0.215693          0.276924   \n",
       " 4       4                NaN             NaN               NaN   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.122780        0.067054          0.079687           0.343574   \n",
       " 1           0.118427        0.062601          0.075014           0.343728   \n",
       " 2           0.113802        0.063523          0.074800           0.338412   \n",
       " 3           0.075974        0.032337          0.041356           0.315737   \n",
       " 4                NaN             NaN               NaN                NaN   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k         model_name keyword_num  \n",
       " 0        0.196122          0.230300  3  Cerebras-GPT-6.7B        None  \n",
       " 1        0.187614          0.223295  3  Cerebras-GPT-6.7B        None  \n",
       " 2        0.194863          0.227914  3  Cerebras-GPT-6.7B        None  \n",
       " 3        0.146245          0.187832  3  Cerebras-GPT-6.7B        None  \n",
       " 4             NaN               NaN  3  Cerebras-GPT-6.7B        None  ,\n",
       " 'mt5-xxl-5-shot':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.241188        0.222625          0.211505   \n",
       " 1       1           0.248789        0.232814          0.220933   \n",
       " 2       2           0.245563        0.229097          0.217467   \n",
       " 3       3           0.236997        0.221463          0.209818   \n",
       " 4       4           0.235591        0.226575          0.212899   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.083463        0.065321          0.065947           0.221538   \n",
       " 1           0.082743        0.067984          0.067101           0.226834   \n",
       " 2           0.086155        0.071148          0.070629           0.225602   \n",
       " 3           0.079218        0.064405          0.063896           0.218351   \n",
       " 4           0.077302        0.067387          0.065053           0.217558   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.198500          0.191251  5    mt5-xxl        None  \n",
       " 1        0.207627          0.199079  5    mt5-xxl        None  \n",
       " 2        0.204672          0.196848  5    mt5-xxl        None  \n",
       " 3        0.198879          0.190674  5    mt5-xxl        None  \n",
       " 4        0.204347          0.194015  5    mt5-xxl        None  ,\n",
       " 'mt5-xxl-3-shot':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.236490        0.241900          0.220055   \n",
       " 1       1           0.232741        0.234307          0.215534   \n",
       " 2       2           0.236015        0.240379          0.219621   \n",
       " 3       3           0.233789        0.239385          0.219248   \n",
       " 4       4           0.228830        0.239781          0.216145   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.079688        0.072868          0.068382           0.216344   \n",
       " 1           0.084673        0.075519          0.072397           0.216366   \n",
       " 2           0.083151        0.073539          0.070907           0.217596   \n",
       " 3           0.080178        0.075549          0.071445           0.215973   \n",
       " 4           0.078796        0.075109          0.069845           0.211244   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.216685          0.199036  3    mt5-xxl        None  \n",
       " 1        0.212932          0.198070  3    mt5-xxl        None  \n",
       " 2        0.215952          0.199843  3    mt5-xxl        None  \n",
       " 3        0.215851          0.200190  3    mt5-xxl        None  \n",
       " 4        0.215816          0.197031  3    mt5-xxl        None  ,\n",
       " 'mt5-xxl-2-shot':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.238934        0.276884          0.238251   \n",
       " 1       1           0.232939        0.272167          0.233521   \n",
       " 2       2           0.237121        0.277563          0.238438   \n",
       " 3       3           0.228650        0.265489          0.228651   \n",
       " 4       4           0.234084        0.265015          0.230699   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.084303        0.087646          0.078825           0.216557   \n",
       " 1           0.082469        0.090638          0.079174           0.212997   \n",
       " 2           0.077050        0.085477          0.074753           0.213976   \n",
       " 3           0.078075        0.083331          0.074227           0.206013   \n",
       " 4           0.081794        0.083686          0.075981           0.212975   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.245205          0.213648  2    mt5-xxl        None  \n",
       " 1        0.244368          0.211513  2    mt5-xxl        None  \n",
       " 2        0.244910          0.212858  2    mt5-xxl        None  \n",
       " 3        0.233393          0.203467  2    mt5-xxl        None  \n",
       " 4        0.234821          0.207275  2    mt5-xxl        None  ,\n",
       " 'mt5-xxl-1-shot':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.276930        0.410621          0.306696   \n",
       " 1       1           0.277748        0.403402          0.305461   \n",
       " 2       2           0.280048        0.412360          0.308453   \n",
       " 3       3           0.280692        0.411945          0.310871   \n",
       " 4       4           0.280411        0.413258          0.310904   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.094998        0.137898          0.101572           0.234455   \n",
       " 1           0.094185        0.133566          0.101137           0.235159   \n",
       " 2           0.096242        0.138824          0.102850           0.238271   \n",
       " 3           0.098894        0.143197          0.107025           0.239358   \n",
       " 4           0.097217        0.139527          0.104962           0.238311   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.340094          0.256769  1    mt5-xxl        None  \n",
       " 1        0.334224          0.256036  1    mt5-xxl        None  \n",
       " 2        0.342527          0.259075  1    mt5-xxl        None  \n",
       " 3        0.345989          0.263071  1    mt5-xxl        None  \n",
       " 4        0.342733          0.260756  1    mt5-xxl        None  ,\n",
       " 'mt5-xl-5-shot':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.246259        0.286924          0.246735   \n",
       " 1       1           0.254101        0.295902          0.254687   \n",
       " 2       2           0.251934        0.292268          0.251630   \n",
       " 3       3           0.247903        0.281153          0.244987   \n",
       " 4       4           0.253728        0.289305          0.252765   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.072565        0.082814          0.070736           0.218836   \n",
       " 1           0.082783        0.089288          0.078749           0.224594   \n",
       " 2           0.078165        0.089430          0.076501           0.223948   \n",
       " 3           0.076790        0.084232          0.073047           0.222682   \n",
       " 4           0.076463        0.083833          0.073978           0.224318   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.249457          0.217045  5     mt5-xl        None  \n",
       " 1        0.255009          0.222293  5     mt5-xl        None  \n",
       " 2        0.254279          0.221319  5     mt5-xl        None  \n",
       " 3        0.247593          0.217609  5     mt5-xl        None  \n",
       " 4        0.250194          0.221004  5     mt5-xl        None  ,\n",
       " 'mt5-xl-3-shot':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.235720        0.319267          0.253861   \n",
       " 1       1           0.223928        0.309401          0.242074   \n",
       " 2       2           0.227933        0.313569          0.246681   \n",
       " 3       3           0.230938        0.315265          0.249775   \n",
       " 4       4           0.233539        0.321322          0.252998   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.073965        0.097464          0.077560           0.206526   \n",
       " 1           0.064901        0.090784          0.069841           0.194799   \n",
       " 2           0.068274        0.093966          0.073164           0.200093   \n",
       " 3           0.068941        0.093757          0.073982           0.201783   \n",
       " 4           0.072574        0.096151          0.076520           0.202224   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.274385          0.220114  3     mt5-xl        None  \n",
       " 1        0.264558          0.208848  3     mt5-xl        None  \n",
       " 2        0.269195          0.214076  3     mt5-xl        None  \n",
       " 3        0.270114          0.216201  3     mt5-xl        None  \n",
       " 4        0.273180          0.217067  3     mt5-xl        None  ,\n",
       " 'mt5-xl-2-shot':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.213259        0.333078          0.244458   \n",
       " 1       1           0.209140        0.325649          0.239136   \n",
       " 2       2           0.215811        0.333980          0.245912   \n",
       " 3       3           0.219396        0.339586          0.250128   \n",
       " 4       4           0.222453        0.340189          0.252077   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.063469        0.098682          0.071533           0.183367   \n",
       " 1           0.059523        0.095379          0.068495           0.179217   \n",
       " 2           0.061150        0.097347          0.070026           0.185307   \n",
       " 3           0.066035        0.104037          0.075034           0.188802   \n",
       " 4           0.067514        0.101921          0.074789           0.192207   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.282486          0.208689  2     mt5-xl        None  \n",
       " 1        0.276017          0.203710  2     mt5-xl        None  \n",
       " 2        0.284201          0.210243  2     mt5-xl        None  \n",
       " 3        0.288734          0.213872  2     mt5-xl        None  \n",
       " 4        0.289050          0.216062  2     mt5-xl        None  ,\n",
       " 'mt5-xl-1-shot':    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       " 0       0           0.178518        0.332754          0.218909   \n",
       " 1       1           0.173666        0.326056          0.213719   \n",
       " 2       2           0.176983        0.331910          0.216641   \n",
       " 3       3           0.170631        0.316088          0.209103   \n",
       " 4       4           0.175261        0.330738          0.216730   \n",
       " \n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       " 0           0.046007        0.092584          0.057901           0.153327   \n",
       " 1           0.048374        0.092562          0.059750           0.149165   \n",
       " 2           0.046839        0.089553          0.056979           0.152282   \n",
       " 3           0.043807        0.084010          0.053941           0.146054   \n",
       " 4           0.045021        0.088607          0.056227           0.149743   \n",
       " \n",
       "    rouge_L_recall  rouge_L_fmeasure  k model_name keyword_num  \n",
       " 0        0.284792          0.187640  1     mt5-xl        None  \n",
       " 1        0.277326          0.182792  1     mt5-xl        None  \n",
       " 2        0.282408          0.185493  1     mt5-xl        None  \n",
       " 3        0.268617          0.178330  1     mt5-xl        None  \n",
       " 4        0.279100          0.184028  1     mt5-xl        None  }"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iterate over completed runs to get ROUGE scores tables\n",
    "run2metric_table = {}\n",
    "for run in tqdm(runs):\n",
    "    if 'complete' not in run.tags or 'evaluation' != getattr(run, 'job_type', ''):\n",
    "        continue\n",
    "    else:\n",
    "        print('parsing run {}'.format(run.name))\n",
    "    # download the rouge table\n",
    "    files = run.files()\n",
    "    metric_file = [file for file in files if 'Evaluation metrics Table' in getattr(file, 'name', '')]\n",
    "    if len(metric_file) < 1:\n",
    "        print('[WARN] skip {} because len(metric_file) < 1'.format(metric_file))\n",
    "        continue\n",
    "    metric_file = metric_file[0]\n",
    "    f = metric_file.download(root='wandb', replace=True)\n",
    "    metrics = json.load(f)\n",
    "    metric_table = pd.read_json(json.dumps(metrics), orient='split')\n",
    "    # get k shot\n",
    "    try:\n",
    "        match = re.search(r'\\d-shot', run.name)\n",
    "        start_i, end_i = match.span()\n",
    "        k = int(run.name[start_i: end_i].split('-')[0])\n",
    "        metric_table['k'] = k\n",
    "    except AttributeError:\n",
    "        print('[debug] skip {}'.format(run.name))\n",
    "        continue \n",
    "    model_name = run.name[: start_i - 1]\n",
    "    if 'keyword' in run.name:\n",
    "        end_id = run.name.find('-keyword')\n",
    "        keyword_num = run.name[end_id - 1:end_id]\n",
    "        metric_table['keyword_num'] = keyword_num\n",
    "        print('[debug] find keyword_num = {} in {}'.format(keyword_num, run.name))\n",
    "    else:\n",
    "        metric_table['keyword_num'] = None\n",
    "\n",
    "    run2metric_table[run.name] = metric_table\n",
    "run2metric_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Direct prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# parse the result of direct prompt\n",
    "new_keys = [x for x in run2metric_table.keys() if ('keyword' not in x and 'nameReplace' not in x and 'length' \n",
    "                                                   not in x and 'replaceName' not in x and 'instructions' not in x and \n",
    "                                                  'focus' not in x and 'randomLabel' not in x)]\n",
    "# new_keys = [x for x in run2metric_table.keys() if ('keyword' not in x and 'nameReplace' not in x and 'length' not\n",
    "#                                                     in x and 'replaceName' not in x and 'instructions' not in x and 'focus' in x)]\n",
    "\n",
    "dfs = [run2metric_table[k] for k in new_keys]\n",
    "rouge_table = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "rouge_table['k'] = rouge_table['k'].astype(int)\n",
    "rouge_table['keyword_num'] = rouge_table['keyword_num'].fillna(0)\n",
    "rouge_table = rouge_table[(rouge_table['k'] <= 3) & ~rouge_table.isna().any(axis=1)]\n",
    "rouge_table = rouge_table[~rouge_table['model_name'].str.contains('Cerebras-GPT-6.7B') & ~rouge_table['model_name'].str.contains('flan-t5-xl')]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "plot = sb.lineplot(data=rouge_table, x='k', y='rouge_1_fmeasure', hue='model_name', ax=axes[0], markers=True)\n",
    "plot.set_xticks([1, 2, 3]) # <--- set the ticks first\n",
    "plot.set_xticklabels(['1', '2', '3'])\n",
    "axes[0].get_legend().remove()\n",
    "axes[0].yaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\n",
    "plot = sb.lineplot(data=rouge_table, x='k', y='rouge_2_fmeasure', hue='model_name', ax=axes[1], markers=True)\n",
    "plot.set_xticks([1, 2, 3]) # <--- set the ticks first\n",
    "plot.set_xticklabels(['1', '2', '3'])\n",
    "axes[1].get_legend().remove()\n",
    "axes[1].yaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\n",
    "\n",
    "plot = sb.lineplot(data=rouge_table, x='k', y='rouge_L_fmeasure', hue='model_name', ax=axes[2], markers=True)\n",
    "plot.set_xticks([1, 2, 3]) # <--- set the ticks first\n",
    "plot.set_xticklabels(['1', '2', '3'])\n",
    "axes[2].get_legend().remove()\n",
    "axes[2].yaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\n",
    "\n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='right', ncol=3, bbox_to_anchor=(.75, 0.98))\n",
    "\n",
    "plt.savefig('direct_prompt.jpg', dpi=500, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['llama-7b-hf-0-shot',\n",
       " 'opt-iml-1.3b-2-shot-randomLabel',\n",
       " 'opt-1.3b-2-shot-focus',\n",
       " 'opt-1.3b-3-shot-focus',\n",
       " 'opt-1.3b-1-shot-focus',\n",
       " 'mt5-xl-3-shot-raw',\n",
       " 'opt-iml-1.3b-3-shot-focus',\n",
       " 'opt-iml-1.3b-2-shot-focus',\n",
       " 'opt-iml-1.3b-1-shot-focus',\n",
       " 'mt5-xl-2-shot-raw',\n",
       " 'GPT3-davinci-003-1-shot',\n",
       " 'mt5-xl-1-shot-raw',\n",
       " 'opt-1.3b-3-shot',\n",
       " 'opt-1.3b-2-shot',\n",
       " 'opt-1.3b-1-shot',\n",
       " 'flan-t5-xl-3-shot',\n",
       " 'flan-t5-xl-2-shot',\n",
       " 'alpaca-native-3-shot',\n",
       " 'alpaca-native-2-shot',\n",
       " 'alpaca-native-1-shot',\n",
       " 'llama-7b-hf-2-shot',\n",
       " 'llama-7b-hf-3-shot',\n",
       " 'bloom-3b-5-shot',\n",
       " 'Cerebras-GPT-6.7B-2-shot',\n",
       " 'Cerebras-GPT-6.7B-1-shot',\n",
       " 'llama-7b-hf-1-shot',\n",
       " 'opt-iml-1.3b-3-shot',\n",
       " 'opt-iml-1.3b-2-shot',\n",
       " 'opt-iml-1.3b-1-shot',\n",
       " 'bloom-3b-3-shot',\n",
       " 'bloom-3b-2-shot',\n",
       " 'bloom-3b-1-shot',\n",
       " 'bloom-7b1-3-shot',\n",
       " 'bloom-7b1-5-shot',\n",
       " 'bloom-7b1-2-shot',\n",
       " 'bloom-7b1-1-shot',\n",
       " 'Cerebras-GPT-13B-3-shot',\n",
       " 'Cerebras-GPT-13B-2-shot',\n",
       " 'Cerebras-GPT-13B-1-shot',\n",
       " 'Cerebras-GPT-2.7B-3-shot',\n",
       " 'Cerebras-GPT-2.7B-1-shot',\n",
       " 'Cerebras-GPT-2.7B-2-shot',\n",
       " 'Cerebras-6.7B-3-shot',\n",
       " 'mt5-xxl-5-shot',\n",
       " 'mt5-xxl-3-shot',\n",
       " 'mt5-xxl-2-shot',\n",
       " 'mt5-xxl-1-shot',\n",
       " 'mt5-xl-5-shot',\n",
       " 'mt5-xl-3-shot',\n",
       " 'mt5-xl-2-shot',\n",
       " 'mt5-xl-1-shot']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_table.groupby(['model_name', 'k']).mean().to_csv('mean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_table.groupby(['model_name', 'k']).std().to_csv('std.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_table.groupby(['model_name', 'k']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_table.groupby(['model_name', 'k']).std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot results under controlled setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[debug] new_keys = ['Cerebras-GPT-6.7B-1-shot-1-keywords', 'Cerebras-GPT-6.7B-1-shot-2-keywords', 'Cerebras-GPT-6.7B-1-shot-3-keywords', 'Cerebras-GPT-6.7B-2-shot-1-keywords', 'Cerebras-GPT-6.7B-2-shot-2-keywords', 'Cerebras-GPT-6.7B-2-shot-3-keywords', 'Cerebras-GPT-6.7B-3-shot-1-keywords', 'Cerebras-GPT-6.7B-3-shot-2-keywords']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\Desktop\\CodeRepositories\\venv\\lib\\site-packages\\ipykernel_launcher.py:26: UserWarning: The palette list has more values (6) than needed (3), which may not be intended.\n",
      "C:\\Users\\chris\\Desktop\\CodeRepositories\\venv\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: The palette list has more values (6) than needed (3), which may not be intended.\n",
      "C:\\Users\\chris\\Desktop\\CodeRepositories\\venv\\lib\\site-packages\\ipykernel_launcher.py:34: UserWarning: The palette list has more values (6) than needed (3), which may not be intended.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>rouge_1_precision</th>\n",
       "      <th>rouge_1_recall</th>\n",
       "      <th>rouge_1_fmeasure</th>\n",
       "      <th>rouge_2_precision</th>\n",
       "      <th>rouge_2_recall</th>\n",
       "      <th>rouge_2_fmeasure</th>\n",
       "      <th>rouge_L_precision</th>\n",
       "      <th>rouge_L_recall</th>\n",
       "      <th>rouge_L_fmeasure</th>\n",
       "      <th>k</th>\n",
       "      <th>model_name</th>\n",
       "      <th>keyword_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.493981</td>\n",
       "      <td>0.294623</td>\n",
       "      <td>0.341204</td>\n",
       "      <td>0.132355</td>\n",
       "      <td>0.072781</td>\n",
       "      <td>0.085314</td>\n",
       "      <td>0.358864</td>\n",
       "      <td>0.207036</td>\n",
       "      <td>0.241720</td>\n",
       "      <td>3</td>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.491757</td>\n",
       "      <td>0.296368</td>\n",
       "      <td>0.341755</td>\n",
       "      <td>0.131848</td>\n",
       "      <td>0.072244</td>\n",
       "      <td>0.085208</td>\n",
       "      <td>0.355531</td>\n",
       "      <td>0.207795</td>\n",
       "      <td>0.241141</td>\n",
       "      <td>3</td>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.494440</td>\n",
       "      <td>0.297449</td>\n",
       "      <td>0.344777</td>\n",
       "      <td>0.138693</td>\n",
       "      <td>0.077496</td>\n",
       "      <td>0.091111</td>\n",
       "      <td>0.360018</td>\n",
       "      <td>0.211611</td>\n",
       "      <td>0.246650</td>\n",
       "      <td>3</td>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.436092</td>\n",
       "      <td>0.238594</td>\n",
       "      <td>0.289984</td>\n",
       "      <td>0.082381</td>\n",
       "      <td>0.053925</td>\n",
       "      <td>0.061412</td>\n",
       "      <td>0.359076</td>\n",
       "      <td>0.193384</td>\n",
       "      <td>0.235991</td>\n",
       "      <td>3</td>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.477882</td>\n",
       "      <td>0.329002</td>\n",
       "      <td>0.357630</td>\n",
       "      <td>0.128556</td>\n",
       "      <td>0.083331</td>\n",
       "      <td>0.091729</td>\n",
       "      <td>0.349500</td>\n",
       "      <td>0.236342</td>\n",
       "      <td>0.257814</td>\n",
       "      <td>1</td>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0.476260</td>\n",
       "      <td>0.330729</td>\n",
       "      <td>0.357130</td>\n",
       "      <td>0.134196</td>\n",
       "      <td>0.085154</td>\n",
       "      <td>0.094625</td>\n",
       "      <td>0.350091</td>\n",
       "      <td>0.236168</td>\n",
       "      <td>0.257627</td>\n",
       "      <td>1</td>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>0.489856</td>\n",
       "      <td>0.335488</td>\n",
       "      <td>0.365386</td>\n",
       "      <td>0.140659</td>\n",
       "      <td>0.088727</td>\n",
       "      <td>0.098937</td>\n",
       "      <td>0.359307</td>\n",
       "      <td>0.241734</td>\n",
       "      <td>0.264439</td>\n",
       "      <td>1</td>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>0.482733</td>\n",
       "      <td>0.335385</td>\n",
       "      <td>0.359898</td>\n",
       "      <td>0.140620</td>\n",
       "      <td>0.089757</td>\n",
       "      <td>0.097854</td>\n",
       "      <td>0.360600</td>\n",
       "      <td>0.244304</td>\n",
       "      <td>0.264172</td>\n",
       "      <td>1</td>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>0.488828</td>\n",
       "      <td>0.330645</td>\n",
       "      <td>0.359345</td>\n",
       "      <td>0.140083</td>\n",
       "      <td>0.087248</td>\n",
       "      <td>0.096790</td>\n",
       "      <td>0.362485</td>\n",
       "      <td>0.240929</td>\n",
       "      <td>0.262607</td>\n",
       "      <td>1</td>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0.507705</td>\n",
       "      <td>0.320978</td>\n",
       "      <td>0.365097</td>\n",
       "      <td>0.153240</td>\n",
       "      <td>0.088650</td>\n",
       "      <td>0.103047</td>\n",
       "      <td>0.374557</td>\n",
       "      <td>0.231014</td>\n",
       "      <td>0.264448</td>\n",
       "      <td>2</td>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0.506733</td>\n",
       "      <td>0.313847</td>\n",
       "      <td>0.356934</td>\n",
       "      <td>0.152984</td>\n",
       "      <td>0.085345</td>\n",
       "      <td>0.099280</td>\n",
       "      <td>0.376799</td>\n",
       "      <td>0.225043</td>\n",
       "      <td>0.258532</td>\n",
       "      <td>2</td>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>0.501645</td>\n",
       "      <td>0.320804</td>\n",
       "      <td>0.361279</td>\n",
       "      <td>0.141813</td>\n",
       "      <td>0.083450</td>\n",
       "      <td>0.096040</td>\n",
       "      <td>0.370867</td>\n",
       "      <td>0.230263</td>\n",
       "      <td>0.261997</td>\n",
       "      <td>2</td>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>0.496936</td>\n",
       "      <td>0.317764</td>\n",
       "      <td>0.358422</td>\n",
       "      <td>0.146937</td>\n",
       "      <td>0.085904</td>\n",
       "      <td>0.098994</td>\n",
       "      <td>0.365494</td>\n",
       "      <td>0.227565</td>\n",
       "      <td>0.258471</td>\n",
       "      <td>2</td>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>0.503397</td>\n",
       "      <td>0.314013</td>\n",
       "      <td>0.358320</td>\n",
       "      <td>0.142490</td>\n",
       "      <td>0.081642</td>\n",
       "      <td>0.095124</td>\n",
       "      <td>0.370279</td>\n",
       "      <td>0.225501</td>\n",
       "      <td>0.258818</td>\n",
       "      <td>2</td>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0.486108</td>\n",
       "      <td>0.274616</td>\n",
       "      <td>0.326318</td>\n",
       "      <td>0.123337</td>\n",
       "      <td>0.064177</td>\n",
       "      <td>0.077769</td>\n",
       "      <td>0.350715</td>\n",
       "      <td>0.191987</td>\n",
       "      <td>0.230050</td>\n",
       "      <td>3</td>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>0.486355</td>\n",
       "      <td>0.272153</td>\n",
       "      <td>0.323331</td>\n",
       "      <td>0.121922</td>\n",
       "      <td>0.065082</td>\n",
       "      <td>0.078064</td>\n",
       "      <td>0.351826</td>\n",
       "      <td>0.190732</td>\n",
       "      <td>0.228294</td>\n",
       "      <td>3</td>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>0.486125</td>\n",
       "      <td>0.278041</td>\n",
       "      <td>0.328051</td>\n",
       "      <td>0.121931</td>\n",
       "      <td>0.066425</td>\n",
       "      <td>0.079312</td>\n",
       "      <td>0.350055</td>\n",
       "      <td>0.193826</td>\n",
       "      <td>0.230610</td>\n",
       "      <td>3</td>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3</td>\n",
       "      <td>0.536577</td>\n",
       "      <td>0.271868</td>\n",
       "      <td>0.326444</td>\n",
       "      <td>0.109221</td>\n",
       "      <td>0.055396</td>\n",
       "      <td>0.066054</td>\n",
       "      <td>0.387696</td>\n",
       "      <td>0.209942</td>\n",
       "      <td>0.246333</td>\n",
       "      <td>3</td>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0.492008</td>\n",
       "      <td>0.299127</td>\n",
       "      <td>0.344076</td>\n",
       "      <td>0.134378</td>\n",
       "      <td>0.076441</td>\n",
       "      <td>0.089304</td>\n",
       "      <td>0.356537</td>\n",
       "      <td>0.211078</td>\n",
       "      <td>0.244338</td>\n",
       "      <td>2</td>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>0.489316</td>\n",
       "      <td>0.299283</td>\n",
       "      <td>0.341278</td>\n",
       "      <td>0.135414</td>\n",
       "      <td>0.074939</td>\n",
       "      <td>0.088001</td>\n",
       "      <td>0.362084</td>\n",
       "      <td>0.214195</td>\n",
       "      <td>0.246560</td>\n",
       "      <td>2</td>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>0.490038</td>\n",
       "      <td>0.302582</td>\n",
       "      <td>0.344730</td>\n",
       "      <td>0.132250</td>\n",
       "      <td>0.076160</td>\n",
       "      <td>0.088514</td>\n",
       "      <td>0.360357</td>\n",
       "      <td>0.216485</td>\n",
       "      <td>0.248890</td>\n",
       "      <td>2</td>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3</td>\n",
       "      <td>0.484320</td>\n",
       "      <td>0.304122</td>\n",
       "      <td>0.345503</td>\n",
       "      <td>0.131890</td>\n",
       "      <td>0.077476</td>\n",
       "      <td>0.089629</td>\n",
       "      <td>0.351721</td>\n",
       "      <td>0.215160</td>\n",
       "      <td>0.245972</td>\n",
       "      <td>2</td>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4</td>\n",
       "      <td>0.486098</td>\n",
       "      <td>0.297424</td>\n",
       "      <td>0.340128</td>\n",
       "      <td>0.133360</td>\n",
       "      <td>0.072606</td>\n",
       "      <td>0.085768</td>\n",
       "      <td>0.355000</td>\n",
       "      <td>0.210166</td>\n",
       "      <td>0.242406</td>\n",
       "      <td>2</td>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0.462219</td>\n",
       "      <td>0.311603</td>\n",
       "      <td>0.341155</td>\n",
       "      <td>0.120545</td>\n",
       "      <td>0.078515</td>\n",
       "      <td>0.086270</td>\n",
       "      <td>0.338104</td>\n",
       "      <td>0.223725</td>\n",
       "      <td>0.245853</td>\n",
       "      <td>1</td>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>0.463167</td>\n",
       "      <td>0.311571</td>\n",
       "      <td>0.341325</td>\n",
       "      <td>0.125286</td>\n",
       "      <td>0.075800</td>\n",
       "      <td>0.085779</td>\n",
       "      <td>0.341686</td>\n",
       "      <td>0.222957</td>\n",
       "      <td>0.246310</td>\n",
       "      <td>1</td>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>0.474294</td>\n",
       "      <td>0.318758</td>\n",
       "      <td>0.346885</td>\n",
       "      <td>0.129466</td>\n",
       "      <td>0.079814</td>\n",
       "      <td>0.088428</td>\n",
       "      <td>0.346670</td>\n",
       "      <td>0.228310</td>\n",
       "      <td>0.249534</td>\n",
       "      <td>1</td>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3</td>\n",
       "      <td>0.469179</td>\n",
       "      <td>0.311320</td>\n",
       "      <td>0.340885</td>\n",
       "      <td>0.122872</td>\n",
       "      <td>0.075110</td>\n",
       "      <td>0.084054</td>\n",
       "      <td>0.343531</td>\n",
       "      <td>0.222999</td>\n",
       "      <td>0.245468</td>\n",
       "      <td>1</td>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4</td>\n",
       "      <td>0.472948</td>\n",
       "      <td>0.314136</td>\n",
       "      <td>0.345949</td>\n",
       "      <td>0.126468</td>\n",
       "      <td>0.078210</td>\n",
       "      <td>0.087962</td>\n",
       "      <td>0.344375</td>\n",
       "      <td>0.224555</td>\n",
       "      <td>0.247926</td>\n",
       "      <td>1</td>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>0.464744</td>\n",
       "      <td>0.286131</td>\n",
       "      <td>0.325319</td>\n",
       "      <td>0.113707</td>\n",
       "      <td>0.065435</td>\n",
       "      <td>0.075484</td>\n",
       "      <td>0.336318</td>\n",
       "      <td>0.202861</td>\n",
       "      <td>0.231415</td>\n",
       "      <td>1</td>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>0.464368</td>\n",
       "      <td>0.285808</td>\n",
       "      <td>0.324762</td>\n",
       "      <td>0.110338</td>\n",
       "      <td>0.062116</td>\n",
       "      <td>0.071973</td>\n",
       "      <td>0.337667</td>\n",
       "      <td>0.201769</td>\n",
       "      <td>0.231091</td>\n",
       "      <td>1</td>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2</td>\n",
       "      <td>0.455819</td>\n",
       "      <td>0.291040</td>\n",
       "      <td>0.323104</td>\n",
       "      <td>0.116532</td>\n",
       "      <td>0.066929</td>\n",
       "      <td>0.076432</td>\n",
       "      <td>0.334742</td>\n",
       "      <td>0.207538</td>\n",
       "      <td>0.232466</td>\n",
       "      <td>1</td>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>3</td>\n",
       "      <td>0.464485</td>\n",
       "      <td>0.285247</td>\n",
       "      <td>0.321982</td>\n",
       "      <td>0.120587</td>\n",
       "      <td>0.066467</td>\n",
       "      <td>0.077023</td>\n",
       "      <td>0.335761</td>\n",
       "      <td>0.201025</td>\n",
       "      <td>0.228327</td>\n",
       "      <td>1</td>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>4</td>\n",
       "      <td>0.470850</td>\n",
       "      <td>0.294725</td>\n",
       "      <td>0.331847</td>\n",
       "      <td>0.119165</td>\n",
       "      <td>0.069473</td>\n",
       "      <td>0.079277</td>\n",
       "      <td>0.338771</td>\n",
       "      <td>0.207092</td>\n",
       "      <td>0.234541</td>\n",
       "      <td>1</td>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0</td>\n",
       "      <td>0.479766</td>\n",
       "      <td>0.278523</td>\n",
       "      <td>0.328012</td>\n",
       "      <td>0.125118</td>\n",
       "      <td>0.066421</td>\n",
       "      <td>0.080361</td>\n",
       "      <td>0.349588</td>\n",
       "      <td>0.196206</td>\n",
       "      <td>0.233578</td>\n",
       "      <td>2</td>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "      <td>0.485832</td>\n",
       "      <td>0.279066</td>\n",
       "      <td>0.325224</td>\n",
       "      <td>0.126388</td>\n",
       "      <td>0.065672</td>\n",
       "      <td>0.078785</td>\n",
       "      <td>0.352289</td>\n",
       "      <td>0.196101</td>\n",
       "      <td>0.230492</td>\n",
       "      <td>2</td>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2</td>\n",
       "      <td>0.481652</td>\n",
       "      <td>0.277991</td>\n",
       "      <td>0.325546</td>\n",
       "      <td>0.123122</td>\n",
       "      <td>0.065834</td>\n",
       "      <td>0.078102</td>\n",
       "      <td>0.348838</td>\n",
       "      <td>0.195419</td>\n",
       "      <td>0.230850</td>\n",
       "      <td>2</td>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>3</td>\n",
       "      <td>0.480734</td>\n",
       "      <td>0.278475</td>\n",
       "      <td>0.324425</td>\n",
       "      <td>0.127839</td>\n",
       "      <td>0.066954</td>\n",
       "      <td>0.080184</td>\n",
       "      <td>0.350922</td>\n",
       "      <td>0.196541</td>\n",
       "      <td>0.231054</td>\n",
       "      <td>2</td>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>4</td>\n",
       "      <td>0.483878</td>\n",
       "      <td>0.274726</td>\n",
       "      <td>0.323892</td>\n",
       "      <td>0.122107</td>\n",
       "      <td>0.061660</td>\n",
       "      <td>0.075280</td>\n",
       "      <td>0.351364</td>\n",
       "      <td>0.192181</td>\n",
       "      <td>0.228991</td>\n",
       "      <td>2</td>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    run_id  rouge_1_precision  rouge_1_recall  rouge_1_fmeasure  \\\n",
       "0        0           0.493981        0.294623          0.341204   \n",
       "1        1           0.491757        0.296368          0.341755   \n",
       "2        2           0.494440        0.297449          0.344777   \n",
       "3        3           0.436092        0.238594          0.289984   \n",
       "5        0           0.477882        0.329002          0.357630   \n",
       "6        1           0.476260        0.330729          0.357130   \n",
       "7        2           0.489856        0.335488          0.365386   \n",
       "8        3           0.482733        0.335385          0.359898   \n",
       "9        4           0.488828        0.330645          0.359345   \n",
       "10       0           0.507705        0.320978          0.365097   \n",
       "11       1           0.506733        0.313847          0.356934   \n",
       "12       2           0.501645        0.320804          0.361279   \n",
       "13       3           0.496936        0.317764          0.358422   \n",
       "14       4           0.503397        0.314013          0.358320   \n",
       "15       0           0.486108        0.274616          0.326318   \n",
       "16       1           0.486355        0.272153          0.323331   \n",
       "17       2           0.486125        0.278041          0.328051   \n",
       "18       3           0.536577        0.271868          0.326444   \n",
       "20       0           0.492008        0.299127          0.344076   \n",
       "21       1           0.489316        0.299283          0.341278   \n",
       "22       2           0.490038        0.302582          0.344730   \n",
       "23       3           0.484320        0.304122          0.345503   \n",
       "24       4           0.486098        0.297424          0.340128   \n",
       "25       0           0.462219        0.311603          0.341155   \n",
       "26       1           0.463167        0.311571          0.341325   \n",
       "27       2           0.474294        0.318758          0.346885   \n",
       "28       3           0.469179        0.311320          0.340885   \n",
       "29       4           0.472948        0.314136          0.345949   \n",
       "30       0           0.464744        0.286131          0.325319   \n",
       "31       1           0.464368        0.285808          0.324762   \n",
       "32       2           0.455819        0.291040          0.323104   \n",
       "33       3           0.464485        0.285247          0.321982   \n",
       "34       4           0.470850        0.294725          0.331847   \n",
       "35       0           0.479766        0.278523          0.328012   \n",
       "36       1           0.485832        0.279066          0.325224   \n",
       "37       2           0.481652        0.277991          0.325546   \n",
       "38       3           0.480734        0.278475          0.324425   \n",
       "39       4           0.483878        0.274726          0.323892   \n",
       "\n",
       "    rouge_2_precision  rouge_2_recall  rouge_2_fmeasure  rouge_L_precision  \\\n",
       "0            0.132355        0.072781          0.085314           0.358864   \n",
       "1            0.131848        0.072244          0.085208           0.355531   \n",
       "2            0.138693        0.077496          0.091111           0.360018   \n",
       "3            0.082381        0.053925          0.061412           0.359076   \n",
       "5            0.128556        0.083331          0.091729           0.349500   \n",
       "6            0.134196        0.085154          0.094625           0.350091   \n",
       "7            0.140659        0.088727          0.098937           0.359307   \n",
       "8            0.140620        0.089757          0.097854           0.360600   \n",
       "9            0.140083        0.087248          0.096790           0.362485   \n",
       "10           0.153240        0.088650          0.103047           0.374557   \n",
       "11           0.152984        0.085345          0.099280           0.376799   \n",
       "12           0.141813        0.083450          0.096040           0.370867   \n",
       "13           0.146937        0.085904          0.098994           0.365494   \n",
       "14           0.142490        0.081642          0.095124           0.370279   \n",
       "15           0.123337        0.064177          0.077769           0.350715   \n",
       "16           0.121922        0.065082          0.078064           0.351826   \n",
       "17           0.121931        0.066425          0.079312           0.350055   \n",
       "18           0.109221        0.055396          0.066054           0.387696   \n",
       "20           0.134378        0.076441          0.089304           0.356537   \n",
       "21           0.135414        0.074939          0.088001           0.362084   \n",
       "22           0.132250        0.076160          0.088514           0.360357   \n",
       "23           0.131890        0.077476          0.089629           0.351721   \n",
       "24           0.133360        0.072606          0.085768           0.355000   \n",
       "25           0.120545        0.078515          0.086270           0.338104   \n",
       "26           0.125286        0.075800          0.085779           0.341686   \n",
       "27           0.129466        0.079814          0.088428           0.346670   \n",
       "28           0.122872        0.075110          0.084054           0.343531   \n",
       "29           0.126468        0.078210          0.087962           0.344375   \n",
       "30           0.113707        0.065435          0.075484           0.336318   \n",
       "31           0.110338        0.062116          0.071973           0.337667   \n",
       "32           0.116532        0.066929          0.076432           0.334742   \n",
       "33           0.120587        0.066467          0.077023           0.335761   \n",
       "34           0.119165        0.069473          0.079277           0.338771   \n",
       "35           0.125118        0.066421          0.080361           0.349588   \n",
       "36           0.126388        0.065672          0.078785           0.352289   \n",
       "37           0.123122        0.065834          0.078102           0.348838   \n",
       "38           0.127839        0.066954          0.080184           0.350922   \n",
       "39           0.122107        0.061660          0.075280           0.351364   \n",
       "\n",
       "    rouge_L_recall  rouge_L_fmeasure  k         model_name  keyword_num  \n",
       "0         0.207036          0.241720  3  Cerebras-GPT-6.7B            2  \n",
       "1         0.207795          0.241141  3  Cerebras-GPT-6.7B            2  \n",
       "2         0.211611          0.246650  3  Cerebras-GPT-6.7B            2  \n",
       "3         0.193384          0.235991  3  Cerebras-GPT-6.7B            2  \n",
       "5         0.236342          0.257814  1  Cerebras-GPT-6.7B            3  \n",
       "6         0.236168          0.257627  1  Cerebras-GPT-6.7B            3  \n",
       "7         0.241734          0.264439  1  Cerebras-GPT-6.7B            3  \n",
       "8         0.244304          0.264172  1  Cerebras-GPT-6.7B            3  \n",
       "9         0.240929          0.262607  1  Cerebras-GPT-6.7B            3  \n",
       "10        0.231014          0.264448  2  Cerebras-GPT-6.7B            3  \n",
       "11        0.225043          0.258532  2  Cerebras-GPT-6.7B            3  \n",
       "12        0.230263          0.261997  2  Cerebras-GPT-6.7B            3  \n",
       "13        0.227565          0.258471  2  Cerebras-GPT-6.7B            3  \n",
       "14        0.225501          0.258818  2  Cerebras-GPT-6.7B            3  \n",
       "15        0.191987          0.230050  3  Cerebras-GPT-6.7B            1  \n",
       "16        0.190732          0.228294  3  Cerebras-GPT-6.7B            1  \n",
       "17        0.193826          0.230610  3  Cerebras-GPT-6.7B            1  \n",
       "18        0.209942          0.246333  3  Cerebras-GPT-6.7B            1  \n",
       "20        0.211078          0.244338  2  Cerebras-GPT-6.7B            2  \n",
       "21        0.214195          0.246560  2  Cerebras-GPT-6.7B            2  \n",
       "22        0.216485          0.248890  2  Cerebras-GPT-6.7B            2  \n",
       "23        0.215160          0.245972  2  Cerebras-GPT-6.7B            2  \n",
       "24        0.210166          0.242406  2  Cerebras-GPT-6.7B            2  \n",
       "25        0.223725          0.245853  1  Cerebras-GPT-6.7B            2  \n",
       "26        0.222957          0.246310  1  Cerebras-GPT-6.7B            2  \n",
       "27        0.228310          0.249534  1  Cerebras-GPT-6.7B            2  \n",
       "28        0.222999          0.245468  1  Cerebras-GPT-6.7B            2  \n",
       "29        0.224555          0.247926  1  Cerebras-GPT-6.7B            2  \n",
       "30        0.202861          0.231415  1  Cerebras-GPT-6.7B            1  \n",
       "31        0.201769          0.231091  1  Cerebras-GPT-6.7B            1  \n",
       "32        0.207538          0.232466  1  Cerebras-GPT-6.7B            1  \n",
       "33        0.201025          0.228327  1  Cerebras-GPT-6.7B            1  \n",
       "34        0.207092          0.234541  1  Cerebras-GPT-6.7B            1  \n",
       "35        0.196206          0.233578  2  Cerebras-GPT-6.7B            1  \n",
       "36        0.196101          0.230492  2  Cerebras-GPT-6.7B            1  \n",
       "37        0.195419          0.230850  2  Cerebras-GPT-6.7B            1  \n",
       "38        0.196541          0.231054  2  Cerebras-GPT-6.7B            1  \n",
       "39        0.192181          0.228991  2  Cerebras-GPT-6.7B            1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get the result of MODEL_NAME family\n",
    "MODEL_NAME = 'Cerebras-GPT-6.7B'\n",
    "\n",
    "if MODEL_NAME == 'mt5-xl':\n",
    "    new_keys = [x for x in run2metric_table.keys() if MODEL_NAME in x and 'mt5-xxl' not in x]\n",
    "else:\n",
    "    new_keys = [x for x in run2metric_table.keys() if MODEL_NAME in x and 'keywords' in x and 'nameReplace' not in x and 'length' not in x and 'replaceName' not in x]\n",
    "#     new_keys = [x for x in run2metric_table.keys() if MODEL_NAME in x and 'nameReplace' not in x and 'length' in x and 'replaceName' not in x]\n",
    "#     new_keys = [x for x in run2metric_table.keys() if MODEL_NAME in x and 'nameReplace' not in x and 'focus' in x and 'replaceName' not in x]\n",
    "\n",
    "print('[debug] new_keys =', sorted(new_keys))\n",
    "dfs = [run2metric_table[k] for k in new_keys]\n",
    "rouge_table = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "model_name = rouge_table['model_name'].unique()[0]\n",
    "rouge_table['k'] = rouge_table['k'].astype(int)\n",
    "rouge_table['keyword_num'] = rouge_table['keyword_num'].fillna(0)\n",
    "rouge_table['keyword_num'] = rouge_table['keyword_num'].astype(int)\n",
    "rouge_table = rouge_table[~rouge_table.isna().any(axis=1)]\n",
    "\n",
    "rouge_table = rouge_table[(rouge_table['k'] <= 3)]\n",
    "# rouge_table = rouge_table[~rouge_table['model_name'].str.contains('Cerebras-GPT-6.7B')]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "palette = sb.color_palette(\"ch:s=.25,rot=-.25\", as_cmap=False)\n",
    "\n",
    "plot = sb.lineplot(data=rouge_table, x='k', y='rouge_1_fmeasure', hue='keyword_num', ax=axes[0], markers=True, palette=palette)\n",
    "plot.set_xticks([1, 2, 3]) # <--- set the ticks first\n",
    "plot.set_xticklabels(['1', '2', '3'])\n",
    "axes[0].yaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\n",
    "plot = sb.lineplot(data=rouge_table, x='k', y='rouge_2_fmeasure', hue='keyword_num', ax=axes[1], markers=True, palette=palette)\n",
    "plot.set_xticks([1, 2, 3]) # <--- set the ticks first\n",
    "plot.set_xticklabels(['1', '2', '3'])\n",
    "axes[1].yaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\n",
    "plot = sb.lineplot(data=rouge_table, x='k', y='rouge_L_fmeasure', hue='keyword_num', ax=axes[2], markers=True, palette=palette)\n",
    "plot.set_xticks([1, 2, 3]) # <--- set the ticks first\n",
    "plot.set_xticklabels(['1', '2', '3'])\n",
    "axes[2].yaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\n",
    "axes[0].get_legend().remove()\n",
    "axes[1].get_legend().remove()\n",
    "axes[2].get_legend().remove()\n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='upper right', ncol=5, bbox_to_anchor=(.8, 1), title='Keyword number')\n",
    "fig.suptitle(model_name, fontweight='bold')\n",
    "#\n",
    "plt.savefig('{}_entity_control.jpg'.format(model_name), dpi=500, bbox_inches='tight')\n",
    "\n",
    "rouge_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_df = rouge_table.groupby('k').mean() * 100\n",
    "mean_df[[x for x in mean_df.columns if 'fmeasure' in x]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_df = rouge_table.groupby('k').std() * 100\n",
    "std_df[[x for x in std_df.columns if 'fmeasure' in x]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cerebras-GPT-6.7B-3-shot-2-keywords',\n",
       " 'Cerebras-GPT-6.7B-1-shot-3-keywords',\n",
       " 'Cerebras-GPT-6.7B-2-shot-3-keywords',\n",
       " 'Cerebras-GPT-6.7B-3-shot-1-keywords',\n",
       " 'Cerebras-GPT-6.7B-2-shot-2-keywords',\n",
       " 'Cerebras-GPT-6.7B-1-shot-2-keywords',\n",
       " 'Cerebras-GPT-6.7B-1-shot-1-keywords',\n",
       " 'Cerebras-GPT-6.7B-2-shot-1-keywords',\n",
       " 'Cerebras-GPT-6.7B-2-shot',\n",
       " 'Cerebras-GPT-6.7B-1-shot']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in run2metric_table.keys() if 'Cerebras-GPT-6.7B' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Success Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67ff392304ae4455a856b2acd1ca8c80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/281 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsing run Cerebras-GPT-6.7B-3-shot-2-keywords\n",
      "['artifact/475083096/wandb_manifest.json', 'artifact/475083173/wandb_manifest.json', 'config.yaml', 'media/table/Evaluation metrics Table_0_9eebc80dcd23ee4c279b.table.json', 'media/table/Summaries Table_1_50dca3262a844019ad90.table.json', 'output.log', 'requirements.txt', 'wandb-metadata.json', 'wandb-summary.json']\n",
      "[debug] find keyword_num = 2 in Cerebras-GPT-6.7B-3-shot-2-keywords\n",
      "parsing run Cerebras-GPT-6.7B-1-shot-3-keywords\n",
      "['artifact/475115110/wandb_manifest.json', 'artifact/475115186/wandb_manifest.json', 'config.yaml', 'media/table/Evaluation metrics Table_0_6eb22dae37cce8af8302.table.json', 'media/table/Summaries Table_1_267abbee1f18f6889514.table.json', 'output.log', 'requirements.txt', 'wandb-metadata.json', 'wandb-summary.json']\n",
      "[debug] find keyword_num = 3 in Cerebras-GPT-6.7B-1-shot-3-keywords\n",
      "parsing run Cerebras-GPT-6.7B-2-shot-3-keywords\n",
      "['artifact/475109301/wandb_manifest.json', 'artifact/475109346/wandb_manifest.json', 'config.yaml', 'media/table/Evaluation metrics Table_0_980c5b3b1ddf481604c9.table.json', 'media/table/Summaries Table_1_a590ed5596348fc56cf4.table.json', 'output.log', 'requirements.txt', 'wandb-metadata.json', 'wandb-summary.json']\n",
      "[debug] find keyword_num = 3 in Cerebras-GPT-6.7B-2-shot-3-keywords\n",
      "parsing run Cerebras-GPT-6.7B-3-shot-1-keywords\n",
      "['artifact/475083119/wandb_manifest.json', 'artifact/475083160/wandb_manifest.json', 'config.yaml', 'media/table/Evaluation metrics Table_0_eace688ae8d7fdb9e851.table.json', 'media/table/Summaries Table_1_6431827e24c2cbfe417d.table.json', 'output.log', 'requirements.txt', 'wandb-metadata.json', 'wandb-summary.json']\n",
      "[debug] find keyword_num = 1 in Cerebras-GPT-6.7B-3-shot-1-keywords\n",
      "parsing run Cerebras-GPT-6.7B-2-shot-2-keywords\n",
      "['artifact/475081844/wandb_manifest.json', 'artifact/475081887/wandb_manifest.json', 'config.yaml', 'media/table/Evaluation metrics Table_0_eb5485d79ff50175c9ec.table.json', 'media/table/Summaries Table_1_9eaff83a3e4d141d81f9.table.json', 'output.log', 'requirements.txt', 'wandb-metadata.json', 'wandb-summary.json']\n",
      "[debug] find keyword_num = 2 in Cerebras-GPT-6.7B-2-shot-2-keywords\n",
      "parsing run Cerebras-GPT-6.7B-1-shot-2-keywords\n",
      "['artifact/475059440/wandb_manifest.json', 'artifact/475059495/wandb_manifest.json', 'config.yaml', 'media/table/Evaluation metrics Table_0_228651f8b5140f4a188e.table.json', 'media/table/Summaries Table_1_f3fd41b219a5d7ce420d.table.json', 'output.log', 'requirements.txt', 'wandb-metadata.json', 'wandb-summary.json']\n",
      "[debug] find keyword_num = 2 in Cerebras-GPT-6.7B-1-shot-2-keywords\n",
      "parsing run Cerebras-GPT-6.7B-1-shot-1-keywords\n",
      "['artifact/474484632/wandb_manifest.json', 'artifact/474484767/wandb_manifest.json', 'config.yaml', 'media/table/Evaluation metrics Table_0_2ad364f108143ffa31ec.table.json', 'media/table/Summaries Table_1_a3979b97aa0cd47f5ea2.table.json', 'output.log', 'requirements.txt', 'wandb-metadata.json', 'wandb-summary.json']\n",
      "[debug] find keyword_num = 1 in Cerebras-GPT-6.7B-1-shot-1-keywords\n",
      "parsing run Cerebras-GPT-6.7B-2-shot-1-keywords\n",
      "['artifact/474544341/wandb_manifest.json', 'artifact/474544562/wandb_manifest.json', 'config.yaml', 'media/table/Evaluation metrics Table_0_04ef3e3adb8bdc0f6c2b.table.json', 'media/table/Summaries Table_1_e7344c13c770cc87913e.table.json', 'output.log', 'requirements.txt', 'wandb-metadata.json', 'wandb-summary.json']\n",
      "[debug] find keyword_num = 1 in Cerebras-GPT-6.7B-2-shot-1-keywords\n",
      "parsing run Cerebras-GPT-6.7B-2-shot\n",
      "['artifact/468933176/wandb_manifest.json', 'artifact/468933216/wandb_manifest.json', 'config.yaml', 'media/table/Evaluation metrics Table_0_656b714ee9654951509d.table.json', 'media/table/Summaries Table_1_3e4bf67f636a2d78a4f0.table.json', 'output.log', 'requirements.txt', 'wandb-metadata.json', 'wandb-summary.json']\n",
      "parsing run Cerebras-GPT-6.7B-1-shot\n",
      "['artifact/468900427/wandb_manifest.json', 'artifact/468900486/wandb_manifest.json', 'config.yaml', 'media/table/Evaluation metrics Table_0_13a5c94b79ff97e89b5c.table.json', 'media/table/Summaries Table_1_c454ed24e67581a8f6c1.table.json', 'output.log', 'requirements.txt', 'wandb-metadata.json', 'wandb-summary.json']\n",
      "parsing run Cerebras-6.7B-3-shot\n",
      "['artifact/460934750/wandb_manifest.json', 'artifact/460934805/wandb_manifest.json', 'config.yaml', 'media/table/Evaluation metrics Table_0_79de4653b96bdd3516d6.table.json', 'media/table/Summaries Table_1_1862cad7895785859830.table.json', 'output.log', 'requirements.txt', 'wandb-metadata.json', 'wandb-summary.json']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Cerebras-GPT-6.7B-3-shot-2-keywords':       run_id                                             prompt  \\\n",
       " 0          0  Summarize the conversation with keywords:\\nCar...   \n",
       " 1          0  Summarize the conversation with keywords:\\nJus...   \n",
       " 2          0  Summarize the conversation with keywords:\\nDan...   \n",
       " 3          0  Summarize the conversation with keywords:\\nTom...   \n",
       " 4          0  Summarize the conversation with keywords:\\nOti...   \n",
       " ...      ...                                                ...   \n",
       " 2457       3  Summarize the conversation with keywords:\\nDer...   \n",
       " 2458       3  Summarize the conversation with keywords:\\nTri...   \n",
       " 2459       3  Summarize the conversation with keywords:\\nJas...   \n",
       " 2460       3  Summarize the conversation with keywords:\\nJak...   \n",
       " 2461       3  Summarize the conversation with keywords:\\nJul...   \n",
       " \n",
       "                                            pred_summary  \\\n",
       " 0     Hannah needs Larry's phone number. Amanda will...   \n",
       " 1     Eric is watching Rob's youtube videos. Rob wil...   \n",
       " 2     Lenny sent Bob a photo of himself wearing a pa...   \n",
       " 3     Emma is sure that she is going to be late for ...   \n",
       " 4     Jane is on her way to a party in OLLIE'S flat....   \n",
       " ...                                                 ...   \n",
       " 2457  Hannah needs to talk to Larry. Amanda is not s...   \n",
       " 2458  Eric watches Rob's youtube videos. Rob shows E...   \n",
       " 2459  Lenny is looking for a pair of trousers to buy...   \n",
       " 2460  Emma is worried that Will won't be able to coo...   \n",
       " 2461  Jane is going to a party on Friday night. She ...   \n",
       " \n",
       "                                            gold_summary  k         model_name  \\\n",
       " 0     Hannah needs Betty's number but Amanda doesn't...  3  Cerebras-GPT-6.7B   \n",
       " 1     Eric and Rob are going to watch a stand-up on ...  3  Cerebras-GPT-6.7B   \n",
       " 2     Lenny can't decide which trousers to buy. Bob ...  3  Cerebras-GPT-6.7B   \n",
       " 3     Emma will be home soon and she will let Will k...  3  Cerebras-GPT-6.7B   \n",
       " 4     Jane is in Warsaw. Ollie and Jane has a party....  3  Cerebras-GPT-6.7B   \n",
       " ...                                                 ... ..                ...   \n",
       " 2457  Hannah needs Betty's number but Amanda doesn't...  3  Cerebras-GPT-6.7B   \n",
       " 2458  Eric and Rob are going to watch a stand-up on ...  3  Cerebras-GPT-6.7B   \n",
       " 2459  Lenny can't decide which trousers to buy. Bob ...  3  Cerebras-GPT-6.7B   \n",
       " 2460  Emma will be home soon and she will let Will k...  3  Cerebras-GPT-6.7B   \n",
       " 2461  Jane is in Warsaw. Ollie and Jane has a party....  3  Cerebras-GPT-6.7B   \n",
       " \n",
       "      keyword_num  \n",
       " 0              2  \n",
       " 1              2  \n",
       " 2              2  \n",
       " 3              2  \n",
       " 4              2  \n",
       " ...          ...  \n",
       " 2457           2  \n",
       " 2458           2  \n",
       " 2459           2  \n",
       " 2460           2  \n",
       " 2461           2  \n",
       " \n",
       " [2462 rows x 7 columns],\n",
       " 'Cerebras-GPT-6.7B-1-shot-3-keywords':       run_id                                             prompt  \\\n",
       " 0          0  Summarize the conversation with keywords:\\nTan...   \n",
       " 1          0  Summarize the conversation with keywords:\\nChr...   \n",
       " 2          0  Summarize the conversation with keywords:\\nSam...   \n",
       " 3          0  Summarize the conversation with keywords:\\nOwe...   \n",
       " 4          0  Summarize the conversation with keywords:\\nAly...   \n",
       " ...      ...                                                ...   \n",
       " 4090       4  Summarize the conversation with keywords:\\nHea...   \n",
       " 4091       4  Summarize the conversation with keywords:\\nKev...   \n",
       " 4092       4  Summarize the conversation with keywords:\\nSel...   \n",
       " 4093       4  Summarize the conversation with keywords:\\nJam...   \n",
       " 4094       4  Summarize the conversation with keywords:\\nJim...   \n",
       " \n",
       "                                            pred_summary  \\\n",
       " 0     Hannah needs to contact Larry. She doesn't hav...   \n",
       " 1     Eric is watching Rob's youtube videos. Rob is ...   \n",
       " 2     Lenny has 4 pairs of black trousers, Bob has 2...   \n",
       " 3     Emma told Will that she would be back soon. Wi...   \n",
       " 4     Jane was invited to a lunch with an old friend...   \n",
       " ...                                                 ...   \n",
       " 4090  Benjamin declares that he is going to play bas...   \n",
       " 4091  Jamilla will remember the time for the auditions.   \n",
       " 4092  Marta accidentally sends a file from her galle...   \n",
       " 4093  James meets Cora and Ellie in a Birmingham mal...   \n",
       " 4094  Janice will include Rachel in her top 50 best ...   \n",
       " \n",
       "                                            gold_summary  k         model_name  \\\n",
       " 0     Hannah needs Betty's number but Amanda doesn't...  1  Cerebras-GPT-6.7B   \n",
       " 1     Eric and Rob are going to watch a stand-up on ...  1  Cerebras-GPT-6.7B   \n",
       " 2     Lenny can't decide which trousers to buy. Bob ...  1  Cerebras-GPT-6.7B   \n",
       " 3     Emma will be home soon and she will let Will k...  1  Cerebras-GPT-6.7B   \n",
       " 4     Jane is in Warsaw. Ollie and Jane has a party....  1  Cerebras-GPT-6.7B   \n",
       " ...                                                 ... ..                ...   \n",
       " 4090  Benjamin didn't come to see a basketball game ...  1  Cerebras-GPT-6.7B   \n",
       " 4091      The audition starts at 7.30 P.M. in Antena 3.  1  Cerebras-GPT-6.7B   \n",
       " 4092                    Marta sent a file accidentally,  1  Cerebras-GPT-6.7B   \n",
       " 4093  There was a meet-and-greet with James Charles ...  1  Cerebras-GPT-6.7B   \n",
       " 4094  Rachel sends a list of Top 50 films of 2018. J...  1  Cerebras-GPT-6.7B   \n",
       " \n",
       "      keyword_num  \n",
       " 0              3  \n",
       " 1              3  \n",
       " 2              3  \n",
       " 3              3  \n",
       " 4              3  \n",
       " ...          ...  \n",
       " 4090           3  \n",
       " 4091           3  \n",
       " 4092           3  \n",
       " 4093           3  \n",
       " 4094           3  \n",
       " \n",
       " [4095 rows x 7 columns],\n",
       " 'Cerebras-GPT-6.7B-2-shot-3-keywords':       run_id                                             prompt  \\\n",
       " 0          0  Summarize the conversation with keywords:\\nJoh...   \n",
       " 1          0  Summarize the conversation with keywords:\\nLis...   \n",
       " 2          0  Summarize the conversation with keywords:\\nLar...   \n",
       " 3          0  Summarize the conversation with keywords:\\nLol...   \n",
       " 4          0  Summarize the conversation with keywords:\\nRob...   \n",
       " ...      ...                                                ...   \n",
       " 4090       4  Summarize the conversation with keywords:\\nCar...   \n",
       " 4091       4  Summarize the conversation with keywords:\\nNic...   \n",
       " 4092       4  Summarize the conversation with keywords:\\nJac...   \n",
       " 4093       4  Summarize the conversation with keywords:\\nIan...   \n",
       " 4094       4  Summarize the conversation with keywords:\\nCla...   \n",
       " \n",
       "                                            pred_summary  \\\n",
       " 0     Hannah needs to contact Larry. She doesn't hav...   \n",
       " 1     Eric watched Rob's youtube videos. Rob is a st...   \n",
       " 2     Lenny asks Bob if he can help him pick out a p...   \n",
       " 3     Emma is worried that she won't be able to cook...   \n",
       " 4     Jane is going to a party on Friday and she wan...   \n",
       " ...                                                 ...   \n",
       " 4090  Benjamin declares that he is going to play bas...   \n",
       " 4091  Jamilla and Kiki are auditioning for a new TV ...   \n",
       " 4092  Marta accidentally sent a file from her galler...   \n",
       " 4093  There were a lot of people who came to meet Ja...   \n",
       " 4094  Rachel watches the 50 best films of the year. ...   \n",
       " \n",
       "                                            gold_summary  k         model_name  \\\n",
       " 0     Hannah needs Betty's number but Amanda doesn't...  2  Cerebras-GPT-6.7B   \n",
       " 1     Eric and Rob are going to watch a stand-up on ...  2  Cerebras-GPT-6.7B   \n",
       " 2     Lenny can't decide which trousers to buy. Bob ...  2  Cerebras-GPT-6.7B   \n",
       " 3     Emma will be home soon and she will let Will k...  2  Cerebras-GPT-6.7B   \n",
       " 4     Jane is in Warsaw. Ollie and Jane has a party....  2  Cerebras-GPT-6.7B   \n",
       " ...                                                 ... ..                ...   \n",
       " 4090  Benjamin didn't come to see a basketball game ...  2  Cerebras-GPT-6.7B   \n",
       " 4091      The audition starts at 7.30 P.M. in Antena 3.  2  Cerebras-GPT-6.7B   \n",
       " 4092                    Marta sent a file accidentally,  2  Cerebras-GPT-6.7B   \n",
       " 4093  There was a meet-and-greet with James Charles ...  2  Cerebras-GPT-6.7B   \n",
       " 4094  Rachel sends a list of Top 50 films of 2018. J...  2  Cerebras-GPT-6.7B   \n",
       " \n",
       "      keyword_num  \n",
       " 0              3  \n",
       " 1              3  \n",
       " 2              3  \n",
       " 3              3  \n",
       " 4              3  \n",
       " ...          ...  \n",
       " 4090           3  \n",
       " 4091           3  \n",
       " 4092           3  \n",
       " 4093           3  \n",
       " 4094           3  \n",
       " \n",
       " [4095 rows x 7 columns],\n",
       " 'Cerebras-GPT-6.7B-3-shot-1-keywords':       run_id                                             prompt  \\\n",
       " 0          0  Summarize the conversation with keywords:\\nCar...   \n",
       " 1          0  Summarize the conversation with keywords:\\nJus...   \n",
       " 2          0  Summarize the conversation with keywords:\\nDan...   \n",
       " 3          0  Summarize the conversation with keywords:\\nTom...   \n",
       " 4          0  Summarize the conversation with keywords:\\nOti...   \n",
       " ...      ...                                                ...   \n",
       " 2457       3  Summarize the conversation with keywords:\\nDer...   \n",
       " 2458       3  Summarize the conversation with keywords:\\nTri...   \n",
       " 2459       3  Summarize the conversation with keywords:\\nJas...   \n",
       " 2460       3  Summarize the conversation with keywords:\\nJak...   \n",
       " 2461       3  Summarize the conversation with keywords:\\nJul...   \n",
       " \n",
       "                                            pred_summary  \\\n",
       " 0     Hannah needs Amanda's phone number so she can ...   \n",
       " 1     Rob and Eric are watching Rob's youtube videos...   \n",
       " 2     Lenny asked Bob to send him some photos of him...   \n",
       " 3     Emma is worried about Will's dinner plans toni...   \n",
       " 4     Jane is on her way to a party in Poland. Jane ...   \n",
       " ...                                                 ...   \n",
       " 2457  Hannah needs Amanda's phone number. Amanda is ...   \n",
       " 2458  Eric is watching Rob's stand up videos. Rob is...   \n",
       " 2459  Lenny wants to buy a pair of pants. Bob says t...   \n",
       " 2460  Emma sends Will a text message. She is worried...   \n",
       " 2461  Jane is going on a trip with her friends. She ...   \n",
       " \n",
       "                                            gold_summary  k         model_name  \\\n",
       " 0     Hannah needs Betty's number but Amanda doesn't...  3  Cerebras-GPT-6.7B   \n",
       " 1     Eric and Rob are going to watch a stand-up on ...  3  Cerebras-GPT-6.7B   \n",
       " 2     Lenny can't decide which trousers to buy. Bob ...  3  Cerebras-GPT-6.7B   \n",
       " 3     Emma will be home soon and she will let Will k...  3  Cerebras-GPT-6.7B   \n",
       " 4     Jane is in Warsaw. Ollie and Jane has a party....  3  Cerebras-GPT-6.7B   \n",
       " ...                                                 ... ..                ...   \n",
       " 2457  Hannah needs Betty's number but Amanda doesn't...  3  Cerebras-GPT-6.7B   \n",
       " 2458  Eric and Rob are going to watch a stand-up on ...  3  Cerebras-GPT-6.7B   \n",
       " 2459  Lenny can't decide which trousers to buy. Bob ...  3  Cerebras-GPT-6.7B   \n",
       " 2460  Emma will be home soon and she will let Will k...  3  Cerebras-GPT-6.7B   \n",
       " 2461  Jane is in Warsaw. Ollie and Jane has a party....  3  Cerebras-GPT-6.7B   \n",
       " \n",
       "      keyword_num  \n",
       " 0              1  \n",
       " 1              1  \n",
       " 2              1  \n",
       " 3              1  \n",
       " 4              1  \n",
       " ...          ...  \n",
       " 2457           1  \n",
       " 2458           1  \n",
       " 2459           1  \n",
       " 2460           1  \n",
       " 2461           1  \n",
       " \n",
       " [2462 rows x 7 columns],\n",
       " 'Cerebras-GPT-6.7B-2-shot-2-keywords':       run_id                                             prompt  \\\n",
       " 0          0  Summarize the conversation with keywords:\\nJoh...   \n",
       " 1          0  Summarize the conversation with keywords:\\nLis...   \n",
       " 2          0  Summarize the conversation with keywords:\\nLar...   \n",
       " 3          0  Summarize the conversation with keywords:\\nLol...   \n",
       " 4          0  Summarize the conversation with keywords:\\nRob...   \n",
       " ...      ...                                                ...   \n",
       " 4090       4  Summarize the conversation with keywords:\\nCar...   \n",
       " 4091       4  Summarize the conversation with keywords:\\nNic...   \n",
       " 4092       4  Summarize the conversation with keywords:\\nJac...   \n",
       " 4093       4  Summarize the conversation with keywords:\\nIan...   \n",
       " 4094       4  Summarize the conversation with keywords:\\nCla...   \n",
       " \n",
       "                                            pred_summary  \\\n",
       " 0     Amanda needs Larry's phone number. She doesn't...   \n",
       " 1     Eric is watching Rob's youtube videos. Rob has...   \n",
       " 2     Lenny asks Bob which pair of trousers he shoul...   \n",
       " 3     Emma is worried that she won't be able to cook...   \n",
       " 4     Jane is on her way to a party in OLLIE'S house...   \n",
       " ...                                                 ...   \n",
       " 4090  Benjamin is a basketball fan. He went to a gam...   \n",
       " 4091  Jamilla and Kiki will be auditioning for a new...   \n",
       " 4092  Marta has sent a file from her gallery. She is...   \n",
       " 4093  There were a lot of people who came to meet Ja...   \n",
       " 4094  Janice watches the 50 best films of the year. ...   \n",
       " \n",
       "                                            gold_summary  k         model_name  \\\n",
       " 0     Hannah needs Betty's number but Amanda doesn't...  2  Cerebras-GPT-6.7B   \n",
       " 1     Eric and Rob are going to watch a stand-up on ...  2  Cerebras-GPT-6.7B   \n",
       " 2     Lenny can't decide which trousers to buy. Bob ...  2  Cerebras-GPT-6.7B   \n",
       " 3     Emma will be home soon and she will let Will k...  2  Cerebras-GPT-6.7B   \n",
       " 4     Jane is in Warsaw. Ollie and Jane has a party....  2  Cerebras-GPT-6.7B   \n",
       " ...                                                 ... ..                ...   \n",
       " 4090  Benjamin didn't come to see a basketball game ...  2  Cerebras-GPT-6.7B   \n",
       " 4091      The audition starts at 7.30 P.M. in Antena 3.  2  Cerebras-GPT-6.7B   \n",
       " 4092                    Marta sent a file accidentally,  2  Cerebras-GPT-6.7B   \n",
       " 4093  There was a meet-and-greet with James Charles ...  2  Cerebras-GPT-6.7B   \n",
       " 4094  Rachel sends a list of Top 50 films of 2018. J...  2  Cerebras-GPT-6.7B   \n",
       " \n",
       "      keyword_num  \n",
       " 0              2  \n",
       " 1              2  \n",
       " 2              2  \n",
       " 3              2  \n",
       " 4              2  \n",
       " ...          ...  \n",
       " 4090           2  \n",
       " 4091           2  \n",
       " 4092           2  \n",
       " 4093           2  \n",
       " 4094           2  \n",
       " \n",
       " [4095 rows x 7 columns],\n",
       " 'Cerebras-GPT-6.7B-1-shot-2-keywords':       run_id                                             prompt  \\\n",
       " 0          0  Summarize the conversation with keywords:\\nTan...   \n",
       " 1          0  Summarize the conversation with keywords:\\nChr...   \n",
       " 2          0  Summarize the conversation with keywords:\\nSam...   \n",
       " 3          0  Summarize the conversation with keywords:\\nOwe...   \n",
       " 4          0  Summarize the conversation with keywords:\\nAly...   \n",
       " ...      ...                                                ...   \n",
       " 4090       4  Summarize the conversation with keywords:\\nHea...   \n",
       " 4091       4  Summarize the conversation with keywords:\\nKev...   \n",
       " 4092       4  Summarize the conversation with keywords:\\nSel...   \n",
       " 4093       4  Summarize the conversation with keywords:\\nJam...   \n",
       " 4094       4  Summarize the conversation with keywords:\\nJim...   \n",
       " \n",
       "                                            pred_summary  \\\n",
       " 0     Amanda needs to get in touch with Betty. Larry...   \n",
       " 1     Eric is watching Rob's youtube videos. Rob is ...   \n",
       " 2     Lenny is looking for a pair of pants. He has f...   \n",
       " 3     Emma is worried that she won't be able to cook...   \n",
       " 4     Jane was talking to Jane about her plans for t...   \n",
       " ...                                                 ...   \n",
       " 4090  Benjamin is disappointed that he couldn't atte...   \n",
       " 4091  Jamilla will remember the time for the auditions.   \n",
       " 4092  Marta sends a file from her gallery to the girls.   \n",
       " 4093  Cora, Ellie and James gathered in a mall to me...   \n",
       " 4094  Janice will include Rachel in her top 50 best ...   \n",
       " \n",
       "                                            gold_summary  k         model_name  \\\n",
       " 0     Hannah needs Betty's number but Amanda doesn't...  1  Cerebras-GPT-6.7B   \n",
       " 1     Eric and Rob are going to watch a stand-up on ...  1  Cerebras-GPT-6.7B   \n",
       " 2     Lenny can't decide which trousers to buy. Bob ...  1  Cerebras-GPT-6.7B   \n",
       " 3     Emma will be home soon and she will let Will k...  1  Cerebras-GPT-6.7B   \n",
       " 4     Jane is in Warsaw. Ollie and Jane has a party....  1  Cerebras-GPT-6.7B   \n",
       " ...                                                 ... ..                ...   \n",
       " 4090  Benjamin didn't come to see a basketball game ...  1  Cerebras-GPT-6.7B   \n",
       " 4091      The audition starts at 7.30 P.M. in Antena 3.  1  Cerebras-GPT-6.7B   \n",
       " 4092                    Marta sent a file accidentally,  1  Cerebras-GPT-6.7B   \n",
       " 4093  There was a meet-and-greet with James Charles ...  1  Cerebras-GPT-6.7B   \n",
       " 4094  Rachel sends a list of Top 50 films of 2018. J...  1  Cerebras-GPT-6.7B   \n",
       " \n",
       "      keyword_num  \n",
       " 0              2  \n",
       " 1              2  \n",
       " 2              2  \n",
       " 3              2  \n",
       " 4              2  \n",
       " ...          ...  \n",
       " 4090           2  \n",
       " 4091           2  \n",
       " 4092           2  \n",
       " 4093           2  \n",
       " 4094           2  \n",
       " \n",
       " [4095 rows x 7 columns],\n",
       " 'Cerebras-GPT-6.7B-1-shot-1-keywords':       run_id                                             prompt  \\\n",
       " 0          0  Summarize the conversation with keywords:\\nTan...   \n",
       " 1          0  Summarize the conversation with keywords:\\nChr...   \n",
       " 2          0  Summarize the conversation with keywords:\\nSam...   \n",
       " 3          0  Summarize the conversation with keywords:\\nOwe...   \n",
       " 4          0  Summarize the conversation with keywords:\\nAly...   \n",
       " ...      ...                                                ...   \n",
       " 4090       4  Summarize the conversation with keywords:\\nHea...   \n",
       " 4091       4  Summarize the conversation with keywords:\\nKev...   \n",
       " 4092       4  Summarize the conversation with keywords:\\nSel...   \n",
       " 4093       4  Summarize the conversation with keywords:\\nJam...   \n",
       " 4094       4  Summarize the conversation with keywords:\\nJim...   \n",
       " \n",
       "                                            pred_summary  \\\n",
       " 0     Needs: Hannah needs to talk to Betty. She does...   \n",
       " 1     Eric is watching Rob's videos. Rob is a stand ...   \n",
       " 2     Lenny wants to buy a pair of pants. Bob says h...   \n",
       " 3     Emma is worried about her boyfriend Will. Will...   \n",
       " 4     Jane was talking about her plans for the weeke...   \n",
       " ...                                                 ...   \n",
       " 4090  Benjamin is disappointed that he couldn't atte...   \n",
       " 4091  Jamilla will remember the time of the\\nauditio...   \n",
       " 4092  Marta sends a file from her gallery to the gro...   \n",
       " 4093  A meet-and-greet with an \"almost-unknown\" YouT...   \n",
       " 4094  Rachel will include Janice in her top 50 best ...   \n",
       " \n",
       "                                            gold_summary  k         model_name  \\\n",
       " 0     Hannah needs Betty's number but Amanda doesn't...  1  Cerebras-GPT-6.7B   \n",
       " 1     Eric and Rob are going to watch a stand-up on ...  1  Cerebras-GPT-6.7B   \n",
       " 2     Lenny can't decide which trousers to buy. Bob ...  1  Cerebras-GPT-6.7B   \n",
       " 3     Emma will be home soon and she will let Will k...  1  Cerebras-GPT-6.7B   \n",
       " 4     Jane is in Warsaw. Ollie and Jane has a party....  1  Cerebras-GPT-6.7B   \n",
       " ...                                                 ... ..                ...   \n",
       " 4090  Benjamin didn't come to see a basketball game ...  1  Cerebras-GPT-6.7B   \n",
       " 4091      The audition starts at 7.30 P.M. in Antena 3.  1  Cerebras-GPT-6.7B   \n",
       " 4092                    Marta sent a file accidentally,  1  Cerebras-GPT-6.7B   \n",
       " 4093  There was a meet-and-greet with James Charles ...  1  Cerebras-GPT-6.7B   \n",
       " 4094  Rachel sends a list of Top 50 films of 2018. J...  1  Cerebras-GPT-6.7B   \n",
       " \n",
       "      keyword_num  \n",
       " 0              1  \n",
       " 1              1  \n",
       " 2              1  \n",
       " 3              1  \n",
       " 4              1  \n",
       " ...          ...  \n",
       " 4090           1  \n",
       " 4091           1  \n",
       " 4092           1  \n",
       " 4093           1  \n",
       " 4094           1  \n",
       " \n",
       " [4095 rows x 7 columns],\n",
       " 'Cerebras-GPT-6.7B-2-shot-1-keywords':       run_id                                             prompt  \\\n",
       " 0          0  Summarize the conversation with keywords:\\nJoh...   \n",
       " 1          0  Summarize the conversation with keywords:\\nLis...   \n",
       " 2          0  Summarize the conversation with keywords:\\nLar...   \n",
       " 3          0  Summarize the conversation with keywords:\\nLol...   \n",
       " 4          0  Summarize the conversation with keywords:\\nRob...   \n",
       " ...      ...                                                ...   \n",
       " 4090       4  Summarize the conversation with keywords:\\nCar...   \n",
       " 4091       4  Summarize the conversation with keywords:\\nNic...   \n",
       " 4092       4  Summarize the conversation with keywords:\\nJac...   \n",
       " 4093       4  Summarize the conversation with keywords:\\nIan...   \n",
       " 4094       4  Summarize the conversation with keywords:\\nCla...   \n",
       " \n",
       "                                            pred_summary  \\\n",
       " 0     Amanda is looking for Betty. Betty is Amanda's...   \n",
       " 1     Eric is watching Rob's videos on YouTube. Rob ...   \n",
       " 2     Lenny asks Bob if he can help him pick out a p...   \n",
       " 3     Emma is worried that she won't be able to cook...   \n",
       " 4     Jane is on her way to a party. She is going to...   \n",
       " ...                                                 ...   \n",
       " 4090  Benjamin is talking to Alex on the phone. He i...   \n",
       " 4091  Jamilla and Kiki will go to Antenna 3 to watch...   \n",
       " 4092  Marta has sent a file from her gallery. She is...   \n",
       " 4093  A meet-and-greet with an \"unrecognized\" YouTub...   \n",
       " 4094  Rachel watches the 50 best films of the year. ...   \n",
       " \n",
       "                                            gold_summary  k         model_name  \\\n",
       " 0     Hannah needs Betty's number but Amanda doesn't...  2  Cerebras-GPT-6.7B   \n",
       " 1     Eric and Rob are going to watch a stand-up on ...  2  Cerebras-GPT-6.7B   \n",
       " 2     Lenny can't decide which trousers to buy. Bob ...  2  Cerebras-GPT-6.7B   \n",
       " 3     Emma will be home soon and she will let Will k...  2  Cerebras-GPT-6.7B   \n",
       " 4     Jane is in Warsaw. Ollie and Jane has a party....  2  Cerebras-GPT-6.7B   \n",
       " ...                                                 ... ..                ...   \n",
       " 4090  Benjamin didn't come to see a basketball game ...  2  Cerebras-GPT-6.7B   \n",
       " 4091      The audition starts at 7.30 P.M. in Antena 3.  2  Cerebras-GPT-6.7B   \n",
       " 4092                    Marta sent a file accidentally,  2  Cerebras-GPT-6.7B   \n",
       " 4093  There was a meet-and-greet with James Charles ...  2  Cerebras-GPT-6.7B   \n",
       " 4094  Rachel sends a list of Top 50 films of 2018. J...  2  Cerebras-GPT-6.7B   \n",
       " \n",
       "      keyword_num  \n",
       " 0              1  \n",
       " 1              1  \n",
       " 2              1  \n",
       " 3              1  \n",
       " 4              1  \n",
       " ...          ...  \n",
       " 4090           1  \n",
       " 4091           1  \n",
       " 4092           1  \n",
       " 4093           1  \n",
       " 4094           1  \n",
       " \n",
       " [4095 rows x 7 columns],\n",
       " 'Cerebras-GPT-6.7B-2-shot':       run_id                                             prompt  \\\n",
       " 0          0  Summarize the conversation:\\nJohn: How are you...   \n",
       " 1          0  Summarize the conversation:\\nLisa: hey there, ...   \n",
       " 2          0  Summarize the conversation:\\nLarry: Andy, you'...   \n",
       " 3          0  Summarize the conversation:\\nLolita: High hand...   \n",
       " 4          0  Summarize the conversation:\\nRobert: Hey sunsh...   \n",
       " ...      ...                                                ...   \n",
       " 4090       4  Summarize the conversation:\\nCaroline: There a...   \n",
       " 4091       4  Summarize the conversation:\\nNicholas: what's ...   \n",
       " 4092       4  Summarize the conversation:\\nJackson: Hey so I...   \n",
       " 4093       4  Summarize the conversation:\\nIan: On way back ...   \n",
       " 4094       4  Summarize the conversation:\\nClaire: I'm afrai...   \n",
       " \n",
       "                                            pred_summary  \\\n",
       " 0     Hannah and Amanda are at a park. Hannah wants ...   \n",
       " 1     Rob and Eric watch Rob's stand up videos. Rob ...   \n",
       " 2     Bob tells Lenny to send him photos of the clot...   \n",
       " 3     Emma is worried that Will won't be able to coo...   \n",
       " 4     Jane is on her way to a party. She is going to...   \n",
       " ...                                                 ...   \n",
       " 4090  Benjamin is a basketball fan. He wants to see ...   \n",
       " 4091  Jamilla and Kiki will go to the radio station ...   \n",
       " 4092  Marta has sent a file from her gallery. She is...   \n",
       " 4093  Cora and Ellie are talking about the meet-and-...   \n",
       " 4094  Rachel and Janice watch the top 50 best films ...   \n",
       " \n",
       "                                            gold_summary  k         model_name  \\\n",
       " 0     Hannah needs Betty's number but Amanda doesn't...  2  Cerebras-GPT-6.7B   \n",
       " 1     Eric and Rob are going to watch a stand-up on ...  2  Cerebras-GPT-6.7B   \n",
       " 2     Lenny can't decide which trousers to buy. Bob ...  2  Cerebras-GPT-6.7B   \n",
       " 3     Emma will be home soon and she will let Will k...  2  Cerebras-GPT-6.7B   \n",
       " 4     Jane is in Warsaw. Ollie and Jane has a party....  2  Cerebras-GPT-6.7B   \n",
       " ...                                                 ... ..                ...   \n",
       " 4090  Benjamin didn't come to see a basketball game ...  2  Cerebras-GPT-6.7B   \n",
       " 4091      The audition starts at 7.30 P.M. in Antena 3.  2  Cerebras-GPT-6.7B   \n",
       " 4092                    Marta sent a file accidentally,  2  Cerebras-GPT-6.7B   \n",
       " 4093  There was a meet-and-greet with James Charles ...  2  Cerebras-GPT-6.7B   \n",
       " 4094  Rachel sends a list of Top 50 films of 2018. J...  2  Cerebras-GPT-6.7B   \n",
       " \n",
       "      keyword_num  \n",
       " 0           None  \n",
       " 1           None  \n",
       " 2           None  \n",
       " 3           None  \n",
       " 4           None  \n",
       " ...          ...  \n",
       " 4090        None  \n",
       " 4091        None  \n",
       " 4092        None  \n",
       " 4093        None  \n",
       " 4094        None  \n",
       " \n",
       " [4095 rows x 7 columns],\n",
       " 'Cerebras-GPT-6.7B-1-shot':       run_id                                             prompt  \\\n",
       " 0          0  Summarize the conversation:\\nTania: Check out ...   \n",
       " 1          0  Summarize the conversation:\\nChris: how is you...   \n",
       " 2          0  Summarize the conversation:\\nSamuel: Stop and ...   \n",
       " 3          0  Summarize the conversation:\\nOwen: guys i am s...   \n",
       " 4          0  Summarize the conversation:\\nAlyssa: have you ...   \n",
       " ...      ...                                                ...   \n",
       " 4090       4  Summarize the conversation:\\nHeather: Eh, I've...   \n",
       " 4091       4  Summarize the conversation:\\nKevin: Hi, will y...   \n",
       " 4092       4  Summarize the conversation:\\nSelby: anybody fo...   \n",
       " 4093       4  Summarize the conversation:\\nJames: sorry boss...   \n",
       " 4094       4  Summarize the conversation:\\nJimmy: get me som...   \n",
       " \n",
       "                                            pred_summary  \\\n",
       " 0     Amanda is trying to find out who Hannah's new ...   \n",
       " 1     Eric is watching Rob's youtube videos. Rob is ...   \n",
       " 2     Lenny wants to buy a pair of pants. Bob says h...   \n",
       " 3     Will and Emma are having dinner. Will is worri...   \n",
       " 4     Jane is on her way to a party, where she is go...   \n",
       " ...                                                 ...   \n",
       " 4090  Benjamin is disappointed that he couldn't atte...   \n",
       " 4091  Jamilla and Kiki will go to Antenna 3 to watch...   \n",
       " 4092  Marta sends a file from her gallery to the gro...   \n",
       " 4093  Cora and Ellie are talking about the meet-and-...   \n",
       " 4094  Rachel tells Janice that she has watched all t...   \n",
       " \n",
       "                                            gold_summary  k         model_name  \\\n",
       " 0     Hannah needs Betty's number but Amanda doesn't...  1  Cerebras-GPT-6.7B   \n",
       " 1     Eric and Rob are going to watch a stand-up on ...  1  Cerebras-GPT-6.7B   \n",
       " 2     Lenny can't decide which trousers to buy. Bob ...  1  Cerebras-GPT-6.7B   \n",
       " 3     Emma will be home soon and she will let Will k...  1  Cerebras-GPT-6.7B   \n",
       " 4     Jane is in Warsaw. Ollie and Jane has a party....  1  Cerebras-GPT-6.7B   \n",
       " ...                                                 ... ..                ...   \n",
       " 4090  Benjamin didn't come to see a basketball game ...  1  Cerebras-GPT-6.7B   \n",
       " 4091      The audition starts at 7.30 P.M. in Antena 3.  1  Cerebras-GPT-6.7B   \n",
       " 4092                    Marta sent a file accidentally,  1  Cerebras-GPT-6.7B   \n",
       " 4093  There was a meet-and-greet with James Charles ...  1  Cerebras-GPT-6.7B   \n",
       " 4094  Rachel sends a list of Top 50 films of 2018. J...  1  Cerebras-GPT-6.7B   \n",
       " \n",
       "      keyword_num  \n",
       " 0           None  \n",
       " 1           None  \n",
       " 2           None  \n",
       " 3           None  \n",
       " 4           None  \n",
       " ...          ...  \n",
       " 4090        None  \n",
       " 4091        None  \n",
       " 4092        None  \n",
       " 4093        None  \n",
       " 4094        None  \n",
       " \n",
       " [4095 rows x 7 columns],\n",
       " 'Cerebras-6.7B-3-shot':       run_id                                             prompt  \\\n",
       " 0          0  Summarize the conversation:\\nCarter: my dietit...   \n",
       " 1          0  Summarize the conversation:\\nJustin: hey max, ...   \n",
       " 2          0  Summarize the conversation:\\nDaniel: <file_pho...   \n",
       " 3          0  Summarize the conversation:\\nTom: How are you ...   \n",
       " 4          0  Summarize the conversation:\\nOti: hi girls, I ...   \n",
       " ...      ...                                                ...   \n",
       " 2457       3  Summarize the conversation:\\nDermi: What app d...   \n",
       " 2458       3  Summarize the conversation:\\nTristan: i lost m...   \n",
       " 2459       3  Summarize the conversation:\\nJason: When are y...   \n",
       " 2460       3  Summarize the conversation:\\nJake: <file_photo...   \n",
       " 2461       3  Summarize the conversation:\\nJulia: Hello Patr...   \n",
       " \n",
       "                                            pred_summary  \\\n",
       " 0     Hannah and Amanda are at a park. Hannah asks A...   \n",
       " 1     Eric is watching Rob's youtube videos. Rob wil...   \n",
       " 2     Bob told Lenny to send him photos of him weari...   \n",
       " 3     Will and Emma are having dinner together. Emma...   \n",
       " 4     Jane is on her way to a party in Poland.  She ...   \n",
       " ...                                                 ...   \n",
       " 2457  Hannah and Amanda are texting each other. Hann...   \n",
       " 2458  Eric is watching Rob's stand up videos. Rob te...   \n",
       " 2459  Bob and Lenny are shopping for clothes. Bob wa...   \n",
       " 2460  Emma tells Will that she is going to be late. ...   \n",
       " 2461  Jane is on her way to a party. She is going to...   \n",
       " \n",
       "                                            gold_summary  k     model_name  \\\n",
       " 0     Hannah needs Betty's number but Amanda doesn't...  3  Cerebras-6.7B   \n",
       " 1     Eric and Rob are going to watch a stand-up on ...  3  Cerebras-6.7B   \n",
       " 2     Lenny can't decide which trousers to buy. Bob ...  3  Cerebras-6.7B   \n",
       " 3     Emma will be home soon and she will let Will k...  3  Cerebras-6.7B   \n",
       " 4     Jane is in Warsaw. Ollie and Jane has a party....  3  Cerebras-6.7B   \n",
       " ...                                                 ... ..            ...   \n",
       " 2457  Hannah needs Betty's number but Amanda doesn't...  3  Cerebras-6.7B   \n",
       " 2458  Eric and Rob are going to watch a stand-up on ...  3  Cerebras-6.7B   \n",
       " 2459  Lenny can't decide which trousers to buy. Bob ...  3  Cerebras-6.7B   \n",
       " 2460  Emma will be home soon and she will let Will k...  3  Cerebras-6.7B   \n",
       " 2461  Jane is in Warsaw. Ollie and Jane has a party....  3  Cerebras-6.7B   \n",
       " \n",
       "      keyword_num  \n",
       " 0           None  \n",
       " 1           None  \n",
       " 2           None  \n",
       " 3           None  \n",
       " 4           None  \n",
       " ...          ...  \n",
       " 2457        None  \n",
       " 2458        None  \n",
       " 2459        None  \n",
       " 2460        None  \n",
       " 2461        None  \n",
       " \n",
       " [2462 rows x 7 columns]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iterate over completed runs to get summaries table\n",
    "MODEL_FAMILY = ['cerebras/Cerebras-GPT-6.7B']\n",
    "\n",
    "run2metric_table = {}\n",
    "for run in tqdm(runs):\n",
    "    if 'complete' not in run.tags or run.config['model_type'] not in MODEL_FAMILY or run.job_type != 'evaluation':\n",
    "        continue\n",
    "    if 'nameReplace' in run.name or 'length' in run.name or 'replaceName' in run.name or 'randomLabel' in run.name or 'focus' in run.name:\n",
    "        continue  \n",
    "    print('parsing run {}'.format(run.name))\n",
    "    files = run.files()\n",
    "    metric_file = [file for file in files if 'Summaries Table' in getattr(file, 'name', '')]\n",
    "    print([file.name for file in files])\n",
    "    if len(metric_file) < 1:\n",
    "        print('[WARN] skip {} because len(metric_file) >= 1'.format(metric_file))\n",
    "        continue \n",
    "    metric_file = metric_file[0]\n",
    "    f = metric_file.download(root='wandb', replace=True)\n",
    "    metrics = json.load(f)\n",
    "    metrics = json.dumps(metrics)\n",
    "    metric_table = pd.read_json(StringIO(metrics), orient='split')\n",
    "    # get k shot\n",
    "    match = re.search(r'\\d-shot', run.name)\n",
    "    start_i, end_i = match.span()\n",
    "    k = int(run.name[start_i: end_i].split('-')[0])\n",
    "\n",
    "    metric_table['k'] = k\n",
    "    model_name = run.name[: start_i - 1]\n",
    "    metric_table['model_name'] = model_name\n",
    "    if 'keyword' in run.name:\n",
    "        end_id = run.name.find('-keyword')\n",
    "        keyword_num = run.name[end_id - 1:end_id]\n",
    "        metric_table['keyword_num'] = keyword_num\n",
    "        print('[debug] find keyword_num = {} in {}'.format(keyword_num, run.name))\n",
    "    else:\n",
    "        metric_table['keyword_num'] = None\n",
    "\n",
    "    run2metric_table[run.name] = metric_table\n",
    "run2metric_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Cerebras-GPT-6.7B-3-shot-2-keywords', 'Cerebras-GPT-6.7B-1-shot-3-keywords', 'Cerebras-GPT-6.7B-2-shot-3-keywords', 'Cerebras-GPT-6.7B-3-shot-1-keywords', 'Cerebras-GPT-6.7B-2-shot-2-keywords', 'Cerebras-GPT-6.7B-1-shot-2-keywords', 'Cerebras-GPT-6.7B-1-shot-1-keywords', 'Cerebras-GPT-6.7B-2-shot-1-keywords', 'Cerebras-GPT-6.7B-2-shot', 'Cerebras-GPT-6.7B-1-shot', 'Cerebras-6.7B-3-shot'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run2metric_table.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_sentence(sentence):\n",
    "    if isinstance(sentence, str):\n",
    "        # Tokenize the sentence into words\n",
    "        words = word_tokenize(sentence)\n",
    "    else:\n",
    "        words = sentence\n",
    "    # Initialize the Porter stemmer\n",
    "    stemmer = PorterStemmer()\n",
    "    # Stem each word in the sentence\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]\n",
    "    # Join the stemmed words back into a sentence\n",
    "    return stemmed_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] parse experiment Cerebras-GPT-6.7B-3-shot-2-keywords\n",
      "[info] parse run 0\n",
      "[info] parse run 1\n",
      "[info] parse run 2\n",
      "[info] parse run 3\n",
      "[info] parse experiment Cerebras-GPT-6.7B-1-shot-3-keywords\n",
      "[info] parse run 0\n",
      "[info] parse run 1\n",
      "[info] parse run 2\n",
      "[info] parse run 3\n",
      "[info] parse run 4\n",
      "[info] parse experiment Cerebras-GPT-6.7B-2-shot-3-keywords\n",
      "[info] parse run 0\n",
      "[info] parse run 1\n",
      "[info] parse run 2\n",
      "[info] parse run 3\n",
      "[info] parse run 4\n",
      "[info] parse experiment Cerebras-GPT-6.7B-3-shot-1-keywords\n",
      "[info] parse run 0\n",
      "[info] parse run 1\n",
      "[info] parse run 2\n",
      "[info] parse run 3\n",
      "[info] parse experiment Cerebras-GPT-6.7B-2-shot-2-keywords\n",
      "[info] parse run 0\n",
      "[info] parse run 1\n",
      "[info] parse run 2\n",
      "[info] parse run 3\n",
      "[info] parse run 4\n",
      "[info] parse experiment Cerebras-GPT-6.7B-1-shot-2-keywords\n",
      "[info] parse run 0\n",
      "[info] parse run 1\n",
      "[info] parse run 2\n",
      "[info] parse run 3\n",
      "[info] parse run 4\n",
      "[info] parse experiment Cerebras-GPT-6.7B-1-shot-1-keywords\n",
      "[info] parse run 0\n",
      "[info] parse run 1\n",
      "[info] parse run 2\n",
      "[info] parse run 3\n",
      "[info] parse run 4\n",
      "[info] parse experiment Cerebras-GPT-6.7B-2-shot-1-keywords\n",
      "[info] parse run 0\n",
      "[info] parse run 1\n",
      "[info] parse run 2\n",
      "[info] parse run 3\n",
      "[info] parse run 4\n",
      "[info] parse experiment Cerebras-GPT-6.7B-2-shot\n",
      "[info] parse experiment Cerebras-GPT-6.7B-1-shot\n",
      "[info] parse experiment Cerebras-6.7B-3-shot\n",
      "7274 summaries with numerical information and 3799 responses contain numerical information\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>k</th>\n",
       "      <th>keyword_num</th>\n",
       "      <th>success_rate</th>\n",
       "      <th>run_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.757021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.758242</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.755189</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.737892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.724054</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.735450</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.738706</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.734229</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.729752</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.741962</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.728531</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.716728</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.720391</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.791209</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.781441</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.791209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.755189</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.753358</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.758242</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.744811</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.744200</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.749695</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.752137</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.751526</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.745421</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.781441</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.776557</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.765568</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.774115</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.788767</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.775336</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.786325</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.785104</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.772894</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model_name  k  keyword_num  success_rate  run_id\n",
       "0   Cerebras-GPT-6.7B  3            2      0.757021       0\n",
       "1   Cerebras-GPT-6.7B  3            2      0.758242       1\n",
       "2   Cerebras-GPT-6.7B  3            2      0.755189       2\n",
       "3   Cerebras-GPT-6.7B  3            2      0.700000       3\n",
       "4   Cerebras-GPT-6.7B  1            3      0.737892       0\n",
       "5   Cerebras-GPT-6.7B  1            3      0.724054       1\n",
       "6   Cerebras-GPT-6.7B  1            3      0.735450       2\n",
       "7   Cerebras-GPT-6.7B  1            3      0.738706       3\n",
       "8   Cerebras-GPT-6.7B  1            3      0.734229       4\n",
       "9   Cerebras-GPT-6.7B  2            3      0.729752       0\n",
       "10  Cerebras-GPT-6.7B  2            3      0.741962       1\n",
       "11  Cerebras-GPT-6.7B  2            3      0.728531       2\n",
       "12  Cerebras-GPT-6.7B  2            3      0.716728       3\n",
       "13  Cerebras-GPT-6.7B  2            3      0.720391       4\n",
       "14  Cerebras-GPT-6.7B  3            1      0.791209       0\n",
       "15  Cerebras-GPT-6.7B  3            1      0.781441       1\n",
       "16  Cerebras-GPT-6.7B  3            1      0.791209       2\n",
       "17  Cerebras-GPT-6.7B  3            1      1.000000       3\n",
       "18  Cerebras-GPT-6.7B  2            2      0.755189       0\n",
       "19  Cerebras-GPT-6.7B  2            2      0.753358       1\n",
       "20  Cerebras-GPT-6.7B  2            2      0.758242       2\n",
       "21  Cerebras-GPT-6.7B  2            2      0.744811       3\n",
       "22  Cerebras-GPT-6.7B  2            2      0.744200       4\n",
       "23  Cerebras-GPT-6.7B  1            2      0.749695       0\n",
       "24  Cerebras-GPT-6.7B  1            2      0.752137       1\n",
       "25  Cerebras-GPT-6.7B  1            2      0.751526       2\n",
       "26  Cerebras-GPT-6.7B  1            2      0.761905       3\n",
       "27  Cerebras-GPT-6.7B  1            2      0.745421       4\n",
       "28  Cerebras-GPT-6.7B  1            1      0.781441       0\n",
       "29  Cerebras-GPT-6.7B  1            1      0.776557       1\n",
       "30  Cerebras-GPT-6.7B  1            1      0.765568       2\n",
       "31  Cerebras-GPT-6.7B  1            1      0.774115       3\n",
       "32  Cerebras-GPT-6.7B  1            1      0.788767       4\n",
       "33  Cerebras-GPT-6.7B  2            1      0.775336       0\n",
       "34  Cerebras-GPT-6.7B  2            1      0.786325       1\n",
       "35  Cerebras-GPT-6.7B  2            1      0.785104       2\n",
       "36  Cerebras-GPT-6.7B  2            1      0.772894       3\n",
       "37  Cerebras-GPT-6.7B  2            1      0.777778       4"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the success rate over runs\n",
    "df = []\n",
    "missing_keywords2counts = defaultdict(lambda: 0)\n",
    "included_keywords2counts = defaultdict(lambda: 0)\n",
    "\n",
    "summary_numerical_num = 0 \n",
    "response_numerical_num = 0\n",
    "\n",
    "for run_name, summaries in run2metric_table.items():\n",
    "    print('[info] parse experiment', run_name)\n",
    "\n",
    "    summaries['keyword_num'] = summaries['keyword_num'].fillna(0)\n",
    "    keyword_num = int(summaries['keyword_num'][0])\n",
    "    if keyword_num <= 0 or 'keywords' not in run_name:\n",
    "        continue  \n",
    "    if 'nameReplace' in run_name or 'length' in run_name or 'replaceName' in run_name or 'randomLabel' in run_name or 'focus' in run_name:\n",
    "        continue \n",
    "\n",
    "    model_name = summaries['model_name'][0]\n",
    "    k = summaries['k'][0]\n",
    "\n",
    "    for run_id, df_ in summaries.groupby('run_id'):\n",
    "        print('[info] parse run', run_id)\n",
    "        keywords_num_total = 0\n",
    "        included_keywords_num = 0\n",
    "\n",
    "        # iterate over the run\n",
    "        for _, row in df_.iterrows():\n",
    "            is_contains_numeric_gold = any(char.isdigit() for char in row['gold_summary'])\n",
    "            summary_numerical_num += is_contains_numeric_gold\n",
    "            is_contains_numeric_pred = any(char.isdigit() for char in row['pred_summary'])\n",
    "            response_numerical_num += is_contains_numeric_pred\n",
    "            \n",
    "            last_line = row['prompt'].split('\\n')[-1]\n",
    "            # parse the keywords\n",
    "            try:\n",
    "                start_i, end_i = re.search('\\[.+\\]', last_line).span()\n",
    "                keywords = [x.strip()[1:-1] for x in last_line[start_i+1:end_i-1].split(',')]\n",
    "            except AttributeError:  # mt5 keywords are in different format\n",
    "                print('[debug] last_line = {}'.format(last_line))\n",
    "                last_line = re.sub(r'<extra_id_\\d+>', '',last_line)\n",
    "                last_line = last_line.split('Summary: ', maxsplit=1)[-1]\n",
    "                keywords = [x for x in last_line.split(' ') if len(x.strip()) >= 1]\n",
    "                if len(keywords) != keyword_num:\n",
    "                    print('[debug] skip')\n",
    "                    continue \n",
    "            # stem words\n",
    "            keywords = stem_sentence(keywords)\n",
    "            gold_summary = stem_sentence(row['pred_summary'])  # fixme: wrong name \n",
    "            # check if keywords are included\n",
    "            keywords_num_total += len(keywords)\n",
    "            for keyword in keywords:\n",
    "                if keyword in gold_summary:\n",
    "                    included_keywords_num += 1\n",
    "                    included_keywords2counts[keyword] += 1\n",
    "                else:\n",
    "                    # print('[miss keywords] {} in sentence: {}'.format(keyword, gold_summary))\n",
    "                    missing_keywords2counts[keyword] += 1\n",
    "\n",
    "        # calculate the success rate\n",
    "        success_rate = included_keywords_num / keywords_num_total\n",
    "        # print('[{}] success_rate = {}/{} = {}'.format(run_name, included_keywords_num, keywords_num_total, success_rate))\n",
    "        df.append({\n",
    "                'model_name': model_name,\n",
    "                'k': k,\n",
    "                'keyword_num': keyword_num,\n",
    "                'success_rate': success_rate,\n",
    "                'run_id': run_id\n",
    "                })\n",
    "\n",
    "print('{} summaries with numerical information and {} responses contain numerical information'.format(summary_numerical_num, response_numerical_num))\n",
    "df = pd.DataFrame(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2923 / 7881 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the ones with numeric values \n",
    "for word, counts in missing_keywords2counts.items():\n",
    "    is_contains_numeric = any(char.isdigit() for char in word)\n",
    "    if is_contains_numeric:\n",
    "        print('Missing {}, counts = {}'.format(word, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the ones with numeric values \n",
    "for word, counts in included_keywords2counts.items():\n",
    "    is_contains_numeric = any(char.isdigit() for char in word)\n",
    "    if is_contains_numeric:\n",
    "        print('Including {}, counts = {}'.format(word, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = sb.color_palette(\"ch:s=.25,rot=-.25\", as_cmap=False)\n",
    "\n",
    "plot = sb.lineplot(data=df, x='k', y='success_rate', hue='keyword_num', style='model_name', palette=palette)\n",
    "\n",
    "plot.set_xticks([1, 2, 3]) # <--- set the ticks first\n",
    "plot.set_xticklabels(['1', '2', '3'])\n",
    "\n",
    "plt.savefig('success_rate.jpg', dpi=500, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>keyword_num</th>\n",
       "      <th>success_rate</th>\n",
       "      <th>run_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cerebras-GPT-6.7B</th>\n",
       "      <td>1.815789</td>\n",
       "      <td>1.894737</td>\n",
       "      <td>0.761641</td>\n",
       "      <td>1.894737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          k  keyword_num  success_rate    run_id\n",
       "model_name                                                      \n",
       "Cerebras-GPT-6.7B  1.815789     1.894737      0.761641  1.894737"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['model_name']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>keyword_num</th>\n",
       "      <th>success_rate</th>\n",
       "      <th>run_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cerebras-GPT-6.7B</th>\n",
       "      <td>0.76601</td>\n",
       "      <td>0.798291</td>\n",
       "      <td>0.045782</td>\n",
       "      <td>1.390887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         k  keyword_num  success_rate    run_id\n",
       "model_name                                                     \n",
       "Cerebras-GPT-6.7B  0.76601     0.798291      0.045782  1.390887"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['model_name']).std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze the numerical keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the test dataset\n",
    "test_dataset = load_dataset('samsum', split='test')\n",
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the summaries with numerical information \n",
    "summaries_numerical = []\n",
    "for summary in test_dataset['summary']:\n",
    "    is_contains_numeric = any(char.isdigit() for char in summary)\n",
    "    if is_contains_numeric:\n",
    "        summaries_numerical.append(summary)\n",
    "\n",
    "print('{} summaries ({}%) with numerical chars'.format(len(summaries_numerical), len(summaries_numerical)/len(test_dataset) * 100))\n",
    "summaries_numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of summaries with numerical values\n",
    "df = []\n",
    "\n",
    "summary_numerical_num = 0 \n",
    "response_numerical_num = 0\n",
    "\n",
    "summary_examples = []\n",
    "response_examples = [] \n",
    "\n",
    "for run_name, summaries in run2metric_table.items():\n",
    "    if 'nameReplace' in run_name or 'length' in run_name or 'replaceName' in run_name \\\n",
    "        or 'randomLabel' in run_name or 'focus' in run_name or 'instructions' in run_name or 'keywords' in run_name:\n",
    "        continue\n",
    "    \n",
    "    print('[info] parse experiment', run_name)\n",
    "\n",
    "    summaries['keyword_num'] = summaries['keyword_num'].fillna(0)\n",
    "    keyword_num = int(summaries['keyword_num'][0])\n",
    "#     if keyword_num <= 0:\n",
    "#         continue  \n",
    "\n",
    "    model_name = summaries['model_name'][0]\n",
    "    k = summaries['k'][0]\n",
    "\n",
    "    for run_id, df_ in summaries.groupby('run_id'):\n",
    "        print('[info] parse run', run_id)\n",
    "        keywords_num_total = 0\n",
    "        included_keywords_num = 0\n",
    "\n",
    "        # iterate over the run\n",
    "        for _, row in df_.iterrows():\n",
    "            is_contains_numeric_gold = any(char.isdigit() for char in row['gold_summary'])\n",
    "            summary_numerical_num += is_contains_numeric_gold\n",
    "            is_contains_numeric_pred = any(char.isdigit() for char in row['pred_summary'])\n",
    "            response_numerical_num += is_contains_numeric_pred\n",
    "            if is_contains_numeric_gold and is_contains_numeric_pred:\n",
    "                summary_examples.append(row['gold_summary'])\n",
    "                response_examples.append(row['pred_summary'])\n",
    "\n",
    "print('{} summaries with numerical information and {} responses contain numerical information ({}%)'.format(summary_numerical_num, response_numerical_num, \n",
    "                                                                                                           response_numerical_num / summary_numerical_num * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_examples[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_examples[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deviation from expected length "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over completed runs to get summaries table\n",
    "MODEL_FAMILY = ['google/mt5-xl']\n",
    "\n",
    "run2metric_table = {}\n",
    "for run in tqdm(runs):\n",
    "    if 'complete' not in run.tags or run.config['model_type'] not in MODEL_FAMILY or run.job_type != 'evaluation':\n",
    "        continue\n",
    "    if 'nameReplace' in run.name:\n",
    "        continue \n",
    "        \n",
    "    print('parsing run {}'.format(run.name))\n",
    "    files = run.files()\n",
    "    metric_file = [file for file in files if 'Summaries Table' in getattr(file, 'name', '')]\n",
    "    assert len(metric_file) >= 1\n",
    "    metric_file = metric_file[0]\n",
    "    f = metric_file.download(root='wandb', replace=True)\n",
    "    metrics = json.load(f)\n",
    "    metrics = json.dumps(metrics)\n",
    "    metric_table = pd.read_json(StringIO(metrics), orient='split')\n",
    "    # get k shot\n",
    "    match = re.search(r'\\d-shot', run.name)\n",
    "    start_i, end_i = match.span()\n",
    "    k = int(run.name[start_i: end_i].split('-')[0])\n",
    "\n",
    "    metric_table['k'] = k\n",
    "    model_name = run.name[: start_i - 1]\n",
    "    metric_table['model_name'] = model_name\n",
    "    if 'keyword' in run.name:\n",
    "        end_id = run.name.find('-keyword')\n",
    "        keyword_num = run.name[end_id - 1:end_id]\n",
    "        metric_table['keyword_num'] = keyword_num\n",
    "        print('[debug] find keyword_num = {} in {}'.format(keyword_num, run.name))\n",
    "    else:\n",
    "        metric_table['keyword_num'] = None\n",
    "\n",
    "    run2metric_table[run.name] = metric_table\n",
    "run2metric_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ks: uncontrolled keys \n",
    "# ks = [x for x in run2metric_table.keys() if ('length' not in x and 'keyword' not in x and 'replaceName' not in x)]\n",
    "# ks: controlled setting \n",
    "ks = [x for x in run2metric_table.keys() if ('length' in x)]\n",
    "\n",
    "\n",
    "length_df = []\n",
    "for k in ks:\n",
    "    print('[debug] processing {}'.format(k))\n",
    "    run_df = run2metric_table[k]\n",
    "    lengths = []\n",
    "    \n",
    "    for _, row in run_df.iterrows():\n",
    "        words = [word.lower() for word in nltk.word_tokenize(row['gold_summary']) if word not in string.punctuation]\n",
    "        control_length = len(words)\n",
    "        \n",
    "        words = [word.lower() for word in nltk.word_tokenize(row['pred_summary']) if word not in string.punctuation]\n",
    "        actual_length = len(words)\n",
    "            \n",
    "        row['length_error'] = abs(control_length - actual_length)\n",
    "        row['run_name'] = k\n",
    "        \n",
    "        length_df.append(row)\n",
    "length_df = pd.DataFrame(length_df)\n",
    "length_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_df.groupby('k').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_df['length_error'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_df['length_error'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over completed runs to get perplexity\n",
    "run2perplexity = {}\n",
    "\n",
    "for run in tqdm(runs):\n",
    "    if 'complete' not in run.tags or getattr(run, 'job_type', '') != 'perplexity_evaluation':\n",
    "        continue\n",
    "    else:\n",
    "        print('parsing run {}'.format(run.name))\n",
    "        \n",
    "    files = run.files()\n",
    "    metric_file = [file for file in files if 'Perplexity Table' in getattr(file, 'name', '')]\n",
    "    assert len(metric_file) == 1\n",
    "\n",
    "    metric_file = metric_file[0]\n",
    "    f = metric_file.download(root='wandb', replace=True)\n",
    "    metrics = json.load(f)\n",
    "    metrics = json.dumps(metrics)\n",
    "    metric_table = pd.read_json(StringIO(metrics), orient='split')\n",
    "    # get k shot\n",
    "    try:\n",
    "        match = re.search(r'\\d-shot', run.name)\n",
    "        start_i, end_i = match.span()\n",
    "        k = int(run.name[start_i: end_i].split('-')[0])\n",
    "    except AttributeError:\n",
    "        print('[debug] skip {}'.format(run.name))\n",
    "        continue\n",
    "    metric_table['k'] = k\n",
    "    model_name = run.name[: start_i - 1]\n",
    "    if run.name == 'Cerebras-6.7B-3-shot':\n",
    "        metric_table['model_name'] = 'Cerebras-GPT-6.7B'\n",
    "    else:\n",
    "        metric_table['model_name'] = model_name\n",
    "    if 'keyword' in run.name:\n",
    "        end_id = run.name.find('-keyword')\n",
    "        keyword_num = run.name[end_id - 1:end_id]\n",
    "        metric_table['keyword_num'] = keyword_num\n",
    "        print('[debug] find keyword_num = {} in {}'.format(keyword_num, run.name))\n",
    "    else:\n",
    "        metric_table['keyword_num'] = None\n",
    "\n",
    "    run2perplexity[run.name] = metric_table\n",
    "run2perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run2perplexity = {k: v for k, v in run2perplexity.items() if 'llama-7b-hf' in k}\n",
    "run2perplexity.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexity_df = pd.concat(run2perplexity.values(), axis=0, ignore_index=True)\n",
    "perplexity_df['perplexity'] = pd.to_numeric(perplexity_df['perplexity'])\n",
    "print('{} infinite values found'.format(sum(perplexity_df['perplexity'].isin([np.inf]))))\n",
    "perplexity_df = perplexity_df[~perplexity_df['perplexity'].isin([np.inf])]\n",
    "perplexity_df = perplexity_df.fillna(0)\n",
    "perplexity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = sb.lineplot(data=perplexity_df, x='k', y='perplexity', hue='keyword_num', markers=True, palette=palette)\n",
    "plot.set_xticks([1, 2, 3]) # <--- set the ticks first\n",
    "plot.set_xticklabels(['1', '2', '3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the result of MODEL_NAME family\n",
    "MODEL_NAME = 'llama-7b-hf'\n",
    "\n",
    "if MODEL_NAME == 'mt5-xl':\n",
    "    new_keys = [x for x in run2metric_table.keys() if MODEL_NAME in x and 'mt5-xxl' not in x]\n",
    "else:\n",
    "    new_keys = [x for x in run2metric_table.keys() if MODEL_NAME in x]\n",
    "print('[debug] new_keys =', sorted(new_keys))\n",
    "dfs = [run2metric_table[k] for k in new_keys]\n",
    "rouge_table = pd.concat(dfs, axis=0)\n",
    "model_name = MODEL_NAME\n",
    "rouge_table['k'] = rouge_table['k'].astype(int)\n",
    "rouge_table['keyword_num'] = rouge_table['keyword_num'].fillna(0)\n",
    "rouge_table['keyword_num'] = rouge_table['keyword_num'].astype(int)\n",
    "rouge_table = rouge_table[~rouge_table.isna().any(axis=1)]\n",
    "\n",
    "rouge_table = rouge_table[(rouge_table['k'] <= 3)]\n",
    "# rouge_table = rouge_table[~rouge_table['model_name'].str.contains('Cerebras-GPT-6.7B')]\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "palette = sb.color_palette(\"ch:s=.25,rot=-.25\", as_cmap=False)\n",
    "\n",
    "plot = sb.lineplot(data=rouge_table, x='k', y='rouge_1_fmeasure', hue='keyword_num', ax=axes[0], markers=True, palette=palette)\n",
    "plot.set_xticks([1, 2, 3]) # <--- set the ticks first\n",
    "plot.set_xticklabels(['1', '2', '3'])\n",
    "axes[0].yaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\n",
    "plot = sb.lineplot(data=rouge_table, x='k', y='rouge_2_fmeasure', hue='keyword_num', ax=axes[1], markers=True, palette=palette)\n",
    "plot.set_xticks([1, 2, 3]) # <--- set the ticks first\n",
    "plot.set_xticklabels(['1', '2', '3'])\n",
    "axes[1].yaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\n",
    "plot = sb.lineplot(data=rouge_table, x='k', y='rouge_L_fmeasure', hue='keyword_num', ax=axes[2], markers=True, palette=palette)\n",
    "plot.set_xticks([1, 2, 3]) # <--- set the ticks first\n",
    "plot.set_xticklabels(['1', '2', '3'])\n",
    "axes[2].yaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\n",
    "plot = sb.lineplot(data=perplexity_df, x='k', y='perplexity', hue='keyword_num', markers=True, palette=palette, ax=axes[3])\n",
    "plot.set_xticks([1, 2, 3]) # <--- set the ticks first\n",
    "plot.set_xticklabels(['1', '2', '3'])\n",
    "axes[0].get_legend().remove()\n",
    "axes[1].get_legend().remove()\n",
    "axes[2].get_legend().remove()\n",
    "axes[3].get_legend().remove()\n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='upper right', ncol=5, bbox_to_anchor=(.8, 1), title='Keyword number')\n",
    "fig.suptitle(MODEL_NAME, fontweight='bold')\n",
    "#\n",
    "plt.savefig('{}_entity_control.jpg'.format(MODEL_NAME), dpi=500, bbox_inches='tight')\n",
    "\n",
    "rouge_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [run2metric_table[k] for k in new_keys]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
