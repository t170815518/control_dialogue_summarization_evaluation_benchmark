{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/2ophe8fc (failed)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/uz2zv3ql (crashed)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/0zg6isnj (failed)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/wcfyq5vs (failed)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/2sl5oj01 (failed)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/t0b7m73y (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/5z96ixcl (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/sjeme75o (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/3os9i1pg (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/rb34pon4 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/s8xdadif (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/ha4kwyw9 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/0698hhn8 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/4ge61rql (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/jsafs9l4 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/6cihgtbz (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/1o828ee1 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/2ftmw2vw (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/jf4dvu0y (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/oaxdkr4v (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/u3qlrxoc (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/649t44ml (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/d6y58dsj (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/88vd2bz2 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/ovgk7vgr (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/3ilef6jx (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/evx9kfzw (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/ol5o3fxg (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/bl5sfk5f (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/vpe35sj9 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/utnt6cag (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/svslkf9g (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/0juanra1 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/muynmp84 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/854g5pde (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/7of9xh05 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/24drf1d0 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/wyba581r (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/znfph1r8 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/7g29utle (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/sztpd82u (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/obg7g54g (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/avbkuk6f (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/wyy1ypxj (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/5g5ap7y4 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/ruskmd5k (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/x84owtic (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/3424bv3i (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/3dh8hbgw (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/jha105b9 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/xit0y9ko (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/wrbutke3 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/mvap8e8p (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/h050ncsy (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/15j8bqqu (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/vz7helse (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/xbiscehj (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/xy5y79l3 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/ztdgfvh0 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/oiyncgnz (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/2u4pvv2b (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/kmjmrzm2 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/4g0w69e5 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/3rr3mpwc (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/mhkws0ws (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/0krumq5w (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/iz5p4fkp (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/2hnjykxj (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/lvxp673n (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/bkenusqx (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/304rxx2r (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/rbfun4ru (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/d8izv9mo (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/r9z90fgp (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/l8vp6otr (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/yq15wqe8 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/0snlm7yu (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/g1rw6cg5 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/91nc9qlw (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/zymnqlcv (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/he8ngdy7 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/rxb48uds (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/kbpu8xu5 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/boo7m1zo (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/34bolxl7 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/ylmun8jo (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/zz22chfq (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/2r77ocu3 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/mnk1tkqz (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/6othf7uv (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/239fzyoa (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/2dfbewz5 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/tn5sil4h (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/lg0et6xu (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/dwsses2i (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/1knxiq37 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/l5e6ntyg (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/30rcz136 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/veil5uy0 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/0czi5w8j (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/btvghd29 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/1iofcb0t (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/2910cokb (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/2axtridp (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/24mzrihk (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/3dnimr54 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/16jwdikp (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/bmrjmozu (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/3rk5sp7r (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/34cp8nbe (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/ly2tcr9q (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/21xjjwwx (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/3ec2mf5c (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/hl25a4ml (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/u93ps6pu (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/19ub5ymd (crashed)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/5rnmejah (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/xwmcj8xi (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/xvhd8rch (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/eyum2mgg (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/h4j3o2ic (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/hdsecxvz (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/eg3z6gcm (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/phcjkfkx (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/k2stjy1j (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/g779h6t8 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/2kjicxev (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/erl82y8d (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/2w9nfjfk (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/bmcjzt04 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/cq515fo5 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/v379qqee (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/g6kl7uoc (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/b98d1671 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/4mfmzz06 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/ek413nmt (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/18t5sqtw (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/5ojlwxi9 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/y56dsqg3 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/wrcx3bb5 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/ts7fz3ig (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/j31v56ns (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/sx8v8w6y (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/kag8fvfr (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/0yaa9iym (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/fdqf3s7y (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/y6s0sepq (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/1qbgf41z (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/sh5rkgzf (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/m29xasf5 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/73dki9cl (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/s4t742qq (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/4awo9398 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/bnq8zzhw (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/yb8klocm (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/jnf4dktw (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/myb6yz65 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/itofm9ru (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/34wldaup (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/1e78r4dj (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/h152em1z (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/p93unja0 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/43rtkrck (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/gjd302f3 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/18dz4thp (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/rlw5bmp3 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/jtar0ea8 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/wfpg1fas (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/spfmntpp (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/d8zgoxid (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/kt0rto57 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/gvqhvu33 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/r4qt2ub7 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/2wa596mz (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/4fh7kf5n (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/0ow32cvh (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/wldzoaed (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/2cmp1sul (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/krzk8azi (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/2irhadgh (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/t82njqf5 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/a786xjap (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/h7t0bk6v (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/h55ln9jt (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/t4bexsi0 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/zzas3zwl (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/rbjjedl6 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/3uwg069b (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/x45fnojw (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/6b8tiig1 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/itkmqiru (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/iic8pur0 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/l2levtbt (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/8tlb542e (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/yp3hruej (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/2ews1ew2 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/e51ukd8x (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/dy7nwhad (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/jcbr461r (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/eqmk7a5e (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/cfo0e1n4 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/vfmc9zvw (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/lhg3em51 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/p7r29dcv (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/25bhw0lb (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/omwjww2d (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/1gnbj09w (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/v1v0pt8n (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/0abwryrr (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/pebu1ixv (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/3ajvqy10 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/bs69r40n (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/gs46yeht (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/alluyeh0 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/saw12im1 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/fx58qa3h (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/92brs01k (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/n3zdd4fx (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/vef9j3m2 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/0hz6bx2d (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/f6jz1psl (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/7pbljwps (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/ty0k5mhk (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/semhvfwg (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/r22gxoee (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/voxye5mk (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/07j7dnrq (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/ajqcfx6c (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/8grd8dn7 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/h4nzd3iy (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/vj99uk7i (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/bbpzqr6d (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/0dzfyarb (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/a4a8juh0 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/yd2b5mwe (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/nfoxlyts (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/9f81dc4d (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/1jxbs6h6 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/yenib4d6 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/dlx53hus (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/rcawyzg2 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/tnq1ybep (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/brrdoiua (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/erq1rnpn (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/41ftb2fw (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/7w0x0s21 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/6iqmccle (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/xm2zfz63 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/2utxglip (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/fsnia1i1 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/b6vph1ju (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/3yngyl3v (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/et4u7fqr (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/tasmbm4o (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/cpjwef0u (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/6lp8ajcs (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/fr9wg8fd (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/99n81ikt (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/xm0bhp1e (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/vg8hsptk (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/xxhu3nxo (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/e17vj9et (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/umgst3jy (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/r575zw56 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/qms1n1nx (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/l25edc50 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/zyw5rqyt (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/pqkjl5vj (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/t67ta5ck (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/1qx4zcaa (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/3ixacef5 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/rhh8ktxz (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/6f4hus0m (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/rutyv207 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/lkl6nuj6 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/3g6v0jkk (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/8drm8nv6 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/5ia93aw0 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/s98u1h72 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/koykbkj4 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/fox718p1 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/kydhwov4 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/0f3qznic (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/dgec7yat (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/3ntwf200 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/wtnriu0x (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/3w9f97yx (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/vvbupie9 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/xlqffm4p (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/2guwlane (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/crppk1on (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/27bsgzwx (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/pcgqjg47 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/jvni6hkb (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/c9qvoiyv (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/3mmxn171 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/lx5ny0nq (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/pb8s8qgi (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/9hmxjg00 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/356smtrw (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/swgvqgmf (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/msmo8mvd (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/5vk2ph9n (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/dy584a6x (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/nf74ucv3 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/f6nlunyr (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/1nfcefjj (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/4e8hfbm7 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/9aqbes60 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/5shdc851 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/t94ufx0p (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/ve9ift4i (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/7cih2v47 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/ubo0c6sf (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/7l4jllyb (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/kriphwx8 (finished)>,\n",
       " <Run yuting_fyp/In-context-learning+for+Dialogue+Summarization/md52vsoa (finished)>]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. import packages and add global parameter settings\n",
    "# 2. fetch all the runs from wandb\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "from io import StringIO\n",
    "from tqdm.auto import tqdm\n",
    "import wandb\n",
    "import string\n",
    "import nltk\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "sb.set_theme(style=\"white\", palette=None)\n",
    "\n",
    "\n",
    "# connect to wandb and get list of runs\n",
    "api_helper = wandb.Api(api_key='3138e1b24deb278ed045d0dedb39511d3a96245b')\n",
    "runs = list(api_helper.runs(path='yuting_fyp/In-context-learning for Dialogue Summarization',\n",
    "                     per_page=1000))\n",
    "runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over completed runs to get ROUGE scores tables\n",
    "run2metric_table = {}\n",
    "for run in tqdm(runs):\n",
    "    if 'complete' not in run.tags or 'evaluation' != getattr(run, 'job_type', ''):\n",
    "        continue\n",
    "    else:\n",
    "        print('parsing run {}'.format(run.name))\n",
    "    # download the rouge table\n",
    "    files = run.files()\n",
    "    metric_file = [file for file in files if 'Evaluation metrics Table' in getattr(file, 'name', '')]\n",
    "    if len(metric_file) < 1:\n",
    "        print('[WARN] skip {} because len(metric_file) < 1'.format(metric_file))\n",
    "        continue\n",
    "    metric_file = metric_file[0]\n",
    "    f = metric_file.download(root='wandb', replace=True)\n",
    "    metrics = json.load(f)\n",
    "    metric_table = pd.read_json(json.dumps(metrics), orient='split')\n",
    "    # get k shot\n",
    "    try:\n",
    "        match = re.search(r'\\d-shot', run.name)\n",
    "        start_i, end_i = match.span()\n",
    "        k = int(run.name[start_i: end_i].split('-')[0])\n",
    "        metric_table['k'] = k\n",
    "    except AttributeError:\n",
    "        print('[debug] skip {}'.format(run.name))\n",
    "        continue \n",
    "    model_name = run.name[: start_i - 1]\n",
    "    if 'keyword' in run.name:\n",
    "        end_id = run.name.find('-keyword')\n",
    "        keyword_num = run.name[end_id - 1:end_id]\n",
    "        metric_table['keyword_num'] = keyword_num\n",
    "        print('[debug] find keyword_num = {} in {}'.format(keyword_num, run.name))\n",
    "    else:\n",
    "        metric_table['keyword_num'] = None\n",
    "\n",
    "    run2metric_table[run.name] = metric_table\n",
    "run2metric_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Direct prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the result of direct prompt\n",
    "new_keys = [x for x in run2metric_table.keys() if ('keyword' not in x and 'nameReplace' not in x and 'length' \n",
    "                                                   not in x and 'replaceName' not in x and 'instructions' not in x and \n",
    "                                                  'focus' not in x and 'randomLabel' not in x)]\n",
    "# new_keys = [x for x in run2metric_table.keys() if ('keyword' not in x and 'nameReplace' not in x and 'length' not\n",
    "#                                                     in x and 'replaceName' not in x and 'instructions' not in x and 'focus' in x)]\n",
    "\n",
    "dfs = [run2metric_table[k] for k in new_keys]\n",
    "rouge_table = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "rouge_table['k'] = rouge_table['k'].astype(int)\n",
    "rouge_table['keyword_num'] = rouge_table['keyword_num'].fillna(0)\n",
    "rouge_table = rouge_table[(rouge_table['k'] <= 3) & ~rouge_table.isna().any(axis=1)]\n",
    "rouge_table = rouge_table[~rouge_table['model_name'].str.contains('Cerebras-GPT-6.7B') & ~rouge_table['model_name'].str.contains('flan-t5-xl')]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "plot = sb.lineplot(data=rouge_table, x='k', y='rouge_1_fmeasure', hue='model_name', ax=axes[0], markers=True)\n",
    "plot.set_xticks([1, 2, 3]) # <--- set the ticks first\n",
    "plot.set_xticklabels(['1', '2', '3'])\n",
    "axes[0].get_legend().remove()\n",
    "axes[0].yaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\n",
    "plot = sb.lineplot(data=rouge_table, x='k', y='rouge_2_fmeasure', hue='model_name', ax=axes[1], markers=True)\n",
    "plot.set_xticks([1, 2, 3]) # <--- set the ticks first\n",
    "plot.set_xticklabels(['1', '2', '3'])\n",
    "axes[1].get_legend().remove()\n",
    "axes[1].yaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\n",
    "\n",
    "plot = sb.lineplot(data=rouge_table, x='k', y='rouge_L_fmeasure', hue='model_name', ax=axes[2], markers=True)\n",
    "plot.set_xticks([1, 2, 3]) # <--- set the ticks first\n",
    "plot.set_xticklabels(['1', '2', '3'])\n",
    "axes[2].get_legend().remove()\n",
    "axes[2].yaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\n",
    "\n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='right', ncol=3, bbox_to_anchor=(.75, 0.98))\n",
    "\n",
    "plt.savefig('direct_prompt.jpg', dpi=500, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_table.groupby(['model_name', 'k']).mean().to_csv('mean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_table.groupby(['model_name', 'k']).std().to_csv('std.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_table.groupby(['model_name', 'k']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_table.groupby(['model_name', 'k']).std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot results under controlled setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the result of MODEL_NAME family\n",
    "MODEL_NAME = 'mt5-xl'\n",
    "\n",
    "if MODEL_NAME == 'mt5-xl':\n",
    "    new_keys = [x for x in run2metric_table.keys() if MODEL_NAME in x and 'mt5-xxl' not in x]\n",
    "else:\n",
    "#     new_keys = [x for x in run2metric_table.keys() if MODEL_NAME in x and 'nameReplace' not in x and 'length' not in x and 'replaceName' not in x]\n",
    "#     new_keys = [x for x in run2metric_table.keys() if MODEL_NAME in x and 'nameReplace' not in x and 'length' in x and 'replaceName' not in x]\n",
    "    new_keys = [x for x in run2metric_table.keys() if MODEL_NAME in x and 'nameReplace' not in x and 'focus' in x and 'replaceName' not in x]\n",
    "\n",
    "print('[debug] new_keys =', sorted(new_keys))\n",
    "dfs = [run2metric_table[k] for k in new_keys]\n",
    "rouge_table = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "rouge_table['k'] = rouge_table['k'].astype(int)\n",
    "rouge_table['keyword_num'] = rouge_table['keyword_num'].fillna(0)\n",
    "rouge_table['keyword_num'] = rouge_table['keyword_num'].astype(int)\n",
    "rouge_table = rouge_table[~rouge_table.isna().any(axis=1)]\n",
    "\n",
    "rouge_table = rouge_table[(rouge_table['k'] <= 3)]\n",
    "# rouge_table = rouge_table[~rouge_table['model_name'].str.contains('Cerebras-GPT-6.7B')]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "palette = sb.color_palette(\"ch:s=.25,rot=-.25\", as_cmap=False)\n",
    "\n",
    "plot = sb.lineplot(data=rouge_table, x='k', y='rouge_1_fmeasure', hue='keyword_num', ax=axes[0], markers=True, palette=palette)\n",
    "plot.set_xticks([1, 2, 3]) # <--- set the ticks first\n",
    "plot.set_xticklabels(['1', '2', '3'])\n",
    "axes[0].yaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\n",
    "plot = sb.lineplot(data=rouge_table, x='k', y='rouge_2_fmeasure', hue='keyword_num', ax=axes[1], markers=True, palette=palette)\n",
    "plot.set_xticks([1, 2, 3]) # <--- set the ticks first\n",
    "plot.set_xticklabels(['1', '2', '3'])\n",
    "axes[1].yaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\n",
    "plot = sb.lineplot(data=rouge_table, x='k', y='rouge_L_fmeasure', hue='keyword_num', ax=axes[2], markers=True, palette=palette)\n",
    "plot.set_xticks([1, 2, 3]) # <--- set the ticks first\n",
    "plot.set_xticklabels(['1', '2', '3'])\n",
    "axes[2].yaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\n",
    "axes[0].get_legend().remove()\n",
    "axes[1].get_legend().remove()\n",
    "axes[2].get_legend().remove()\n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='upper right', ncol=5, bbox_to_anchor=(.8, 1), title='Keyword number')\n",
    "fig.suptitle(MODEL_NAME, fontweight='bold')\n",
    "#\n",
    "plt.savefig('{}_entity_control.jpg'.format(MODEL_NAME), dpi=500, bbox_inches='tight')\n",
    "\n",
    "rouge_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_df = rouge_table.groupby('k').mean() * 100\n",
    "mean_df[[x for x in mean_df.columns if 'fmeasure' in x]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_df = rouge_table.groupby('k').std() * 100\n",
    "std_df[[x for x in std_df.columns if 'fmeasure' in x]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in run2metric_table.keys() if 'Cerebras-GPT-6.7B' in x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Success Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "575fb31bbb87466c8fd3a6cef26309e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/317 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsing run opt-1.3b-2-shot-3-keywords\n",
      "['artifact/477130634/wandb_manifest.json', 'artifact/477130654/wandb_manifest.json', 'config.yaml', 'media/table/Evaluation metrics Table_0_a179d933c87fcf0fb04e.table.json', 'media/table/Summaries Table_1_eadcc4375741818a2273.table.json', 'output.log', 'requirements.txt', 'wandb-metadata.json', 'wandb-summary.json']\n",
      "[debug] find keyword_num = 3 in opt-1.3b-2-shot-3-keywords\n",
      "parsing run opt-1.3b-2-shot-1-keywords\n",
      "['artifact/477129919/wandb_manifest.json', 'artifact/477129941/wandb_manifest.json', 'config.yaml', 'media/table/Evaluation metrics Table_0_fe1d14aafd7ef327051f.table.json', 'media/table/Summaries Table_1_988c6721190ef73ef5ca.table.json', 'output.log', 'requirements.txt', 'wandb-metadata.json', 'wandb-summary.json']\n",
      "[debug] find keyword_num = 1 in opt-1.3b-2-shot-1-keywords\n",
      "parsing run opt-1.3b-2-shot-2-keywords\n",
      "['artifact/477128728/wandb_manifest.json', 'artifact/477128747/wandb_manifest.json', 'config.yaml', 'media/table/Evaluation metrics Table_0_fdf6cabb581bd5fef9b8.table.json', 'media/table/Summaries Table_1_8ffd19e831750756762a.table.json', 'output.log', 'requirements.txt', 'wandb-metadata.json', 'wandb-summary.json']\n",
      "[debug] find keyword_num = 2 in opt-1.3b-2-shot-2-keywords\n",
      "parsing run opt-1.3b-1-shot-3-keywords\n",
      "['artifact/477087144/wandb_manifest.json', 'artifact/477087178/wandb_manifest.json', 'config.yaml', 'media/table/Evaluation metrics Table_0_60be446a7625f1174083.table.json', 'media/table/Summaries Table_1_f3e224f5e2b00417baa0.table.json', 'output.log', 'requirements.txt', 'wandb-metadata.json', 'wandb-summary.json']\n",
      "[debug] find keyword_num = 3 in opt-1.3b-1-shot-3-keywords\n",
      "parsing run opt-1.3b-1-shot-2-keywords\n",
      "['artifact/477082663/wandb_manifest.json', 'artifact/477082700/wandb_manifest.json', 'config.yaml', 'media/table/Evaluation metrics Table_0_8aa3dbfc9cd4063d3728.table.json', 'media/table/Summaries Table_1_19d9707f404c2bbb90ff.table.json', 'output.log', 'requirements.txt', 'wandb-metadata.json', 'wandb-summary.json']\n",
      "[debug] find keyword_num = 2 in opt-1.3b-1-shot-2-keywords\n",
      "parsing run opt-1.3b-1-shot-1-keywords\n",
      "['artifact/477082308/wandb_manifest.json', 'artifact/477082334/wandb_manifest.json', 'config.yaml', 'media/table/Evaluation metrics Table_0_78a8982bbf963f0b6d85.table.json', 'media/table/Summaries Table_1_d1dafe13d0dfffb151a9.table.json', 'output.log', 'requirements.txt', 'wandb-metadata.json', 'wandb-summary.json']\n",
      "[debug] find keyword_num = 1 in opt-1.3b-1-shot-1-keywords\n",
      "parsing run opt-1.3b-3-shot\n",
      "['artifact/476634668/wandb_manifest.json', 'artifact/476634722/wandb_manifest.json', 'config.yaml', 'media/table/Evaluation metrics Table_0_18946ee5cb7139bdfb33.table.json', 'media/table/Summaries Table_1_f4e21ecdae0042495f04.table.json', 'output.log', 'requirements.txt', 'wandb-metadata.json', 'wandb-summary.json']\n",
      "parsing run opt-1.3b-2-shot\n",
      "['artifact/476649106/wandb_manifest.json', 'artifact/476649147/wandb_manifest.json', 'config.yaml', 'media/table/Evaluation metrics Table_0_be5e6fc1028351aa108a.table.json', 'media/table/Summaries Table_1_5c4632e8beeb607b6b2c.table.json', 'output.log', 'requirements.txt', 'wandb-metadata.json', 'wandb-summary.json']\n",
      "parsing run opt-1.3b-1-shot\n",
      "['artifact/476644509/wandb_manifest.json', 'artifact/476644546/wandb_manifest.json', 'config.yaml', 'media/table/Evaluation metrics Table_0_cc805085220002368ea3.table.json', 'media/table/Summaries Table_1_63dbcb3ba639b9ce99b5.table.json', 'output.log', 'requirements.txt', 'wandb-metadata.json', 'wandb-summary.json']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'opt-1.3b-2-shot-3-keywords':       run_id                                             prompt  \\\n",
       " 0          0  Summarize the conversation with keywords:\\nJoh...   \n",
       " 1          0  Summarize the conversation with keywords:\\nLis...   \n",
       " 2          0  Summarize the conversation with keywords:\\nLar...   \n",
       " 3          0  Summarize the conversation with keywords:\\nLol...   \n",
       " 4          0  Summarize the conversation with keywords:\\nRob...   \n",
       " ...      ...                                                ...   \n",
       " 4090       4  Summarize the conversation with keywords:\\nCar...   \n",
       " 4091       4  Summarize the conversation with keywords:\\nNic...   \n",
       " 4092       4  Summarize the conversation with keywords:\\nJac...   \n",
       " 4093       4  Summarize the conversation with keywords:\\nIan...   \n",
       " 4094       4  Summarize the conversation with keywords:\\nCla...   \n",
       " \n",
       "                                            pred_summary  \\\n",
       " 0     Hannah and Amanda are talking about Betty. Han...   \n",
       " 1     Eric is a stand up comedian. He has a youtube ...   \n",
       " 2            Lenny and Bob pick the same pair of pants.   \n",
       " 3     Emma and Will are going to have dinner togethe...   \n",
       " 4     Jane is on her way to lunch with her friends. ...   \n",
       " ...                                                 ...   \n",
       " 4090  ~~Alex and Benjamin are excited about the upco...   \n",
       " 4091  Jamilla and Kiki will go to the auditions for ...   \n",
       " 4092  ~~~ Marta has accidentally sent a file from he...   \n",
       " 4093  Cora and Ellie were surprised by the number of...   \n",
       " 4094  Rachel watches the top 50 best films of the ye...   \n",
       " \n",
       "                                            gold_summary  k model_name  \\\n",
       " 0     Hannah needs Betty's number but Amanda doesn't...  2   opt-1.3b   \n",
       " 1     Eric and Rob are going to watch a stand-up on ...  2   opt-1.3b   \n",
       " 2     Lenny can't decide which trousers to buy. Bob ...  2   opt-1.3b   \n",
       " 3     Emma will be home soon and she will let Will k...  2   opt-1.3b   \n",
       " 4     Jane is in Warsaw. Ollie and Jane has a party....  2   opt-1.3b   \n",
       " ...                                                 ... ..        ...   \n",
       " 4090  Benjamin didn't come to see a basketball game ...  2   opt-1.3b   \n",
       " 4091      The audition starts at 7.30 P.M. in Antena 3.  2   opt-1.3b   \n",
       " 4092                    Marta sent a file accidentally,  2   opt-1.3b   \n",
       " 4093  There was a meet-and-greet with James Charles ...  2   opt-1.3b   \n",
       " 4094  Rachel sends a list of Top 50 films of 2018. J...  2   opt-1.3b   \n",
       " \n",
       "      keyword_num  \n",
       " 0              3  \n",
       " 1              3  \n",
       " 2              3  \n",
       " 3              3  \n",
       " 4              3  \n",
       " ...          ...  \n",
       " 4090           3  \n",
       " 4091           3  \n",
       " 4092           3  \n",
       " 4093           3  \n",
       " 4094           3  \n",
       " \n",
       " [4095 rows x 7 columns],\n",
       " 'opt-1.3b-2-shot-1-keywords':       run_id                                             prompt  \\\n",
       " 0          0  Summarize the conversation with keywords:\\nJoh...   \n",
       " 1          0  Summarize the conversation with keywords:\\nLis...   \n",
       " 2          0  Summarize the conversation with keywords:\\nLar...   \n",
       " 3          0  Summarize the conversation with keywords:\\nLol...   \n",
       " 4          0  Summarize the conversation with keywords:\\nRob...   \n",
       " ...      ...                                                ...   \n",
       " 4090       4  Summarize the conversation with keywords:\\nCar...   \n",
       " 4091       4  Summarize the conversation with keywords:\\nNic...   \n",
       " 4092       4  Summarize the conversation with keywords:\\nJac...   \n",
       " 4093       4  Summarize the conversation with keywords:\\nIan...   \n",
       " 4094       4  Summarize the conversation with keywords:\\nCla...   \n",
       " \n",
       "                                            pred_summary  \\\n",
       " 0     Hannah and Amanda are texting each other. Aman...   \n",
       " 1                \n",
       " 2     Lenny asks Bob if he wants to buy a new pair o...   \n",
       " 3     Emma is having a bad day at work and Will is t...   \n",
       " 4     Jane is on her way back to Warsaw from Morocco...   \n",
       " ...                                                 ...   \n",
       " 4090  ~~Alex~~ Benjamin and Alex went to Friday's ga...   \n",
       " 4091  Jamilla and Kiki will go to the auditions for ...   \n",
       " 4092  ~~~ Marta has an accident and accidentally sen...   \n",
       " 4093  Cora and Ellie were surprised by the amount of...   \n",
       " 4094  ~~~ Rachel and Janice watch the top 50 best fi...   \n",
       " \n",
       "                                            gold_summary  k model_name  \\\n",
       " 0     Hannah needs Betty's number but Amanda doesn't...  2   opt-1.3b   \n",
       " 1     Eric and Rob are going to watch a stand-up on ...  2   opt-1.3b   \n",
       " 2     Lenny can't decide which trousers to buy. Bob ...  2   opt-1.3b   \n",
       " 3     Emma will be home soon and she will let Will k...  2   opt-1.3b   \n",
       " 4     Jane is in Warsaw. Ollie and Jane has a party....  2   opt-1.3b   \n",
       " ...                                                 ... ..        ...   \n",
       " 4090  Benjamin didn't come to see a basketball game ...  2   opt-1.3b   \n",
       " 4091      The audition starts at 7.30 P.M. in Antena 3.  2   opt-1.3b   \n",
       " 4092                    Marta sent a file accidentally,  2   opt-1.3b   \n",
       " 4093  There was a meet-and-greet with James Charles ...  2   opt-1.3b   \n",
       " 4094  Rachel sends a list of Top 50 films of 2018. J...  2   opt-1.3b   \n",
       " \n",
       "      keyword_num  \n",
       " 0              1  \n",
       " 1              1  \n",
       " 2              1  \n",
       " 3              1  \n",
       " 4              1  \n",
       " ...          ...  \n",
       " 4090           1  \n",
       " 4091           1  \n",
       " 4092           1  \n",
       " 4093           1  \n",
       " 4094           1  \n",
       " \n",
       " [4095 rows x 7 columns],\n",
       " 'opt-1.3b-2-shot-2-keywords':       run_id                                             prompt  \\\n",
       " 0          0  Summarize the conversation with keywords:\\nJoh...   \n",
       " 1          0  Summarize the conversation with keywords:\\nLis...   \n",
       " 2          0  Summarize the conversation with keywords:\\nLar...   \n",
       " 3          0  Summarize the conversation with keywords:\\nLol...   \n",
       " 4          0  Summarize the conversation with keywords:\\nRob...   \n",
       " ...      ...                                                ...   \n",
       " 4090       4  Summarize the conversation with keywords:\\nCar...   \n",
       " 4091       4  Summarize the conversation with keywords:\\nNic...   \n",
       " 4092       4  Summarize the conversation with keywords:\\nJac...   \n",
       " 4093       4  Summarize the conversation with keywords:\\nIan...   \n",
       " 4094       4  Summarize the conversation with keywords:\\nCla...   \n",
       " \n",
       "                                            pred_summary  \\\n",
       " 0     Hannah and Amanda are talking about Betty. Ama...   \n",
       " 1     Eric watched a few of Rob's videos on YouTube....   \n",
       " 2     Bob buys Lenny a pair of black trousers and se...   \n",
       " 3     Emma is home and Will is picking her up. He te...   \n",
       " 4     Jane and Olly are talking about their plans fo...   \n",
       " ...                                                 ...   \n",
       " 4090  ~~Alex~~ Benjamin and Alex went to Friday's ga...   \n",
       " 4091  Jamilla and Kiki will be auditioning for the r...   \n",
       " 4092  ~~~ Marta has an accident and clicks something...   \n",
       " 4093  Cora and Ellie were surprised by the number of...   \n",
       " 4094  Janice and Spencer watch the top 50 best films...   \n",
       " \n",
       "                                            gold_summary  k model_name  \\\n",
       " 0     Hannah needs Betty's number but Amanda doesn't...  2   opt-1.3b   \n",
       " 1     Eric and Rob are going to watch a stand-up on ...  2   opt-1.3b   \n",
       " 2     Lenny can't decide which trousers to buy. Bob ...  2   opt-1.3b   \n",
       " 3     Emma will be home soon and she will let Will k...  2   opt-1.3b   \n",
       " 4     Jane is in Warsaw. Ollie and Jane has a party....  2   opt-1.3b   \n",
       " ...                                                 ... ..        ...   \n",
       " 4090  Benjamin didn't come to see a basketball game ...  2   opt-1.3b   \n",
       " 4091      The audition starts at 7.30 P.M. in Antena 3.  2   opt-1.3b   \n",
       " 4092                    Marta sent a file accidentally,  2   opt-1.3b   \n",
       " 4093  There was a meet-and-greet with James Charles ...  2   opt-1.3b   \n",
       " 4094  Rachel sends a list of Top 50 films of 2018. J...  2   opt-1.3b   \n",
       " \n",
       "      keyword_num  \n",
       " 0              2  \n",
       " 1              2  \n",
       " 2              2  \n",
       " 3              2  \n",
       " 4              2  \n",
       " ...          ...  \n",
       " 4090           2  \n",
       " 4091           2  \n",
       " 4092           2  \n",
       " 4093           2  \n",
       " 4094           2  \n",
       " \n",
       " [4095 rows x 7 columns],\n",
       " 'opt-1.3b-1-shot-3-keywords':       run_id                                             prompt  \\\n",
       " 0          0  Summarize the conversation with keywords:\\nTan...   \n",
       " 1          0  Summarize the conversation with keywords:\\nChr...   \n",
       " 2          0  Summarize the conversation with keywords:\\nSam...   \n",
       " 3          0  Summarize the conversation with keywords:\\nOwe...   \n",
       " 4          0  Summarize the conversation with keywords:\\nAly...   \n",
       " ...      ...                                                ...   \n",
       " 4090       4  Summarize the conversation with keywords:\\nHea...   \n",
       " 4091       4  Summarize the conversation with keywords:\\nKev...   \n",
       " 4092       4  Summarize the conversation with keywords:\\nSel...   \n",
       " 4093       4  Summarize the conversation with keywords:\\nJam...   \n",
       " 4094       4  Summarize the conversation with keywords:\\nJim...   \n",
       " \n",
       "                                            pred_summary  \\\n",
       " 0     ??????\\nLarry: Hi Hannah, I was wondering if y...   \n",
       " 1     ~~~ Eric is a stand up comedian. He has a yout...   \n",
       " 2     Lenny is wearing a pair of black trousers and ...   \n",
       " 3     Emma and Will are having dinner together. Will...   \n",
       " 4     Jane and Olly went to a cafe, where they had t...   \n",
       " ...                                                 ...   \n",
       " 4090  Benjamin says that he wishes he could have gon...   \n",
       " 4091        Jamilla and Kiki will attend the auditions.   \n",
       " 4092  ~~~ Marta invites Agnie to a dinner party, but...   \n",
       " 4093  ~~~ On her way home, Ellie tells Cora that she...   \n",
       " 4094  ~~~ Janice and Spencer watch Avengers: Infinit...   \n",
       " \n",
       "                                            gold_summary  k model_name  \\\n",
       " 0     Hannah needs Betty's number but Amanda doesn't...  1   opt-1.3b   \n",
       " 1     Eric and Rob are going to watch a stand-up on ...  1   opt-1.3b   \n",
       " 2     Lenny can't decide which trousers to buy. Bob ...  1   opt-1.3b   \n",
       " 3     Emma will be home soon and she will let Will k...  1   opt-1.3b   \n",
       " 4     Jane is in Warsaw. Ollie and Jane has a party....  1   opt-1.3b   \n",
       " ...                                                 ... ..        ...   \n",
       " 4090  Benjamin didn't come to see a basketball game ...  1   opt-1.3b   \n",
       " 4091      The audition starts at 7.30 P.M. in Antena 3.  1   opt-1.3b   \n",
       " 4092                    Marta sent a file accidentally,  1   opt-1.3b   \n",
       " 4093  There was a meet-and-greet with James Charles ...  1   opt-1.3b   \n",
       " 4094  Rachel sends a list of Top 50 films of 2018. J...  1   opt-1.3b   \n",
       " \n",
       "      keyword_num  \n",
       " 0              3  \n",
       " 1              3  \n",
       " 2              3  \n",
       " 3              3  \n",
       " 4              3  \n",
       " ...          ...  \n",
       " 4090           3  \n",
       " 4091           3  \n",
       " 4092           3  \n",
       " 4093           3  \n",
       " 4094           3  \n",
       " \n",
       " [4095 rows x 7 columns],\n",
       " 'opt-1.3b-1-shot-2-keywords':       run_id                                             prompt  \\\n",
       " 0          0  Summarize the conversation with keywords:\\nTan...   \n",
       " 1          0  Summarize the conversation with keywords:\\nChr...   \n",
       " 2          0  Summarize the conversation with keywords:\\nSam...   \n",
       " 3          0  Summarize the conversation with keywords:\\nOwe...   \n",
       " 4          0  Summarize the conversation with keywords:\\nAly...   \n",
       " ...      ...                                                ...   \n",
       " 4090       4  Summarize the conversation with keywords:\\nHea...   \n",
       " 4091       4  Summarize the conversation with keywords:\\nKev...   \n",
       " 4092       4  Summarize the conversation with keywords:\\nSel...   \n",
       " 4093       4  Summarize the conversation with keywords:\\nJam...   \n",
       " 4094       4  Summarize the conversation with keywords:\\nJim...   \n",
       " \n",
       "                                            pred_summary  \\\n",
       " 0     ~~~\\nLarry: Hi Hannah, I was wondering if you ...   \n",
       " 1     ~~~ Eric is watching a youtube video of a Russ...   \n",
       " 2     Lenny is wearing a pair of black trousers and ...   \n",
       " 3     Emma and Will are having dinner together. Will...   \n",
       " 4     Jane and Olly were talking about their plans f...   \n",
       " ...                                                 ...   \n",
       " 4090  Benjamin says that he wishes he could have gon...   \n",
       " 4091        Jamilla and Kiki will attend the auditions.   \n",
       " 4092  ~~~ Marta invites Agnie and Werona to her home...   \n",
       " 4093  Cora, Ellie and Christian were surprised by th...   \n",
       " 4094  Janice included Avengers: Infinity War in her ...   \n",
       " \n",
       "                                            gold_summary  k model_name  \\\n",
       " 0     Hannah needs Betty's number but Amanda doesn't...  1   opt-1.3b   \n",
       " 1     Eric and Rob are going to watch a stand-up on ...  1   opt-1.3b   \n",
       " 2     Lenny can't decide which trousers to buy. Bob ...  1   opt-1.3b   \n",
       " 3     Emma will be home soon and she will let Will k...  1   opt-1.3b   \n",
       " 4     Jane is in Warsaw. Ollie and Jane has a party....  1   opt-1.3b   \n",
       " ...                                                 ... ..        ...   \n",
       " 4090  Benjamin didn't come to see a basketball game ...  1   opt-1.3b   \n",
       " 4091      The audition starts at 7.30 P.M. in Antena 3.  1   opt-1.3b   \n",
       " 4092                    Marta sent a file accidentally,  1   opt-1.3b   \n",
       " 4093  There was a meet-and-greet with James Charles ...  1   opt-1.3b   \n",
       " 4094  Rachel sends a list of Top 50 films of 2018. J...  1   opt-1.3b   \n",
       " \n",
       "      keyword_num  \n",
       " 0              2  \n",
       " 1              2  \n",
       " 2              2  \n",
       " 3              2  \n",
       " 4              2  \n",
       " ...          ...  \n",
       " 4090           2  \n",
       " 4091           2  \n",
       " 4092           2  \n",
       " 4093           2  \n",
       " 4094           2  \n",
       " \n",
       " [4095 rows x 7 columns],\n",
       " 'opt-1.3b-1-shot-1-keywords':       run_id                                             prompt  \\\n",
       " 0          0  Summarize the conversation with keywords:\\nTan...   \n",
       " 1          0  Summarize the conversation with keywords:\\nChr...   \n",
       " 2          0  Summarize the conversation with keywords:\\nSam...   \n",
       " 3          0  Summarize the conversation with keywords:\\nOwe...   \n",
       " 4          0  Summarize the conversation with keywords:\\nAly...   \n",
       " ...      ...                                                ...   \n",
       " 4090       4  Summarize the conversation with keywords:\\nHea...   \n",
       " 4091       4  Summarize the conversation with keywords:\\nKev...   \n",
       " 4092       4  Summarize the conversation with keywords:\\nSel...   \n",
       " 4093       4  Summarize the conversation with keywords:\\nJam...   \n",
       " 4094       4  Summarize the conversation with keywords:\\nJim...   \n",
       " \n",
       "                                            pred_summary  \\\n",
       " 0     ____________\\nNeeds: _________________\\nWant:_...   \n",
       " 1     ~~~Rob and Eric are watching a video of a Russ...   \n",
       " 2                Lenny is buying a pair of black pants.   \n",
       " 3     Will and Emma are having dinner together. Emma...   \n",
       " 4     Jane was on her way back to Warsaw, when she r...   \n",
       " ...                                                 ...   \n",
       " 4090  Benjamin says that he wishes he could have gon...   \n",
       " 4091        Jamilla and Kiki will attend the auditions.   \n",
       " 4092  ~~~ Marta invites Agnie and Werona to her home...   \n",
       " 4093  A lot of people were surprised by the number o...   \n",
       " 4094  __________ will watch Avengers: Endgame with R...   \n",
       " \n",
       "                                            gold_summary  k model_name  \\\n",
       " 0     Hannah needs Betty's number but Amanda doesn't...  1   opt-1.3b   \n",
       " 1     Eric and Rob are going to watch a stand-up on ...  1   opt-1.3b   \n",
       " 2     Lenny can't decide which trousers to buy. Bob ...  1   opt-1.3b   \n",
       " 3     Emma will be home soon and she will let Will k...  1   opt-1.3b   \n",
       " 4     Jane is in Warsaw. Ollie and Jane has a party....  1   opt-1.3b   \n",
       " ...                                                 ... ..        ...   \n",
       " 4090  Benjamin didn't come to see a basketball game ...  1   opt-1.3b   \n",
       " 4091      The audition starts at 7.30 P.M. in Antena 3.  1   opt-1.3b   \n",
       " 4092                    Marta sent a file accidentally,  1   opt-1.3b   \n",
       " 4093  There was a meet-and-greet with James Charles ...  1   opt-1.3b   \n",
       " 4094  Rachel sends a list of Top 50 films of 2018. J...  1   opt-1.3b   \n",
       " \n",
       "      keyword_num  \n",
       " 0              1  \n",
       " 1              1  \n",
       " 2              1  \n",
       " 3              1  \n",
       " 4              1  \n",
       " ...          ...  \n",
       " 4090           1  \n",
       " 4091           1  \n",
       " 4092           1  \n",
       " 4093           1  \n",
       " 4094           1  \n",
       " \n",
       " [4095 rows x 7 columns],\n",
       " 'opt-1.3b-3-shot':       run_id                                             prompt  \\\n",
       " 0          0  Summarize the conversation:\\nCarter: my dietit...   \n",
       " 1          0  Summarize the conversation:\\nJustin: hey max, ...   \n",
       " 2          0  Summarize the conversation:\\nDaniel: <file_pho...   \n",
       " 3          0  Summarize the conversation:\\nTom: How are you ...   \n",
       " 4          0  Summarize the conversation:\\nOti: hi girls, I ...   \n",
       " ...      ...                                                ...   \n",
       " 2457       3  Summarize the conversation:\\nDermi: What app d...   \n",
       " 2458       3  Summarize the conversation:\\nTristan: i lost m...   \n",
       " 2459       3  Summarize the conversation:\\nJason: When are y...   \n",
       " 2460       3  Summarize the conversation:\\nJake: <file_photo...   \n",
       " 2461       3  Summarize the conversation:\\nJulia: Hello Patr...   \n",
       " \n",
       "                                            pred_summary  \\\n",
       " 0     ~~~ Hannah, Amanda and Larry are at a park. Ha...   \n",
       " 1     Eric and Rob watch a few of Eric's videos on Y...   \n",
       " 2     Bob sent Lenny photos of four different pairs ...   \n",
       " 3     Will and Emma are not happy with their dinner ...   \n",
       " 4     Jane is on her way back to Warsaw from Morocco...   \n",
       " ...                                                 ...   \n",
       " 2457  ~~~ Hannah and Amanda are talking about Betty....   \n",
       " 2458  ~~Eric~~ Rob and Eric watch Eric's YouTube vid...   \n",
       " 2459  Lenny wants to buy a pair of pants. Bob wants ...   \n",
       " 2460  Emma sends Will a picture of her cooking dinne...   \n",
       " 2461  Jane is on her way back to Warsaw from Morocco...   \n",
       " \n",
       "                                            gold_summary  k model_name  \\\n",
       " 0     Hannah needs Betty's number but Amanda doesn't...  3   opt-1.3b   \n",
       " 1     Eric and Rob are going to watch a stand-up on ...  3   opt-1.3b   \n",
       " 2     Lenny can't decide which trousers to buy. Bob ...  3   opt-1.3b   \n",
       " 3     Emma will be home soon and she will let Will k...  3   opt-1.3b   \n",
       " 4     Jane is in Warsaw. Ollie and Jane has a party....  3   opt-1.3b   \n",
       " ...                                                 ... ..        ...   \n",
       " 2457  Hannah needs Betty's number but Amanda doesn't...  3   opt-1.3b   \n",
       " 2458  Eric and Rob are going to watch a stand-up on ...  3   opt-1.3b   \n",
       " 2459  Lenny can't decide which trousers to buy. Bob ...  3   opt-1.3b   \n",
       " 2460  Emma will be home soon and she will let Will k...  3   opt-1.3b   \n",
       " 2461  Jane is in Warsaw. Ollie and Jane has a party....  3   opt-1.3b   \n",
       " \n",
       "      keyword_num  \n",
       " 0           None  \n",
       " 1           None  \n",
       " 2           None  \n",
       " 3           None  \n",
       " 4           None  \n",
       " ...          ...  \n",
       " 2457        None  \n",
       " 2458        None  \n",
       " 2459        None  \n",
       " 2460        None  \n",
       " 2461        None  \n",
       " \n",
       " [2462 rows x 7 columns],\n",
       " 'opt-1.3b-2-shot':       run_id                                             prompt  \\\n",
       " 0          0  Summarize the conversation:\\nJohn: How are you...   \n",
       " 1          0  Summarize the conversation:\\nLisa: hey there, ...   \n",
       " 2          0  Summarize the conversation:\\nLarry: Andy, you'...   \n",
       " 3          0  Summarize the conversation:\\nLolita: High hand...   \n",
       " 4          0  Summarize the conversation:\\nRobert: Hey sunsh...   \n",
       " ...      ...                                                ...   \n",
       " 4090       4  Summarize the conversation:\\nCaroline: There a...   \n",
       " 4091       4  Summarize the conversation:\\nNicholas: what's ...   \n",
       " 4092       4  Summarize the conversation:\\nJackson: Hey so I...   \n",
       " 4093       4  Summarize the conversation:\\nIan: On way back ...   \n",
       " 4094       4  Summarize the conversation:\\nClaire: I'm afrai...   \n",
       " \n",
       "                                            pred_summary  \\\n",
       " 0     Hannah and Amanda are texting each other. Aman...   \n",
       " 1     ~~Eric~~ Rob wants to watch Eric's videos on Y...   \n",
       " 2                Bob buys Lenny a pair of purple pants.   \n",
       " 3     Will and Emma have an argument over dinner. Em...   \n",
       " 4     Jane is on her way back to Warsaw from Morocco...   \n",
       " ...                                                 ...   \n",
       " 4090  ~~Alex~~ Benjamin and Alex went to Friday's ga...   \n",
       " 4091  Kiki and Jamilla will go to the auditions for ...   \n",
       " 4092  ~~~ Marta has an accident and accidentally sen...   \n",
       " 4093  Cora and Ellie were surprised by the amount of...   \n",
       " 4094  ~~Rachel~~ Janice and Spencer watch the top 50...   \n",
       " \n",
       "                                            gold_summary  k model_name  \\\n",
       " 0     Hannah needs Betty's number but Amanda doesn't...  2   opt-1.3b   \n",
       " 1     Eric and Rob are going to watch a stand-up on ...  2   opt-1.3b   \n",
       " 2     Lenny can't decide which trousers to buy. Bob ...  2   opt-1.3b   \n",
       " 3     Emma will be home soon and she will let Will k...  2   opt-1.3b   \n",
       " 4     Jane is in Warsaw. Ollie and Jane has a party....  2   opt-1.3b   \n",
       " ...                                                 ... ..        ...   \n",
       " 4090  Benjamin didn't come to see a basketball game ...  2   opt-1.3b   \n",
       " 4091      The audition starts at 7.30 P.M. in Antena 3.  2   opt-1.3b   \n",
       " 4092                    Marta sent a file accidentally,  2   opt-1.3b   \n",
       " 4093  There was a meet-and-greet with James Charles ...  2   opt-1.3b   \n",
       " 4094  Rachel sends a list of Top 50 films of 2018. J...  2   opt-1.3b   \n",
       " \n",
       "      keyword_num  \n",
       " 0           None  \n",
       " 1           None  \n",
       " 2           None  \n",
       " 3           None  \n",
       " 4           None  \n",
       " ...          ...  \n",
       " 4090        None  \n",
       " 4091        None  \n",
       " 4092        None  \n",
       " 4093        None  \n",
       " 4094        None  \n",
       " \n",
       " [4095 rows x 7 columns],\n",
       " 'opt-1.3b-1-shot':       run_id                                             prompt  \\\n",
       " 0          0  Summarize the conversation:\\nTania: Check out ...   \n",
       " 1          0  Summarize the conversation:\\nChris: how is you...   \n",
       " 2          0  Summarize the conversation:\\nSamuel: Stop and ...   \n",
       " 3          0  Summarize the conversation:\\nOwen: guys i am s...   \n",
       " 4          0  Summarize the conversation:\\nAlyssa: have you ...   \n",
       " ...      ...                                                ...   \n",
       " 4090       4  Summarize the conversation:\\nHeather: Eh, I've...   \n",
       " 4091       4  Summarize the conversation:\\nKevin: Hi, will y...   \n",
       " 4092       4  Summarize the conversation:\\nSelby: anybody fo...   \n",
       " 4093       4  Summarize the conversation:\\nJames: sorry boss...   \n",
       " 4094       4  Summarize the conversation:\\nJimmy: get me som...   \n",
       " \n",
       "                                            pred_summary  \\\n",
       " 0     ~~~ Amanda and Hannah are at a park. They are ...   \n",
       " 1     ~~Rob~~ Eric watches a few of Chris's videos o...   \n",
       " 2     Lenny is buying a pair of black trousers from ...   \n",
       " 3     Will and Emma are having dinner together. Will...   \n",
       " 4     Jane is on her way to a friend's place, where ...   \n",
       " ...                                                 ...   \n",
       " 4090  Alex and Benjamin talk about how they wish the...   \n",
       " 4091        Jamilla and Kiki will attend the auditions.   \n",
       " 4092  ~~~ Marta invites Agnie and Werona to a dinner...   \n",
       " 4093  Cora and Ellie are discussing the recent media...   \n",
       " 4094  ~~~ Janice and Spencer will watch Avengers: In...   \n",
       " \n",
       "                                            gold_summary  k model_name  \\\n",
       " 0     Hannah needs Betty's number but Amanda doesn't...  1   opt-1.3b   \n",
       " 1     Eric and Rob are going to watch a stand-up on ...  1   opt-1.3b   \n",
       " 2     Lenny can't decide which trousers to buy. Bob ...  1   opt-1.3b   \n",
       " 3     Emma will be home soon and she will let Will k...  1   opt-1.3b   \n",
       " 4     Jane is in Warsaw. Ollie and Jane has a party....  1   opt-1.3b   \n",
       " ...                                                 ... ..        ...   \n",
       " 4090  Benjamin didn't come to see a basketball game ...  1   opt-1.3b   \n",
       " 4091      The audition starts at 7.30 P.M. in Antena 3.  1   opt-1.3b   \n",
       " 4092                    Marta sent a file accidentally,  1   opt-1.3b   \n",
       " 4093  There was a meet-and-greet with James Charles ...  1   opt-1.3b   \n",
       " 4094  Rachel sends a list of Top 50 films of 2018. J...  1   opt-1.3b   \n",
       " \n",
       "      keyword_num  \n",
       " 0           None  \n",
       " 1           None  \n",
       " 2           None  \n",
       " 3           None  \n",
       " 4           None  \n",
       " ...          ...  \n",
       " 4090        None  \n",
       " 4091        None  \n",
       " 4092        None  \n",
       " 4093        None  \n",
       " 4094        None  \n",
       " \n",
       " [4095 rows x 7 columns]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iterate over completed runs to get summaries table\n",
    "MODEL_FAMILY = ['facebook/opt-1.3b']  # huggingface path\n",
    "\n",
    "run2metric_table = {}\n",
    "for run in tqdm(runs):\n",
    "    if 'complete' not in run.tags or run.config['model_type'] not in MODEL_FAMILY or run.job_type != 'evaluation':\n",
    "        continue\n",
    "    \n",
    "    # adjust the boolean expression if needed \n",
    "    if 'nameReplace' in run.name or 'length' in run.name or 'replaceName' in run.name or \\\n",
    "        'randomLabel' in run.name or 'focus' in run.name or 'numeric' in run.name:\n",
    "        continue  \n",
    "        \n",
    "    print('parsing run {}'.format(run.name))\n",
    "    files = run.files()\n",
    "    metric_file = [file for file in files if 'Summaries Table' in getattr(file, 'name', '')]\n",
    "    print([file.name for file in files])\n",
    "    if len(metric_file) < 1:\n",
    "        print('[WARN] skip {} because len(metric_file) >= 1'.format(metric_file))\n",
    "        continue \n",
    "    metric_file = metric_file[0]\n",
    "    f = metric_file.download(root='wandb', replace=True)\n",
    "    metrics = json.load(f)\n",
    "    metrics = json.dumps(metrics)\n",
    "    metric_table = pd.read_json(StringIO(metrics), orient='split')\n",
    "    # get k shot\n",
    "    match = re.search(r'\\d-shot', run.name)\n",
    "    start_i, end_i = match.span()\n",
    "    k = int(run.name[start_i: end_i].split('-')[0])\n",
    "\n",
    "    metric_table['k'] = k\n",
    "    model_name = run.name[: start_i - 1]\n",
    "    metric_table['model_name'] = model_name\n",
    "    if 'keyword' in run.name:\n",
    "        end_id = run.name.find('-keyword')\n",
    "        keyword_num = run.name[end_id - 1:end_id]\n",
    "        metric_table['keyword_num'] = keyword_num\n",
    "        print('[debug] find keyword_num = {} in {}'.format(keyword_num, run.name))\n",
    "    else:\n",
    "        metric_table['keyword_num'] = None\n",
    "\n",
    "    run2metric_table[run.name] = metric_table\n",
    "run2metric_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['opt-1.3b-2-shot-3-keywords', 'opt-1.3b-2-shot-1-keywords', 'opt-1.3b-2-shot-2-keywords', 'opt-1.3b-1-shot-3-keywords', 'opt-1.3b-1-shot-2-keywords', 'opt-1.3b-1-shot-1-keywords', 'opt-1.3b-3-shot', 'opt-1.3b-2-shot', 'opt-1.3b-1-shot'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run2metric_table.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_sentence(sentence):\n",
    "    if isinstance(sentence, str):\n",
    "        # Tokenize the sentence into words\n",
    "        words = word_tokenize(sentence)\n",
    "    else:\n",
    "        words = sentence\n",
    "    # Initialize the Porter stemmer\n",
    "    stemmer = PorterStemmer()\n",
    "    # Stem each word in the sentence\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]\n",
    "    # Join the stemmed words back into a sentence\n",
    "    return stemmed_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] parse experiment opt-1.3b-2-shot-3-keywords\n",
      "[info] parse experiment opt-1.3b-2-shot-1-keywords\n",
      "[info] parse experiment opt-1.3b-2-shot-2-keywords\n",
      "[info] parse experiment opt-1.3b-1-shot-3-keywords\n",
      "[info] parse experiment opt-1.3b-1-shot-2-keywords\n",
      "[info] parse experiment opt-1.3b-1-shot-1-keywords\n",
      "[info] parse experiment opt-1.3b-3-shot\n",
      "[info] parse run 0\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8728\\2373756365.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[1;31m# calculate the success rate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m         \u001b[0msuccess_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mincluded_keywords_num\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mkeywords_num_total\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m         \u001b[1;31m# print('[{}] success_rate = {}/{} = {}'.format(run_name, included_keywords_num, keywords_num_total, success_rate))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         df.append({\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "# get the success rate over runs and save the keywords\n",
    "df = []\n",
    "missing_keywords2counts = defaultdict(lambda: 0)\n",
    "included_keywords2counts = defaultdict(lambda: 0)\n",
    "\n",
    "summary_numerical_num = 0 \n",
    "response_numerical_num = 0\n",
    "\n",
    "for run_name, summaries in run2metric_table.items():\n",
    "    print('[info] parse experiment', run_name)\n",
    "\n",
    "    summaries['keyword_num'] = summaries['keyword_num'].fillna(0)\n",
    "    keyword_num = int(summaries['keyword_num'][0])\n",
    "#     if keyword_num <= 0 or 'keywords' not in run_name:\n",
    "#         continue  \n",
    "    if 'nameReplace' in run_name or 'length' in run_name or 'replaceName' in run_name or \\\n",
    "        'randomLabel' in run_name or 'focus' in run_name or 'numeric' in run_name or 'keywords' in run_name:\n",
    "        continue \n",
    "\n",
    "    model_name = summaries['model_name'][0]\n",
    "    k = summaries['k'][0]\n",
    "\n",
    "    for run_id, df_ in summaries.groupby('run_id'):\n",
    "        print('[info] parse run', run_id)\n",
    "        keywords_num_total = 0\n",
    "        included_keywords_num = 0\n",
    "\n",
    "        # iterate over the run\n",
    "        for _, row in df_.iterrows():\n",
    "            is_contains_numeric_gold = any(char.isdigit() for char in row['gold_summary'])\n",
    "            summary_numerical_num += is_contains_numeric_gold\n",
    "            is_contains_numeric_pred = any(char.isdigit() for char in row['pred_summary'])\n",
    "            response_numerical_num += is_contains_numeric_pred\n",
    "            \n",
    "            last_line = row['prompt'].split('\\n')[-1]\n",
    "            # parse the keywords\n",
    "            try:\n",
    "                start_i, end_i = re.search('\\[.+\\]', last_line).span()\n",
    "                keywords = [x.strip()[1:-1] for x in last_line[start_i+1:end_i-1].split(',')]\n",
    "            except AttributeError:  # mt5 keywords are in different format\n",
    "#                 print('[debug] last_line = {}'.format(last_line))\n",
    "                last_line = re.sub(r'<extra_id_\\d+>', '',last_line)\n",
    "                last_line = last_line.split('Summary: ', maxsplit=1)[-1]\n",
    "                keywords = [x for x in last_line.split(' ') if len(x.strip()) >= 1]\n",
    "                if len(keywords) != keyword_num:\n",
    "                    print('[debug] skip')\n",
    "                    continue \n",
    "            # stem words\n",
    "            keywords = stem_sentence(keywords)\n",
    "            gold_summary = stem_sentence(row['pred_summary'])  # fixme: wrong name \n",
    "            # check if keywords are included\n",
    "            keywords_num_total += len(keywords)\n",
    "            for keyword in keywords:\n",
    "                if keyword in gold_summary:\n",
    "                    included_keywords_num += 1\n",
    "                    included_keywords2counts[keyword] += 1\n",
    "                else:\n",
    "                    # print('[miss keywords] {} in sentence: {}'.format(keyword, gold_summary))\n",
    "                    missing_keywords2counts[keyword] += 1\n",
    "\n",
    "        # calculate the success rate\n",
    "        success_rate = included_keywords_num / keywords_num_total\n",
    "        # print('[{}] success_rate = {}/{} = {}'.format(run_name, included_keywords_num, keywords_num_total, success_rate))\n",
    "        df.append({\n",
    "                'model_name': model_name,\n",
    "                'k': k,\n",
    "                'keyword_num': keyword_num,\n",
    "                'success_rate': success_rate,\n",
    "                'run_id': run_id\n",
    "                })\n",
    "\n",
    "print('{} summaries with numerical information and {} responses contain numerical information'.format(summary_numerical_num, response_numerical_num))\n",
    "df = pd.DataFrame(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the ones with numeric values \n",
    "for word, counts in missing_keywords2counts.items():\n",
    "    is_contains_numeric = any(char.isdigit() for char in word)\n",
    "    if is_contains_numeric:\n",
    "        print('Missing {}, counts = {}'.format(word, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the ones with numeric values \n",
    "for word, counts in included_keywords2counts.items():\n",
    "    is_contains_numeric = any(char.isdigit() for char in word)\n",
    "    if is_contains_numeric:\n",
    "        print('Including {}, counts = {}'.format(word, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = sb.color_palette(\"ch:s=.25,rot=-.25\", as_cmap=False)\n",
    "\n",
    "plot = sb.lineplot(data=df, x='k', y='success_rate', hue='keyword_num', style='model_name', palette=palette)\n",
    "\n",
    "plot.set_xticks([1, 2, 3]) # <--- set the ticks first\n",
    "plot.set_xticklabels(['1', '2', '3'])\n",
    "\n",
    "plt.savefig('success_rate.jpg', dpi=500, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['model_name']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['model_name']).std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the success rate deviation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "749365f43b13432aa5622156dc2f09cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/317 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsing run Cerebras-GPT-6.7B-3-shot-focus\n",
      "['artifact/494913737/wandb_manifest.json', 'artifact/494913775/wandb_manifest.json', 'config.yaml', 'media/table/Evaluation metrics Table_0_15c461e7d379620a2afb.table.json', 'media/table/Summaries Table_1_cea1e202aaaba1a14116.table.json', 'output.log', 'requirements.txt', 'wandb-metadata.json', 'wandb-summary.json']\n",
      "parsing run Cerebras-GPT-6.7B-3-shot\n",
      "['artifact/460934750/wandb_manifest.json', 'artifact/460934805/wandb_manifest.json', 'config.yaml', 'media/table/Evaluation metrics Table_0_79de4653b96bdd3516d6.table.json', 'media/table/Summaries Table_1_1862cad7895785859830.table.json', 'output.log', 'requirements.txt', 'wandb-metadata.json', 'wandb-summary.json']\n"
     ]
    }
   ],
   "source": [
    "# Define the runs and fetch the evaluation results \n",
    "KEYWORDS_RUN_NAME = 'Cerebras-GPT-6.7B-3-shot-focus'\n",
    "DIRECT_RUN_NAME = 'Cerebras-GPT-6.7B-3-shot'\n",
    "\n",
    "\n",
    "keywords_summary_df = None\n",
    "direct_summary_df = None \n",
    "for run in tqdm(runs):\n",
    "    if 'complete' not in run.tags or run.name not in [KEYWORDS_RUN_NAME, DIRECT_RUN_NAME] or run.job_type != 'evaluation':\n",
    "        continue\n",
    "        \n",
    "    print('parsing run {}'.format(run.name))\n",
    "    files = run.files()\n",
    "    metric_file = [file for file in files if 'Summaries Table' in getattr(file, 'name', '')]\n",
    "    print([file.name for file in files])\n",
    "    if len(metric_file) < 1:\n",
    "        print('[WARN] skip {} because len(metric_file) >= 1'.format(metric_file))\n",
    "        continue \n",
    "    metric_file = metric_file[0]\n",
    "    f = metric_file.download(root='wandb', replace=True)\n",
    "    metrics = json.load(f)\n",
    "    metrics = json.dumps(metrics)\n",
    "    metric_table = pd.read_json(StringIO(metrics), orient='split')\n",
    "    # get k shot\n",
    "    match = re.search(r'\\d-shot', run.name)\n",
    "    start_i, end_i = match.span()\n",
    "    k = int(run.name[start_i: end_i].split('-')[0])\n",
    "\n",
    "    metric_table['k'] = k\n",
    "    model_name = run.name[: start_i - 1]\n",
    "    metric_table['model_name'] = model_name\n",
    "    if 'keyword' in run.name:\n",
    "        end_id = run.name.find('-keyword')\n",
    "        keyword_num = run.name[end_id - 1:end_id]\n",
    "        metric_table['keyword_num'] = keyword_num\n",
    "        print('[debug] find keyword_num = {} in {}'.format(keyword_num, run.name))\n",
    "    else:\n",
    "        metric_table['keyword_num'] = None\n",
    "\n",
    "    if run.name == KEYWORDS_RUN_NAME:\n",
    "        keywords_summary_df = metric_table\n",
    "    else:\n",
    "        direct_summary_df = metric_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>pred_summary</th>\n",
       "      <th>gold_summary</th>\n",
       "      <th>k</th>\n",
       "      <th>model_name</th>\n",
       "      <th>keyword_num</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Summarize the conversation with the focus pers...</td>\n",
       "      <td>Hannah asked Betty for her phone number. Betty...</td>\n",
       "      <td>Hannah needs Betty's number but Amanda doesn't...</td>\n",
       "      <td>3</td>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>None</td>\n",
       "      <td>[Hannah, Betty, Amanda, Larry]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Summarize the conversation with the focus pers...</td>\n",
       "      <td>Eric is watching Rob's youtube videos. Rob wil...</td>\n",
       "      <td>Eric and Rob are going to watch a stand-up on ...</td>\n",
       "      <td>3</td>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>None</td>\n",
       "      <td>[Eric, Rob]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Summarize the conversation with the focus pers...</td>\n",
       "      <td>Lenny asked Bob to send him some photos of him...</td>\n",
       "      <td>Lenny can't decide which trousers to buy. Bob ...</td>\n",
       "      <td>3</td>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>None</td>\n",
       "      <td>[Lenny, Bob]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Summarize the conversation with the focus pers...</td>\n",
       "      <td>Emma and Will are having dinner together. Emma...</td>\n",
       "      <td>Emma will be home soon and she will let Will k...</td>\n",
       "      <td>3</td>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>None</td>\n",
       "      <td>[Emma, Will]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Summarize the conversation with the focus pers...</td>\n",
       "      <td>Jane is on her way to a party in Poland.  She ...</td>\n",
       "      <td>Jane is in Warsaw. Ollie and Jane has a party....</td>\n",
       "      <td>3</td>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>None</td>\n",
       "      <td>[Jane, Ollie]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1957</td>\n",
       "      <td>2</td>\n",
       "      <td>Summarize the conversation with the focus pers...</td>\n",
       "      <td>Nick and Steve are having lunch together. Nick...</td>\n",
       "      <td>Nick will got some lunch for Steve - it can be...</td>\n",
       "      <td>3</td>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>None</td>\n",
       "      <td>[Nick, Steve]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1958</td>\n",
       "      <td>2</td>\n",
       "      <td>Summarize the conversation with the focus pers...</td>\n",
       "      <td>Gemma and Timmy have been invited to attend th...</td>\n",
       "      <td>Gemma will invite Timmy and his Date, as well ...</td>\n",
       "      <td>3</td>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>None</td>\n",
       "      <td>[Gemma, Timmy, Date, Lona, Michelle]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1959</td>\n",
       "      <td>2</td>\n",
       "      <td>Summarize the conversation with the focus pers...</td>\n",
       "      <td>Millie is sick. She won't come to work today. ...</td>\n",
       "      <td>Millie is sick, so she won't come today.</td>\n",
       "      <td>3</td>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>None</td>\n",
       "      <td>[Millie]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1960</td>\n",
       "      <td>2</td>\n",
       "      <td>Summarize the conversation with the focus pers...</td>\n",
       "      <td>Lisa and Daisy are waiting for Daisy to go hom...</td>\n",
       "      <td>Lisa isn't going home yet. Daisy wants her to ...</td>\n",
       "      <td>3</td>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>None</td>\n",
       "      <td>[Lisa, Daisy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1961</td>\n",
       "      <td>2</td>\n",
       "      <td>Summarize the conversation with the focus pers...</td>\n",
       "      <td>Tina and Sophie are almost ready to leave. Tin...</td>\n",
       "      <td>Tina will make it for the bus that is leaving ...</td>\n",
       "      <td>3</td>\n",
       "      <td>Cerebras-GPT-6.7B</td>\n",
       "      <td>None</td>\n",
       "      <td>[Tina]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1962 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      run_id                                             prompt  \\\n",
       "0          0  Summarize the conversation with the focus pers...   \n",
       "1          0  Summarize the conversation with the focus pers...   \n",
       "2          0  Summarize the conversation with the focus pers...   \n",
       "3          0  Summarize the conversation with the focus pers...   \n",
       "4          0  Summarize the conversation with the focus pers...   \n",
       "...      ...                                                ...   \n",
       "1957       2  Summarize the conversation with the focus pers...   \n",
       "1958       2  Summarize the conversation with the focus pers...   \n",
       "1959       2  Summarize the conversation with the focus pers...   \n",
       "1960       2  Summarize the conversation with the focus pers...   \n",
       "1961       2  Summarize the conversation with the focus pers...   \n",
       "\n",
       "                                           pred_summary  \\\n",
       "0     Hannah asked Betty for her phone number. Betty...   \n",
       "1     Eric is watching Rob's youtube videos. Rob wil...   \n",
       "2     Lenny asked Bob to send him some photos of him...   \n",
       "3     Emma and Will are having dinner together. Emma...   \n",
       "4     Jane is on her way to a party in Poland.  She ...   \n",
       "...                                                 ...   \n",
       "1957  Nick and Steve are having lunch together. Nick...   \n",
       "1958  Gemma and Timmy have been invited to attend th...   \n",
       "1959  Millie is sick. She won't come to work today. ...   \n",
       "1960  Lisa and Daisy are waiting for Daisy to go hom...   \n",
       "1961  Tina and Sophie are almost ready to leave. Tin...   \n",
       "\n",
       "                                           gold_summary  k         model_name  \\\n",
       "0     Hannah needs Betty's number but Amanda doesn't...  3  Cerebras-GPT-6.7B   \n",
       "1     Eric and Rob are going to watch a stand-up on ...  3  Cerebras-GPT-6.7B   \n",
       "2     Lenny can't decide which trousers to buy. Bob ...  3  Cerebras-GPT-6.7B   \n",
       "3     Emma will be home soon and she will let Will k...  3  Cerebras-GPT-6.7B   \n",
       "4     Jane is in Warsaw. Ollie and Jane has a party....  3  Cerebras-GPT-6.7B   \n",
       "...                                                 ... ..                ...   \n",
       "1957  Nick will got some lunch for Steve - it can be...  3  Cerebras-GPT-6.7B   \n",
       "1958  Gemma will invite Timmy and his Date, as well ...  3  Cerebras-GPT-6.7B   \n",
       "1959           Millie is sick, so she won't come today.  3  Cerebras-GPT-6.7B   \n",
       "1960  Lisa isn't going home yet. Daisy wants her to ...  3  Cerebras-GPT-6.7B   \n",
       "1961  Tina will make it for the bus that is leaving ...  3  Cerebras-GPT-6.7B   \n",
       "\n",
       "     keyword_num                              keywords  \n",
       "0           None        [Hannah, Betty, Amanda, Larry]  \n",
       "1           None                           [Eric, Rob]  \n",
       "2           None                          [Lenny, Bob]  \n",
       "3           None                          [Emma, Will]  \n",
       "4           None                         [Jane, Ollie]  \n",
       "...          ...                                   ...  \n",
       "1957        None                         [Nick, Steve]  \n",
       "1958        None  [Gemma, Timmy, Date, Lona, Michelle]  \n",
       "1959        None                              [Millie]  \n",
       "1960        None                         [Lisa, Daisy]  \n",
       "1961        None                                [Tina]  \n",
       "\n",
       "[1962 rows x 8 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get keywords\n",
    "keywords_col = []\n",
    "\n",
    "for _, row in keywords_summary_df.iterrows():\n",
    "    # parse the keywords in the prompt \n",
    "    last_line = row['prompt'].split('\\n')[-1]\n",
    "    try:\n",
    "        start_i, end_i = re.search('\\[.+\\]', last_line).span()\n",
    "        keywords = [x.strip()[1:-1] for x in last_line[start_i+1:end_i-1].split(',')]\n",
    "        keywords_col.append(keywords)\n",
    "    except AttributeError:  # mt5 keywords are in different format\n",
    "#                 print('[debug] last_line = {}'.format(last_line))\n",
    "        last_line = re.sub(r'<extra_id_\\d+>', '',last_line)\n",
    "        last_line = last_line.split('Summary: ', maxsplit=1)[-1]\n",
    "        keywords = [x for x in last_line.split(' ') if len(x.strip()) >= 1]\n",
    "        if len(keywords) != keyword_num:\n",
    "            print('[debug] skip')\n",
    "            continue \n",
    "        else:\n",
    "            keywords_col.append(keywords)\n",
    "keywords_summary_df['keywords'] = keywords_col\n",
    "keywords_summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success rate = 0.8252494778370851\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('', 36),\n",
       " ('abigail', 12),\n",
       " ('ella', 9),\n",
       " ('jack', 9),\n",
       " ('john', 8),\n",
       " ('tom', 8),\n",
       " ('peter', 7),\n",
       " ('anna', 6),\n",
       " ('ela', 6),\n",
       " ('kate', 6),\n",
       " ('olli', 5),\n",
       " ('helen', 5),\n",
       " ('bill', 5),\n",
       " ('jim', 5),\n",
       " ('michel', 5),\n",
       " ('elliot', 4),\n",
       " ('eric', 4),\n",
       " ('jessica', 4),\n",
       " ('nicol', 4),\n",
       " ('chri', 4),\n",
       " ('martin', 4),\n",
       " ('aquaman', 4),\n",
       " ('susi', 4),\n",
       " ('hilari', 3),\n",
       " ('mroek', 3),\n",
       " ('momo', 3),\n",
       " ('wujek janek', 3),\n",
       " ('chewi', 3),\n",
       " ('poppi', 3),\n",
       " ('lulu', 3),\n",
       " ('speedi', 3),\n",
       " ('patrycja', 3),\n",
       " ('inez', 3),\n",
       " ('gosia', 3),\n",
       " ('alicja', 3),\n",
       " ('zadi', 3),\n",
       " ('nathali', 3),\n",
       " ('zazu', 3),\n",
       " ('ro', 3),\n",
       " ('donald trump', 3),\n",
       " ('rashi', 3),\n",
       " ('jenson', 3),\n",
       " ('alen', 3),\n",
       " ('lister', 3),\n",
       " ('dawid podsiadlo', 3),\n",
       " ('doctor mccormick', 3),\n",
       " ('naheeda', 3),\n",
       " ('estefania', 3),\n",
       " ('sam', 3),\n",
       " ('nicki', 3)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the original success rate \n",
    "keywords_summary_df['gold_summary'] = keywords_summary_df['gold_summary'].astype(str)\n",
    "direct_summary_df['gold_summary'] = direct_summary_df['gold_summary'].astype(str)\n",
    "merged_df = keywords_summary_df.merge(right=direct_summary_df, \n",
    "                        on=['gold_summary', 'run_id'],\n",
    "                         how='inner')\n",
    "\n",
    "keywords_num_total = 0 \n",
    "included_keywords_num = 0 \n",
    "\n",
    "missing_keywords2counts = defaultdict(lambda: 0)\n",
    "included_keywords2counts = defaultdict(lambda: 0)\n",
    "\n",
    "for _, row in merged_df.iterrows():\n",
    "    keywords = row['keywords']\n",
    "    # stem words\n",
    "    keywords = stem_sentence(keywords)\n",
    "    gold_summary = stem_sentence(row['pred_summary_y'])  # fixme: wrong name \n",
    "    # check if keywords are included\n",
    "    keywords_num_total += len(keywords)\n",
    "    for keyword in keywords:\n",
    "        if keyword in gold_summary:\n",
    "            included_keywords_num += 1\n",
    "            included_keywords2counts[keyword] += 1\n",
    "        else:\n",
    "            # print('[miss keywords] {} in sentence: {}'.format(keyword, gold_summary))\n",
    "            missing_keywords2counts[keyword] += 1\n",
    "print('Success rate = {}'.format(included_keywords_num / keywords_num_total))\n",
    "sorted([(k, v) for k, v in  missing_keywords2counts.items()], key=lambda x: x[1], reverse=True)[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>prompt_x</th>\n",
       "      <th>pred_summary_x</th>\n",
       "      <th>gold_summary</th>\n",
       "      <th>k_x</th>\n",
       "      <th>model_name_x</th>\n",
       "      <th>keyword_num_x</th>\n",
       "      <th>keywords</th>\n",
       "      <th>prompt_y</th>\n",
       "      <th>pred_summary_y</th>\n",
       "      <th>k_y</th>\n",
       "      <th>model_name_y</th>\n",
       "      <th>keyword_num_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Summarize the conversation with keywords:\\nJoh...</td>\n",
       "      <td>Amanda asks Larry to text Betty.</td>\n",
       "      <td>Hannah needs Betty's number but Amanda doesn't...</td>\n",
       "      <td>2</td>\n",
       "      <td>opt-iml-1.3b</td>\n",
       "      <td>3</td>\n",
       "      <td>[needs, contact, larry]</td>\n",
       "      <td>Summarize the conversation:\\nJohn: How are you...</td>\n",
       "      <td>Hannah wants to text Larry to ask him about Be...</td>\n",
       "      <td>2</td>\n",
       "      <td>opt-iml-1.3b</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Summarize the conversation with keywords:\\nLis...</td>\n",
       "      <td>Eric will watch some videos of Rob's.</td>\n",
       "      <td>Eric and Rob are going to watch a stand-up on ...</td>\n",
       "      <td>2</td>\n",
       "      <td>opt-iml-1.3b</td>\n",
       "      <td>3</td>\n",
       "      <td>[eric, stand, youtube]</td>\n",
       "      <td>Summarize the conversation:\\nLisa: hey there, ...</td>\n",
       "      <td>Eric, Rob and Jenny are going to watch some vi...</td>\n",
       "      <td>2</td>\n",
       "      <td>opt-iml-1.3b</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Summarize the conversation with keywords:\\nLar...</td>\n",
       "      <td>Lenny sends Bob photos of the trousers he will...</td>\n",
       "      <td>Lenny can't decide which trousers to buy. Bob ...</td>\n",
       "      <td>2</td>\n",
       "      <td>opt-iml-1.3b</td>\n",
       "      <td>3</td>\n",
       "      <td>[lenny, trousers, bob]</td>\n",
       "      <td>Summarize the conversation:\\nLarry: Andy, you'...</td>\n",
       "      <td>Lenny wants Bob to send him photos of the clot...</td>\n",
       "      <td>2</td>\n",
       "      <td>opt-iml-1.3b</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Summarize the conversation with keywords:\\nLol...</td>\n",
       "      <td>Emma and Will are going to have dinner togethe...</td>\n",
       "      <td>Emma will be home soon and she will let Will k...</td>\n",
       "      <td>2</td>\n",
       "      <td>opt-iml-1.3b</td>\n",
       "      <td>3</td>\n",
       "      <td>[emma, soon, let]</td>\n",
       "      <td>Summarize the conversation:\\nLolita: High hand...</td>\n",
       "      <td>Emma won't cook tonight.</td>\n",
       "      <td>2</td>\n",
       "      <td>opt-iml-1.3b</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Summarize the conversation with keywords:\\nRob...</td>\n",
       "      <td>Jane is on her way back to Warsaw. She will ha...</td>\n",
       "      <td>Jane is in Warsaw. Ollie and Jane has a party....</td>\n",
       "      <td>2</td>\n",
       "      <td>opt-iml-1.3b</td>\n",
       "      <td>3</td>\n",
       "      <td>[jane, ollie, lunch]</td>\n",
       "      <td>Summarize the conversation:\\nRobert: Hey sunsh...</td>\n",
       "      <td>Jane is on her way back to Warsaw from Morocco...</td>\n",
       "      <td>2</td>\n",
       "      <td>opt-iml-1.3b</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4090</td>\n",
       "      <td>4</td>\n",
       "      <td>Summarize the conversation with keywords:\\nCar...</td>\n",
       "      <td>Benjamin and Alex watched Friday's game of bas...</td>\n",
       "      <td>Benjamin didn't come to see a basketball game ...</td>\n",
       "      <td>2</td>\n",
       "      <td>opt-iml-1.3b</td>\n",
       "      <td>3</td>\n",
       "      <td>[benjamin, basketball, declares]</td>\n",
       "      <td>Summarize the conversation:\\nCaroline: There a...</td>\n",
       "      <td>Alex, Benjamin and Alex's mom are sick.</td>\n",
       "      <td>2</td>\n",
       "      <td>opt-iml-1.3b</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4091</td>\n",
       "      <td>4</td>\n",
       "      <td>Summarize the conversation with keywords:\\nNic...</td>\n",
       "      <td>Jamilla and Kiki will go to the auditions.</td>\n",
       "      <td>The audition starts at 7.30 P.M. in Antena 3.</td>\n",
       "      <td>2</td>\n",
       "      <td>opt-iml-1.3b</td>\n",
       "      <td>3</td>\n",
       "      <td>[audition, starts, antena]</td>\n",
       "      <td>Summarize the conversation:\\nNicholas: what's ...</td>\n",
       "      <td>Jamilla, Kiki, Yo and Roger are going to an au...</td>\n",
       "      <td>2</td>\n",
       "      <td>opt-iml-1.3b</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4092</td>\n",
       "      <td>4</td>\n",
       "      <td>Summarize the conversation with keywords:\\nJac...</td>\n",
       "      <td>Marta accidentally clicked on a file.</td>\n",
       "      <td>Marta sent a file accidentally,</td>\n",
       "      <td>2</td>\n",
       "      <td>opt-iml-1.3b</td>\n",
       "      <td>3</td>\n",
       "      <td>[marta, file, accidentally]</td>\n",
       "      <td>Summarize the conversation:\\nJackson: Hey so I...</td>\n",
       "      <td>Marta accidentally clicked on a file.</td>\n",
       "      <td>2</td>\n",
       "      <td>opt-iml-1.3b</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4093</td>\n",
       "      <td>4</td>\n",
       "      <td>Summarize the conversation with keywords:\\nIan...</td>\n",
       "      <td>Cora, Ellie and Kylie were surprised by the am...</td>\n",
       "      <td>There was a meet-and-greet with James Charles ...</td>\n",
       "      <td>2</td>\n",
       "      <td>opt-iml-1.3b</td>\n",
       "      <td>3</td>\n",
       "      <td>[greet, gathered, 8000]</td>\n",
       "      <td>Summarize the conversation:\\nIan: On way back ...</td>\n",
       "      <td>Cora, Ellie and Kylie are talking about the news.</td>\n",
       "      <td>2</td>\n",
       "      <td>opt-iml-1.3b</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4094</td>\n",
       "      <td>4</td>\n",
       "      <td>Summarize the conversation with keywords:\\nCla...</td>\n",
       "      <td>Rachel, Janice and Spencer watched the top 50 ...</td>\n",
       "      <td>Rachel sends a list of Top 50 films of 2018. J...</td>\n",
       "      <td>2</td>\n",
       "      <td>opt-iml-1.3b</td>\n",
       "      <td>3</td>\n",
       "      <td>[2018, janice, included]</td>\n",
       "      <td>Summarize the conversation:\\nClaire: I'm afrai...</td>\n",
       "      <td>Emily, Gavin, Janice, Sam, Anna and Meg are go...</td>\n",
       "      <td>2</td>\n",
       "      <td>opt-iml-1.3b</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4095 rows  13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      run_id                                           prompt_x  \\\n",
       "0          0  Summarize the conversation with keywords:\\nJoh...   \n",
       "1          0  Summarize the conversation with keywords:\\nLis...   \n",
       "2          0  Summarize the conversation with keywords:\\nLar...   \n",
       "3          0  Summarize the conversation with keywords:\\nLol...   \n",
       "4          0  Summarize the conversation with keywords:\\nRob...   \n",
       "...      ...                                                ...   \n",
       "4090       4  Summarize the conversation with keywords:\\nCar...   \n",
       "4091       4  Summarize the conversation with keywords:\\nNic...   \n",
       "4092       4  Summarize the conversation with keywords:\\nJac...   \n",
       "4093       4  Summarize the conversation with keywords:\\nIan...   \n",
       "4094       4  Summarize the conversation with keywords:\\nCla...   \n",
       "\n",
       "                                         pred_summary_x  \\\n",
       "0                      Amanda asks Larry to text Betty.   \n",
       "1                 Eric will watch some videos of Rob's.   \n",
       "2     Lenny sends Bob photos of the trousers he will...   \n",
       "3     Emma and Will are going to have dinner togethe...   \n",
       "4     Jane is on her way back to Warsaw. She will ha...   \n",
       "...                                                 ...   \n",
       "4090  Benjamin and Alex watched Friday's game of bas...   \n",
       "4091         Jamilla and Kiki will go to the auditions.   \n",
       "4092              Marta accidentally clicked on a file.   \n",
       "4093  Cora, Ellie and Kylie were surprised by the am...   \n",
       "4094  Rachel, Janice and Spencer watched the top 50 ...   \n",
       "\n",
       "                                           gold_summary  k_x  model_name_x  \\\n",
       "0     Hannah needs Betty's number but Amanda doesn't...    2  opt-iml-1.3b   \n",
       "1     Eric and Rob are going to watch a stand-up on ...    2  opt-iml-1.3b   \n",
       "2     Lenny can't decide which trousers to buy. Bob ...    2  opt-iml-1.3b   \n",
       "3     Emma will be home soon and she will let Will k...    2  opt-iml-1.3b   \n",
       "4     Jane is in Warsaw. Ollie and Jane has a party....    2  opt-iml-1.3b   \n",
       "...                                                 ...  ...           ...   \n",
       "4090  Benjamin didn't come to see a basketball game ...    2  opt-iml-1.3b   \n",
       "4091      The audition starts at 7.30 P.M. in Antena 3.    2  opt-iml-1.3b   \n",
       "4092                    Marta sent a file accidentally,    2  opt-iml-1.3b   \n",
       "4093  There was a meet-and-greet with James Charles ...    2  opt-iml-1.3b   \n",
       "4094  Rachel sends a list of Top 50 films of 2018. J...    2  opt-iml-1.3b   \n",
       "\n",
       "     keyword_num_x                          keywords  \\\n",
       "0                3           [needs, contact, larry]   \n",
       "1                3            [eric, stand, youtube]   \n",
       "2                3            [lenny, trousers, bob]   \n",
       "3                3                 [emma, soon, let]   \n",
       "4                3              [jane, ollie, lunch]   \n",
       "...            ...                               ...   \n",
       "4090             3  [benjamin, basketball, declares]   \n",
       "4091             3        [audition, starts, antena]   \n",
       "4092             3       [marta, file, accidentally]   \n",
       "4093             3           [greet, gathered, 8000]   \n",
       "4094             3          [2018, janice, included]   \n",
       "\n",
       "                                               prompt_y  \\\n",
       "0     Summarize the conversation:\\nJohn: How are you...   \n",
       "1     Summarize the conversation:\\nLisa: hey there, ...   \n",
       "2     Summarize the conversation:\\nLarry: Andy, you'...   \n",
       "3     Summarize the conversation:\\nLolita: High hand...   \n",
       "4     Summarize the conversation:\\nRobert: Hey sunsh...   \n",
       "...                                                 ...   \n",
       "4090  Summarize the conversation:\\nCaroline: There a...   \n",
       "4091  Summarize the conversation:\\nNicholas: what's ...   \n",
       "4092  Summarize the conversation:\\nJackson: Hey so I...   \n",
       "4093  Summarize the conversation:\\nIan: On way back ...   \n",
       "4094  Summarize the conversation:\\nClaire: I'm afrai...   \n",
       "\n",
       "                                         pred_summary_y  k_y  model_name_y  \\\n",
       "0     Hannah wants to text Larry to ask him about Be...    2  opt-iml-1.3b   \n",
       "1     Eric, Rob and Jenny are going to watch some vi...    2  opt-iml-1.3b   \n",
       "2     Lenny wants Bob to send him photos of the clot...    2  opt-iml-1.3b   \n",
       "3                              Emma won't cook tonight.    2  opt-iml-1.3b   \n",
       "4     Jane is on her way back to Warsaw from Morocco...    2  opt-iml-1.3b   \n",
       "...                                                 ...  ...           ...   \n",
       "4090            Alex, Benjamin and Alex's mom are sick.    2  opt-iml-1.3b   \n",
       "4091  Jamilla, Kiki, Yo and Roger are going to an au...    2  opt-iml-1.3b   \n",
       "4092              Marta accidentally clicked on a file.    2  opt-iml-1.3b   \n",
       "4093  Cora, Ellie and Kylie are talking about the news.    2  opt-iml-1.3b   \n",
       "4094  Emily, Gavin, Janice, Sam, Anna and Meg are go...    2  opt-iml-1.3b   \n",
       "\n",
       "     keyword_num_y  \n",
       "0             None  \n",
       "1             None  \n",
       "2             None  \n",
       "3             None  \n",
       "4             None  \n",
       "...            ...  \n",
       "4090          None  \n",
       "4091          None  \n",
       "4092          None  \n",
       "4093          None  \n",
       "4094          None  \n",
       "\n",
       "[4095 rows x 13 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing 10, counts = 5\n",
      "Missing 300, counts = 5\n",
      "Missing 2014, counts = 5\n",
      "Missing 19, counts = 5\n",
      "Missing 2pm, counts = 5\n",
      "Missing 15, counts = 10\n",
      "Missing 21st, counts = 5\n",
      "Missing 00, counts = 5\n",
      "Missing 898998, counts = 5\n",
      "Missing 342, counts = 4\n",
      "Missing 40, counts = 5\n",
      "Missing 11, counts = 10\n",
      "Missing 100, counts = 5\n",
      "Missing 35, counts = 5\n",
      "Missing 7pm, counts = 5\n",
      "Missing 6123, counts = 5\n",
      "Missing 15th, counts = 5\n",
      "Missing 45678, counts = 5\n",
      "Missing 30, counts = 5\n",
      "Missing 20, counts = 6\n",
      "Missing 55, counts = 5\n",
      "Missing 104, counts = 5\n",
      "Missing 21, counts = 5\n",
      "Missing 50, counts = 5\n",
      "Missing 24, counts = 5\n",
      "Missing s8, counts = 5\n",
      "Missing 637, counts = 5\n",
      "Missing 187, counts = 5\n",
      "Missing 112, counts = 5\n",
      "Missing 2nd, counts = 5\n",
      "Missing 20th, counts = 5\n",
      "Missing 11am, counts = 5\n",
      "Missing 8pm, counts = 5\n",
      "Missing 65, counts = 4\n",
      "Missing 11th, counts = 5\n",
      "Missing 4pm, counts = 5\n",
      "Missing 22, counts = 5\n",
      "Missing 8000, counts = 5\n",
      "Missing 2018, counts = 3\n",
      "Missing 1990, counts = 4\n",
      "Missing ps4, counts = 1\n"
     ]
    }
   ],
   "source": [
    "# find the ones with numeric values \n",
    "for word, counts in missing_keywords2counts.items():\n",
    "    is_contains_numeric = any(char.isdigit() for char in word)\n",
    "    if is_contains_numeric:\n",
    "        print('Missing {}, counts = {}'.format(word, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing ps4, counts = 4\n",
      "Missing 1990, counts = 1\n",
      "Missing 20, counts = 4\n",
      "Missing 2019, counts = 5\n",
      "Missing 342, counts = 1\n",
      "Missing 2018, counts = 2\n",
      "Missing 65, counts = 1\n"
     ]
    }
   ],
   "source": [
    "# find the ones with numeric values \n",
    "for word, counts in included_keywords2counts.items():\n",
    "    is_contains_numeric = any(char.isdigit() for char in word)\n",
    "    if is_contains_numeric:\n",
    "        print('Missing {}, counts = {}'.format(word, counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze the numerical keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the test dataset\n",
    "test_dataset = load_dataset('samsum', split='test')\n",
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the summaries with numerical information \n",
    "summaries_numerical = []\n",
    "for summary in test_dataset['summary']:\n",
    "    is_contains_numeric = any(char.isdigit() for char in summary)\n",
    "    if is_contains_numeric:\n",
    "        summaries_numerical.append(summary)\n",
    "\n",
    "print('{} summaries ({}%) with numerical chars'.format(len(summaries_numerical), len(summaries_numerical)/len(test_dataset) * 100))\n",
    "summaries_numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of summaries with numerical values\n",
    "df = []\n",
    "\n",
    "summary_numerical_num = 0 \n",
    "response_numerical_num = 0\n",
    "\n",
    "summary_examples = []\n",
    "response_examples = [] \n",
    "\n",
    "for run_name, summaries in run2metric_table.items():\n",
    "    if 'nameReplace' in run_name or 'length' in run_name or 'replaceName' in run_name \\\n",
    "        or 'randomLabel' in run_name or 'focus' in run_name or 'instructions' in run_name or 'keywords' in run_name:\n",
    "        continue\n",
    "    \n",
    "    print('[info] parse experiment', run_name)\n",
    "\n",
    "    summaries['keyword_num'] = summaries['keyword_num'].fillna(0)\n",
    "    keyword_num = int(summaries['keyword_num'][0])\n",
    "#     if keyword_num <= 0:\n",
    "#         continue  \n",
    "\n",
    "    model_name = summaries['model_name'][0]\n",
    "    k = summaries['k'][0]\n",
    "\n",
    "    for run_id, df_ in summaries.groupby('run_id'):\n",
    "        print('[info] parse run', run_id)\n",
    "        keywords_num_total = 0\n",
    "        included_keywords_num = 0\n",
    "\n",
    "        # iterate over the run\n",
    "        for _, row in df_.iterrows():\n",
    "            is_contains_numeric_gold = any(char.isdigit() for char in row['gold_summary'])\n",
    "            summary_numerical_num += is_contains_numeric_gold\n",
    "            is_contains_numeric_pred = any(char.isdigit() for char in row['pred_summary'])\n",
    "            response_numerical_num += is_contains_numeric_pred\n",
    "            if is_contains_numeric_gold and is_contains_numeric_pred:\n",
    "                summary_examples.append(row['gold_summary'])\n",
    "                response_examples.append(row['pred_summary'])\n",
    "\n",
    "print('{} summaries with numerical information and {} responses contain numerical information ({}%)'.format(summary_numerical_num, response_numerical_num, \n",
    "                                                                                                           response_numerical_num / summary_numerical_num * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_examples[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_examples[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deviation from expected length "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over completed runs to get summaries table\n",
    "MODEL_FAMILY = ['cerebras/Cerebras-GPT-6.7B']\n",
    "\n",
    "run2metric_table = {}\n",
    "for run in tqdm(runs):\n",
    "    if 'complete' not in run.tags or run.config['model_type'] not in MODEL_FAMILY or run.job_type != 'evaluation':\n",
    "        continue\n",
    "    if 'nameReplace' in run.name:\n",
    "        continue \n",
    "        \n",
    "    print('parsing run {}'.format(run.name))\n",
    "    files = run.files()\n",
    "    metric_file = [file for file in files if 'Summaries Table' in getattr(file, 'name', '')]\n",
    "    if len(metric_file) < 1:\n",
    "        print('[WARN] no metric_file is found at {}, and it is skipped'.format(run.name))\n",
    "        continue \n",
    "    metric_file = metric_file[0]\n",
    "    f = metric_file.download(root='wandb', replace=True)\n",
    "    metrics = json.load(f)\n",
    "    metrics = json.dumps(metrics)\n",
    "    metric_table = pd.read_json(StringIO(metrics), orient='split')\n",
    "    # get k shot\n",
    "    match = re.search(r'\\d-shot', run.name)\n",
    "    start_i, end_i = match.span()\n",
    "    k = int(run.name[start_i: end_i].split('-')[0])\n",
    "\n",
    "    metric_table['k'] = k\n",
    "    model_name = run.name[: start_i - 1]\n",
    "    metric_table['model_name'] = model_name\n",
    "    if 'keyword' in run.name:\n",
    "        end_id = run.name.find('-keyword')\n",
    "        keyword_num = run.name[end_id - 1:end_id]\n",
    "        metric_table['keyword_num'] = keyword_num\n",
    "        print('[debug] find keyword_num = {} in {}'.format(keyword_num, run.name))\n",
    "    else:\n",
    "        metric_table['keyword_num'] = None\n",
    "\n",
    "    run2metric_table[run.name] = metric_table\n",
    "run2metric_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ks: uncontrolled keys \n",
    "ks = [x for x in run2metric_table.keys() if ('length' not in x and 'keyword' not in x and 'replaceName' not in x)]\n",
    "# ks: controlled setting \n",
    "# ks = [x for x in run2metric_table.keys() if ('length' in x)]\n",
    "\n",
    "\n",
    "length_df = []\n",
    "for k in ks:\n",
    "    print('[debug] processing {}'.format(k))\n",
    "    run_df = run2metric_table[k]\n",
    "    lengths = []\n",
    "    \n",
    "    for _, row in run_df.iterrows():\n",
    "        words = [word.lower() for word in nltk.word_tokenize(row['gold_summary']) if word not in string.punctuation]\n",
    "        control_length = len(words)\n",
    "        \n",
    "        words = [word.lower() for word in nltk.word_tokenize(row['pred_summary']) if word not in string.punctuation]\n",
    "        actual_length = len(words)\n",
    "            \n",
    "        row['length_error'] = abs(control_length - actual_length)\n",
    "        row['run_name'] = k\n",
    "        \n",
    "        length_df.append(row)\n",
    "length_df = pd.DataFrame(length_df)\n",
    "length_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_df.groupby('k').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_df['length_error'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_df['length_error'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over completed runs to get perplexity\n",
    "run2perplexity = {}\n",
    "\n",
    "for run in tqdm(runs):\n",
    "    if 'complete' not in run.tags or getattr(run, 'job_type', '') != 'perplexity_evaluation':\n",
    "        continue\n",
    "    else:\n",
    "        print('parsing run {}'.format(run.name))\n",
    "        \n",
    "    files = run.files()\n",
    "    metric_file = [file for file in files if 'Perplexity Table' in getattr(file, 'name', '')]\n",
    "    assert len(metric_file) == 1\n",
    "\n",
    "    metric_file = metric_file[0]\n",
    "    f = metric_file.download(root='wandb', replace=True)\n",
    "    metrics = json.load(f)\n",
    "    metrics = json.dumps(metrics)\n",
    "    metric_table = pd.read_json(StringIO(metrics), orient='split')\n",
    "    # get k shot\n",
    "    try:\n",
    "        match = re.search(r'\\d-shot', run.name)\n",
    "        start_i, end_i = match.span()\n",
    "        k = int(run.name[start_i: end_i].split('-')[0])\n",
    "    except AttributeError:\n",
    "        print('[debug] skip {}'.format(run.name))\n",
    "        continue\n",
    "    metric_table['k'] = k\n",
    "    model_name = run.name[: start_i - 1]\n",
    "    if run.name == 'Cerebras-6.7B-3-shot':\n",
    "        metric_table['model_name'] = 'Cerebras-GPT-6.7B'\n",
    "    else:\n",
    "        metric_table['model_name'] = model_name\n",
    "    if 'keyword' in run.name:\n",
    "        end_id = run.name.find('-keyword')\n",
    "        keyword_num = run.name[end_id - 1:end_id]\n",
    "        metric_table['keyword_num'] = keyword_num\n",
    "        print('[debug] find keyword_num = {} in {}'.format(keyword_num, run.name))\n",
    "    else:\n",
    "        metric_table['keyword_num'] = None\n",
    "\n",
    "    run2perplexity[run.name] = metric_table\n",
    "run2perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run2perplexity = {k: v for k, v in run2perplexity.items() if 'llama-7b-hf' in k}\n",
    "run2perplexity.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexity_df = pd.concat(run2perplexity.values(), axis=0, ignore_index=True)\n",
    "perplexity_df['perplexity'] = pd.to_numeric(perplexity_df['perplexity'])\n",
    "print('{} infinite values found'.format(sum(perplexity_df['perplexity'].isin([np.inf]))))\n",
    "perplexity_df = perplexity_df[~perplexity_df['perplexity'].isin([np.inf])]\n",
    "perplexity_df = perplexity_df.fillna(0)\n",
    "perplexity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = sb.lineplot(data=perplexity_df, x='k', y='perplexity', hue='keyword_num', markers=True, palette=palette)\n",
    "plot.set_xticks([1, 2, 3]) # <--- set the ticks first\n",
    "plot.set_xticklabels(['1', '2', '3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the result of MODEL_NAME family\n",
    "MODEL_NAME = 'llama-7b-hf'\n",
    "\n",
    "if MODEL_NAME == 'mt5-xl':\n",
    "    new_keys = [x for x in run2metric_table.keys() if MODEL_NAME in x and 'mt5-xxl' not in x]\n",
    "else:\n",
    "    new_keys = [x for x in run2metric_table.keys() if MODEL_NAME in x]\n",
    "print('[debug] new_keys =', sorted(new_keys))\n",
    "dfs = [run2metric_table[k] for k in new_keys]\n",
    "rouge_table = pd.concat(dfs, axis=0)\n",
    "model_name = MODEL_NAME\n",
    "rouge_table['k'] = rouge_table['k'].astype(int)\n",
    "rouge_table['keyword_num'] = rouge_table['keyword_num'].fillna(0)\n",
    "rouge_table['keyword_num'] = rouge_table['keyword_num'].astype(int)\n",
    "rouge_table = rouge_table[~rouge_table.isna().any(axis=1)]\n",
    "\n",
    "rouge_table = rouge_table[(rouge_table['k'] <= 3)]\n",
    "# rouge_table = rouge_table[~rouge_table['model_name'].str.contains('Cerebras-GPT-6.7B')]\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "palette = sb.color_palette(\"ch:s=.25,rot=-.25\", as_cmap=False)\n",
    "\n",
    "plot = sb.lineplot(data=rouge_table, x='k', y='rouge_1_fmeasure', hue='keyword_num', ax=axes[0], markers=True, palette=palette)\n",
    "plot.set_xticks([1, 2, 3]) # <--- set the ticks first\n",
    "plot.set_xticklabels(['1', '2', '3'])\n",
    "axes[0].yaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\n",
    "plot = sb.lineplot(data=rouge_table, x='k', y='rouge_2_fmeasure', hue='keyword_num', ax=axes[1], markers=True, palette=palette)\n",
    "plot.set_xticks([1, 2, 3]) # <--- set the ticks first\n",
    "plot.set_xticklabels(['1', '2', '3'])\n",
    "axes[1].yaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\n",
    "plot = sb.lineplot(data=rouge_table, x='k', y='rouge_L_fmeasure', hue='keyword_num', ax=axes[2], markers=True, palette=palette)\n",
    "plot.set_xticks([1, 2, 3]) # <--- set the ticks first\n",
    "plot.set_xticklabels(['1', '2', '3'])\n",
    "axes[2].yaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\n",
    "plot = sb.lineplot(data=perplexity_df, x='k', y='perplexity', hue='keyword_num', markers=True, palette=palette, ax=axes[3])\n",
    "plot.set_xticks([1, 2, 3]) # <--- set the ticks first\n",
    "plot.set_xticklabels(['1', '2', '3'])\n",
    "axes[0].get_legend().remove()\n",
    "axes[1].get_legend().remove()\n",
    "axes[2].get_legend().remove()\n",
    "axes[3].get_legend().remove()\n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='upper right', ncol=5, bbox_to_anchor=(.8, 1), title='Keyword number')\n",
    "fig.suptitle(MODEL_NAME, fontweight='bold')\n",
    "#\n",
    "plt.savefig('{}_entity_control.jpg'.format(MODEL_NAME), dpi=500, bbox_inches='tight')\n",
    "\n",
    "rouge_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [run2metric_table[k] for k in new_keys]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
